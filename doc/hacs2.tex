%% HACS 2 NOTES.
%%
%% Copyright (c) 2015 Kristoffer Rose <krisrose@crsx.org>
%% 
\documentclass[11pt]{article} %style: font size.
\usepackage[utf8]{inputenc}

\usepackage[type={CC},modifier={by},version={4.0}]{doclicense}
\newcommand{\basecopyright}{\noindent
  \HAX is © 2011, 2015 Kristoffer Rose and released under the
  \href{https://www.eclipse.org/legal/epl-v10.html}{Eclipse Public License 1.0}.\\
  \noindent Documentation is \doclicenseImage[imagewidth=3em]
  2011,2015 Kristoffer Rose.}
\newcommand{\documentcopyright}{\basecopyright}

%% Style.
\usepackage[margin=.7in]{geometry}
\usepackage[T1]{fontenc}
\bibliographystyle{plainurl}
\renewcommand{\rmdefault}{pplx}\usepackage{eulervm}\AtBeginDocument{\SelectTips{eu}{11}}

%% Base format.
\input{setup}

%% Topmatter.
\title{
  Evolution From \HAX\ 1 to 2
}
\author{
  Kristoffer H. Rose\\
  Two Sigma Investments / New York University
}

\begin{document}
\maketitle

\begin{abstract}\noindent
  This document discusses curious implementation details of \HAX version 1 and how they should be
  fixed and new things added in \HAX version 2.

  \compacttableofcontents

  \vspace*{2em}\small\color{gray}\noindent%
  \documentcopyright
\end{abstract}


\section{Overview}\label{sec:overview}

\HAX1 is written as the following components:
%%
\begin{itemize}

\item A parser, \emph{HxRaw}, which is generated by instantiating the \emph{HxRaw.pgtemplate} with
  the four \emph{Hx.*} files and using pg and JavaCC. The resulting parser will take a \emph{.hx}
  file into a generic ``raw'' \CRSX3 term form (the instructions for that are in \emph{Hacs.mk}).

\item A \CRSX3 script, \emph{Prep.crs}, which from a ``raw'' \CRSX3 term form of a \emph{.hx} file
  will generate a single file with three parsers (detailed in Section~\ref{sec:parsing}). One of
  these parsers is fully compiled to serve the following script.

\item A \CRSX3 script, \emph{Cook.crs}, which is run on a \CRSX3 term of the \emph{.hx} file, which
  is generated by one of the custom parsers of the previous step. The output of the \emph{Cook.crs}
  script is itself a \CRSX3 script, which can be run with the special user parser (also from
  \emph{Prep.crs}) to implement the user's intent (see Section~\ref{sec:compiling} for further
  details on this).

\end{itemize}
%%
The following sections give further details on how \HAX1 is implemented and what should be fixed for
\HAX2.


\section{Lexing \& Parsing}\label{sec:parsing}

In version 1, the \emph{Prep.crs} script translates a grammar to three parsers in mixed pg/JavaCC
form:
%%
\begin{itemize}

\item\emph{User input parser.} Has all user syntax as specified by the grammar with no recognition
  of \HAX meta-notation ("⟦⟨⟩⟧"). Generates user AST terms. Only parser that is used by the final
  user script.

\item\emph{Raw parser.} Recognizes all declared ``raw'' constructs as well as generic \HAX syntax
  (meta-variables with \#, \etc). All material in syntax brackets ("⟦⟧") results in invocation of
  the embedded parser below. Generates Cook-ready internal \HAX AST.

\item\emph{Embedded parser.} Recognizes the user's specified syntax extended with \HAX meta-notation
  for embedding ``raw'' \HAX into syntax. All raw syntax is delegated to the raw parser
  above. Generates Cook-ready internal \HAX AST.

\end{itemize}
%%
In version 2, we plan for several tweaks to this. (See also the Modules Section~\ref{sec:modules}
for the plan to allow modular parsers and the Sugar Section~\ref{sec:sugar} for plans to fix
\kw{sugar}.)

\subsection{Repetition}

We reintroduce automatic list generation by having derived non-terminals of the form $NM$
where $N$ is a non-terminal and $M$ is one of "?", "*", and "+"$U$, with the usual RE semantics
and $U$ an optional unit as in \kw{token} declarations allowed just for "+". The resulting
non-terminal is registered as such, making the following kinds of definitions possible:
%% 
\begin{itemize}

\item For $M="?"$ the required patterns are:
  \begin{hacs}[mathescape]
    sort … | scheme F($N$?);
    F(⟦ ⟨$N$ #1⟩ ⟧) →  …; //present
    F(⟦ ⟧) →  …; //absent
  \end{hacs}

\item For $M="*"$ the required patterns are:
  %% 
  \begin{hacs}[mathescape]
    sort … | scheme F($N$*);
    F(⟦ ⟨$N$ #1⟩ ⟨$N$* #rest⟩ ⟧) →  …; //one more
    F(⟦ ⟧) →  …; //end
  \end{hacs}
  %% 
  The first rule is applied for every list element, and the second at the end of the list
  (innermost).

\item For $M="+"U$, the patterns include the special $U$ separator and must have this shape:
  \begin{hacs}[mathescape]
    sort … | scheme F($N$+$U$);
    F(⟦ ⟨$N$ #1⟩ $U$ ⟨$N$+$U$ #rest⟩ ⟧) →  …; //non-last
    F(⟦ ⟨$N$ #1⟩ ⟧) →  …; //last
  \end{hacs}
  where the second rule is applied to just the last list element (so innermost). The first rule
  should insert the $U$ literally, of course, for example like this:
  \begin{hacs}[mathescape]
    sort Bool | scheme IsSingle(Elem+[,]);
    IsSingle(⟦ ⟨Elem #1⟩ ,  ⟨Elem+[,] #rest⟩ ⟧) →  False;
    IsSingle(⟦ ⟨Elem #1⟩ ⟧) →  True;
  \end{hacs}

\end{itemize}
%% 
Note that we will not allow $M="*"U$ with patterns
%% 
\begin{hacs}[mathescape]
    sort … | scheme F($N$*$U$);
    F(⟦ ⟨$N$ #1⟩ $U$ ⟨$N$*$U$ #rest⟩ ⟧) →  …;
    F(⟦ ⟧) →  …;
\end{hacs}
%% 
(and some understanding that it is dishonest about the last separator before the empty case). You
can get almost the same with
%% 
\begin{hacs}[mathescape]
    sort … | scheme F($N$+$U$?) | scheme F2($N$+$U$); F(⟦ ⟨$N$+$U$ #⟩ ⟧) →  F2(#);

    F(⟦ ⟧) →  …;  //empty
    F2(⟦ ⟨$N$ #1⟩ $U$ ⟨$N$*$U$ #rest⟩ ⟧) →  …; //non-last
    F2(⟦ ⟨$N$ #1⟩ ⟧) →  …; //last
\end{hacs}

\subsection{Modules}

Modules, described in Section~\ref{sec:modules}, each define a \emph{separate parser family} of
three parsers (user, embedded, raw); the \kw{private} declaration there affects the user parser.


\section{Modules}\label{sec:modules}

In version 1, one can only have one top level module. In version 2, modules can be combined.  The
semantics of multiple modules is as follows:

\subsection{Inclusion}

Modules can \emph{include} other modules with code like this:
\begin{hacs}
    include org.crsx.hacs.Prelude;
\end{hacs}
This will search for a file named something like \emph{org/crsx/hacs/Prelude.hx} with some search
path mechanism to be determined.  The include mechanism operates as if all the declarations of the
included module were \emph{copied} into the location of the include declaration.  In particular,
all syntax is included as is, so the including module can create extensions of the included
parser. Note that internal nodes generated by the including parser will be incompatible with nodes
generated by the original parser.

\subsection{Import}

Modules can \emph{import} another module with code like this:
\begin{hacs}
    import org.crsx.hacs.Prelude;
\end{hacs}
This will search for a file named something like \emph{org/crsx/hacs/Prelude.hx} with some search
path mechanism to be determined.  After the import, all tokens and sort defined in the imported
module are available with their fully qualified names.

\subsection{Private Declarations}

All declarations in a module can be marked with the keyword \kw{private}. This hides them from
\kw{import} (but not from \kw{include}, where the privateness is merely repeated). For the generated
parsers, in addition any \kw{private}-declared syntax is omitted from the user input parsers.


\section{Attributes}\label{sec:attributes}

A key feature of \HAX1 is the rules for synthesized and inherited attributes:
%%
\begin{itemize}

\item Synthesized attributes are limited to simple upwards propagation (S-attributed) rules, and
  only one attribute can be defined at the time in this way.

\item Inherited attributes must be ``carried'' by a scheme and are only available during the single
  traversal of that scheme, leading to complex ``chain rules'' of multiple helper schemes and
  non-trivial interactions with synthesized attributes.

\end{itemize}
%%
This is messy and hard to explain, and \HAX2 attempts to generalize it…

\subsection{Catchers}

First, we intend to follow \hax and change the syntax for ``catcher'' meta-variables in \HAX2 to
just "{#}", changing set lookup to "{#:}" and making "{:#}" deprecated. Also, \HAX2 will permit
multiple maps per instance, \eg, "↓e{a:A,b:B}".

In addition, in \HAX2, we allow ${↕}\text{\#as}$ as an abbreviation for the attribute set catchers
${↑}\text{\#asyn}{↓}\text{\#ainh}$).

\subsection{Unified Attribution Rules}

In \HAX2 we try to recast this by explaining that the \emph{notion} of attributes could be
systematically expressed by equations of the general form
%%
\begin{equation}
  d\left(\,\ov{\, t_j\,\ov{{↑}s_j} ⇒ \ov{{↓}i_j} \,}\,\right) ~ \ov{{↓}i_0} ⇒ \ov{{↑}s_0}
  \label{eq:attributes}
\end{equation}
%%
with the intent that
%%
\begin{itemize}

\item $d$ is a data constructor representing an abstract syntax tree node corresponding to one
  production that we call ``the $d$ production;''

\item ${↑}s_{0,1}…{↑}s_{0,k}$ (for $k≥0$) represent the synthesized attributes that are defined for
  the $d$ production parent;

\item ${↓}i_{0,1}…{↓}i_{0,k}$ (for $k≥0$) represent the inherited attributes that are extracted from
  the $d$ production parent;

\item The various ${↑}s_{j,1}…{↑}s_{j,k}$ (for $k≥0$) represent the synthesized attributes that are
  extracted from the $d$ production component~$t_j$;

\item The various ${↓}i_{j,1}…{↓}i_{j,k}$ (for $k≥0$) represent the inherited attributes that are
  defined for the $d$ production component~$t_j$.

\end{itemize}
%%
The above works with the following constraints:
%%
\begin{itemize}
\item there are no other ⇒s in the term than those explicitly mentioned;
\item $\op{mv}\!\left(\ov{{↓}i_j}\,\ov{{↑}s_0}\right) ⊆
  \op{mv}\!\left(t_j\,\ov{{↑}s_j}\,\ov{{↓}i_0}\right)$.
\end{itemize}
%%
With the above, we can rewrite an SDD inspired by the manual~\cite{Rose:ts2016}:
%%
\begin{equation*}
  \begin{array}{r@{\;}l|lr}
    \Xhline{2\arrayrulewidth}
    \multicolumn{2}{c|}{\textsc{Production}}  & \textsc{Semantic Rules} &\Bigstrut\\
    \hline\Bigstrut
    S &→ \textbf{id} := E_1; S_2
    & E_1.e = S.e; S_2.e = \op{Extend}(S.e, \textbf{id}.sym, E_1.t) &\thetag{S1}
    \\[\jot]
    &\mid \{~S_1~\}~S_2 & S_1.e = S.e; S_2.e = S.e &\thetag{S2}
    \\[\jot]
    &\mid ε & &\thetag{S3}
    \\[\jot]
    \hline\Bigstrut
    E &→ E_1 + E_2 & E_1.e=E.e; E_2.e=E.e; E.t = \op{Unif}(E_1.t, E_2.t) &\thetag{E1}\\[\jot]
    &\mid \textbf{int} & E.t = \op{Int}&\thetag{E2}\\[\jot]
    &\mid \textbf{id} & E.t = \op{Lookup}(E.e,\textbf{id}.sym)&\thetag{E3}
    \\[\jot]
    \Xhline{2\arrayrulewidth}
  \end{array}
\end{equation*}
%%
as the following \HAX2 (omitting syntax declarations from the manual and with the new catcher
syntax):
%%
\begin{hacs}[texcl,numbers=right,xrightmargin=2em]
    attribute ↓e{E:T};
    attribute ↑t(T);

    sort S | ↓e;

    // S1(1): $E_1.e = S.e$
    ⟦ id := ⟨E#1 ⇒ ↓e{#Se}⟩; ⟨S#2⟩ ⟧ ↓e{#Se} ⇒;
    // S1(2): $S_2.e = \op{Extend}(S.e, \textbf{id}.sym, E_1.t) $
    ⟦ id := ⟨E#1 ↑t(#E1t) ⇒⟩; ⟨S#2 ⇒ ↓e{#Se,⟦id⟧:#E1t}⟩ ⟧ ↓e{#Se} ⇒;

    // S2: $S_1.e = S.e; S_2.e = S.e $
    ⟦ { ⟨S#1 ⇒↓e{#Se}⟩ } ⟨S#2 ⇒↓e{#Se}⟩ ⟧ ↓e{#Se} ⇒;

    // S3:
    ⟦ ⟧ ↓e{#Se} ⇒;

    sort E | ↓e | ↑t;

    // E1(1): $E_1.e=E.e; E_2.e=E.e$
    ⟦ ⟨E#1 ⇒ ↓e{#Ee}⟩ + ⟨E#2 ⇒ ↓e{#Ee}⟩ ⟧↓e{#Ee} ⇒;
    // E1(2): $E.t = \op{Unif}(E_1.t, E_2.t)$
    ⟦ ⟨E#1 ↑t(#E1t) ⇒⟩ + ⟨E#2 ↑t(#E2t) ⇒⟩ ⟧ ⇒ ↑t(Unif(#E1t,#E2t));

    // E2: $E.t = \op{Int}$
    ⟦ ⟨INT#1⟩ ⟧ ⇒ ↑t(Int);

    // E3: $E.t = \op{Lookup}(E.e,\textbf{id}.sym)$
    ⟦ id ⟧ ↓e{⟦id⟧ : #t} ⇒  ↑t(#t);
\end{hacs}
%%
The insight needed by the programmer is that two of the rules---\thetag{S1} and \thetag{E1}---need
to be split into two passes: the first to propagate $e$, the second to synthesize~$t$. The reason
for this is \thetag{E3}, where the synthesized $t$ \emph{depends} on the inherted~$e$.

\TBD{
  I am unsure about whether the $⇒$ should just be $→$ or should be removed (which corresponds to
  what \HAX1 has).
}

The full formal details of how attribution rules are realized are given in
Appendix~\ref{app:attributes}.


\section{Inference Rules}\label{sec:infer}

\HAX1 has no support for inference rules. In \HAX2, I hope to add (higher order) \emph{inference
  rules} of the form
%% 
\begin{equation}
  \dfrac
  { ∀\,\ov{x} : (\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,) }
  { P_0 ⇒ C_{n+1}}
  ~(L)
  \label{eq:infer}
\end{equation}
%% 
where
%% 
\begin{itemize}
\item $L$ is the unique name of the rule.
\item $P_0$ and all of $C_1,…,C_n$ are \emph{function constructions}.
\item $P_0$ is a \emph{pattern} and all of $P_1,…,P_n$ are \emph{pattern fragments}.
\item $∀i\colon \op{mv}(C_i) ⊆ \op{mv}(P_0…P_{i-1})$.
\end{itemize}
%%
In \HAX2, we'd hope to implement the above by syntax like
\begin{equation}
  [L]~P_0~\kw{where}~[\ov{x}](\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,) → C_{n+1}
\end{equation}
%%
or
%%
\begin{equation}
  [L]~P_0 → C_{n+1}~\kw{when}~[\ov{x}](\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,)
\end{equation}
%%
or
%%
\begin{equation}
  [L]~\kw{when}~[\ov{x}](\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,) ~ \kw{infer} ~ P_0 → C_{n+1}
\end{equation}
%%
or
%%
\begin{equation}
  [L]~\kw{infer} ~ P_0 → C_{n+1} ~ \kw{when}~[\ov{x}](\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,)
\end{equation}
%% 
where $P_0$ is a usual rule left side, \ie, must be a legal scheme instantiation.

To be practical, we intend to also allow ``filters premises'' of the form $C_i=P_i$, which simply
require that the function construction $C_i$ can be matched by~$P_i$ (but otherwise satisfy the same
constraints as for regular premises).

Note that inference rules as described here are \emph{not} ``Conditional Term Rewriting Systems:''
no restrictions on evaluation are implied.

We formalize in some detail in Appendix~\ref{app:infer}.


\section{Sugar}\label{sec:sugar}

\HAX2 permits some additional syntactic sugar:
%%
\begin{enumerate}

\item Currently \kw{sugar} declarations really only work for usual parenthesis. The notion should be
  extended to allow any syntax to rewrite to other syntax, possibly by reverting to using rewrite
  steps except in the most simple cases. Sugar should also be more intelligently reinserted when
  possible.

\item An additional top level declaration is allowed:
  \begin{displaymath}
    \kw{template}~P~\kw{$→$}~M\,\kw;  \quad⇒\quad
    \kw{scheme}~P'\,\kw; ~ \kw{\texttt{|}} ~ \kw{data} ~ T'\,\kw; ~ \kw{rule} ~ P~\kw{$→$}~M\,\kw;
  \end{displaymath}
  where $P'$ and $T'$ are variants of $P$ and $P$ that have been cleared of "#"s.

\end{enumerate}


\section{Behavior}\label{sec:behavior}

\HAX1 has a special built-in "Computed" pseudo-module, which has a special ``behavior'' in that
"Computed" terms are \emph{evaluated} following hard-coded rules. In \HAX2, this should be
generalized to allow programmable rules.  I am as of yet unsure what the best notation for this
would be---alternatives include
%%
\begin{itemize}

\item Eliminate "Computed" and instead make numeric and atom types native to \HAX with the
  expression syntax native to (raw) \HAX.

\item Create a way to access ``C primitives'' directly from \HAX on basic values.

\end{itemize}


\section{Compiling}\label{sec:compiling}

Generated \HAX1 rewrite systems are currently in untyped \CRSX3 form. It would be nice if the
generated rewrite systems were compilable with the \CRSX rules-compiler (initially using \CRSX3 but
eventually moving to \CRSX4/\hax). This would involve the following steps:
%%
\begin{itemize}

\item Extend the \emph{Cook.crs} script to generate full sort information in the generated \CRSX3
  script, so the \CRSX3 full compiler can be used (as it is used for the \HAX scripts).

\item Modify the \emph{Prep.crs} to generate parsers to use flex/bison directly. Initially just the
  user parser should be generated this way: the parser needs to reflect the semantic of the way the
  current pg→\emph{file}→crsx\_scan→\emph{term} (in memory) works.

\end{itemize}


\appendix\small

\section{Attribute Normalization}
\label{app:attributes}

In this appendix we give the formal rules for translating attribution rules to core \HAX2 rules.

\begin{definition}

  The \emph{full attribution rules} for a data constructor $d$ are the full set of rules rooted with
  $d$, which must have the shape.
  %% 
  \begin{gather*}
    d\left(\,
      [\ov{v_{1.1}}]t_{1.1}\,\ov{{↑}a_{1.1}} ⇒ \ov{{↓}b_{1.1}}
      \,,…,\,
      [\ov{v_{1.m_1}}]t_{1.m_1}\,\ov{{↑}a_{1.m_1}} ⇒ \ov{{↓}b_{1.m_1}}
      \,\right) ~ \ov{{↓}b_{1.0}} ⇒ \ov{{↑}a_{1.0}} \\[-1ex]
    \vdots\\
    d\left(\,
      [\ov{v_{n.1}}]t_{n.1}\,\ov{{↑}a_{n.1}} ⇒ \ov{{↓}b_{n.1}}
      \,,…,\,
      [\ov{v_{n.m_n}}]t_{n.m_n}\,\ov{{↑}a_{n.m_n}} ⇒ \ov{{↓}b_{n.m_n}}
      \,\right) ~ \ov{{↓}b_{n.0}} ⇒ \ov{{↑}a_{n.0}}
  \end{gather*}
  %% 
  with $n≥1$ and $∀j, 1≤j≤n\colon m_j≥0$, and where we have used $a$ and $b$ to denote complete
  attribute valuations.

\end{definition}

\begin{notation}

  As we'll have many layers of indices, we adopt the convention that \$ means ``last possible
  index'' for the indicated vector index.

\end{notation}

\begin{definition}

  All attributes are assumed to belong to an \emph{attribute class} and there is a partial order
  between the attribute classes (discussed later). A vector $\ov{a}$ of attributes is in
  \emph{attribute-ascending} (\emph{attribute-descending}) order if each non-first attribute belongs
  to a class that compares greater (less) or equal to the preceeding attribute in the vector.

\end{definition}

\begin{definition}

  The \emph{synthesis fall-back needs rule} for a value attribute $a$ is
  \begin{equation}
    \kw{priority}~\text{N-$a$}(\#\,{↑}a(\#\text{a})\,{↕}\text{\#as})
    → \#\,{↕}\text{\#as}
  \end{equation}
  and for a map attribute $a$ is
  \begin{equation}
    \kw{priority}~\text{N-$a$}(\#\,{↑}a\{\}\,{↕}\text{\#as})
    → \#\,{↕}\text{\#as}
  \end{equation}
  The N-$a$ symbol is called the \emph{synthesis need function} for~$a$.

\end{definition}

\begin{definition}

  A rule is a \emph{pure synthesis rule} if it has the shape
  %% 
  \begin{equation}
    d\left(\,
      [\ov{v_{i.1}}]t_{i.1}\,\ov{{↑}a_{i.1}} ⇒ ε
      \,,…,\,
      [\ov{v_{i.\$}}]t_{i.\$}\,\ov{{↑}a_{i.\$}} ⇒ ε
      \,\right) ~ ε ⇒ \ov{{↑}a_{i.0}}
  \end{equation}
  %% 
  where the vector $\ov{{↑}a_{i.0}}$ is not empty. We assume that all vectors are in
  attribute-ascending order.

  The \emph{pure synthesis-need rules} for a pure synthesis rule as above are
  %% 
  \begin{align*}
    \text{N-$a_{i.0.1}$}(d(\#)\,{↕}\text{\#as})
    &→ \text{C-$d$-$i$}\bigl(d\bigl(\,
    [\ov{v_{i.1}}] \text{N-$a_{i.1.\$}$}(…(\text{N-$a_{i.1.1}$}(t_{i.1})))
    \,,…,\,
    [\ov{v_{i.\$}}] \text{N-$a_{i.\$.\$}$}(…(\text{N-$a_{i.\$.1}$}(t_{i.\$})))
    \,\bigr)\,{↕}\text{\#as}\bigr)
    \\[-1ex]
    &~\vdots
    \\
    \text{N-$a_{i.0.\$}$}(d(\#)\,{↕}\text{\#as})
    &→ \text{C-$d$-$i$}\bigl(d\bigl(\,
    [\ov{v_{i.1}}] \text{N-$a_{i.1.\$}$}(…(\text{N-$a_{i.1.1}$}(t_{i.1})))
    \,,…,\,
    [\ov{v_{i.\$}}] \text{N-$a_{i.\$.\$}$}(…(\text{N-$a_{i.\$.1}$}(t_{i.\$})))
    \,\bigr)\,{↕}\text{\#as}\bigr)
  \end{align*}
  %%
  (note that the synthesis-need function wrappers are backwards).

  The \emph{pure synthesis-collect rule} for the above pure synthesis rule is
  %% 
  \begin{equation*}
    \text{C-$d$-$i$}\left(\,d\bigl(
      [\ov{v_{i.1}}]t_{i.1}\,\ov{{↑}a_{i.1}}
      \,,…,\,
      [\ov{v_{i.\$}}]t_{i.\$}\,\ov{{↑}a_{i.\$}}
      \,\bigr)\,{↕}\text{\#as}\right)
    → 
    d\bigl(\, [\ov{v_{i.1}}]t_{i.1} \,,…,\, [\ov{v_{i.\$}}]t_{i.\$} \,\bigr)\, \ov{{↑}a_{i.0}}\,{↕}\text{\#as}
  \end{equation*}
  %%
  where the C-$d$-$i$ function symbol is called the \emph{synthesis collector function} for the pure
  synthesis rule.
  %Note that if all the inner terms $t_{i.j}$ are meta-applications and the
  %corresponding vectors $\ov{{↑}a_{i.j}}$ are empty then the synthesis-collect can be inlined.

\end{definition}

\begin{definition}
  A rule is a \emph{pure inheritance rule} if it has the shape
  %% 
  \begin{equation}
    d\left(\,
      [\ov{v_{i.1}}]t_{i.1}\,ε ⇒ \ov{{↓}b_{i.1}}
      \,,…,\,
      [\ov{v_{i.\$}}]t_{i.\$}\,ε ⇒ \ov{{↓}b_{i.\$}}
      \,\right) ~ \ov{{↓}b_{i.0}} ⇒ ε
  \end{equation}
  %% 
  where the vector $\ov{{↓}b_{i.0}}$ is not empty, and each of the vectors
  $\ov{{↓}b_{i.1}}…\ov{{↓}b_{i.\$}}$ and $\ov{{↓}b_{i.0}}$ captures all the attributes of an
  attribute class, which we shall call $B_1,…,B_{\$},B_0$ (respectively).

  The \emph{pure inheritance propagation rule} for such a pure inheritance rule is the following
  %%
  \begin{equation}
    \text{P-$B_0$}\bigl( d\left(
      [\ov{v_{i.1}}]t_{i.1}
      \,,…,\,
      [\ov{v_{i.\$}}]t_{i.\$}
    \right)\,{↕}\text{\#as} \bigr)\, \ov{{↓}b_{i.0}} 
    →
    d\left(
      [\ov{v_{i.1}}]\text{P-$B_1$}(t_{i.1})\ov{{↓}b_{i.1}}
      \,,…,\,
      [\ov{v_{i.\$}}]\text{P-$B_{\$}$}(t_{i.\$})\ov{{↓}b_{i.\$}}
    \right)\ov{{↓}b_{i.0}} \,{↕}\text{\#as}
  \end{equation}
  %%
  It provides one rule for the \emph{attribute class propagation function} P-$B$.

  \TBD{Figure out the attribute class set stuff…}
    
\end{definition}


\section{Inference System Normalization}
\label{app:infer}

Recall~\thetag{\ref{eq:infer}} from Section~\ref{sec:infer}:
%% 
\begin{equation}
  \dfrac
  { ∀\,\ov{x} : (\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,) }
  { P_0 ⇒ C_{n+1}}
  ~(L)
  \tag{\ref{eq:infer}}
\end{equation}

\begin{formalization}
  The \emph{inference simplification system} for the rule \thetag{\ref{eq:infer}} is the system
  %% 
  \begin{align}
    P_0 &→ L_1(P_0, [\ov{x}]C_1) \tag{$L_0$}\\
    L_1(P_0, [\ov{x}]P_1) &→ L_2(P_0, [\ov{x}]P_1, [\ov{x}]C_2) \tag{$L_1$}\\[-\jot]
    &~~\vdots\notag\\
    L_{n-1}(P_0, [\ov{x}]P_1, …, [\ov{x}]P_{n-1}) &→ L_n(P_0, [\ov{x}]P_1, …, [\ov{x}]P_{n-1}, [\ov{x}]C_n) \tag{$L_{n-1}$}\\
    L_n(P_0, [\ov{x}]P_1, …, [\ov{x}]P_n) &→ C_{n+1} \tag{$L_n$}
  \end{align}
  %% 
  (where all symbols, including the variables $\ov{x}$, are the same as in the initial rule). All
  these rules need to be part of the "sort" declaration for the sort of $P_0$ and $C_{n+1}$, along
  with "scheme" declarations for all the introduced $L_i$ symbols.
\end{formalization}

The following develops the details on how this generalizes to multiple inference rules.

\begin{definition}
  %%
  A \HAX \emph{ground sequential inference rule} has the form
  %%
  \begin{equation}
    \dfrac{ M_1 ⇒ P_1 \quad\cdots\quad M_n ⇒ P_n }{ P_0 ⇒ M_{n+1} }
  \end{equation}
  %%
  where $n≥0$ and
  %%
  \begin{enumerate}
  \item $P_0$ (the \emph{initial} pattern) can be any \HAX pattern.
  \item $M_i$ (the \emph{tests}, $1≤i≤n$) are \HAX terms, and are allowed occurrences of
    meta-variables from $P_0…P_{i-1}$.
  \item $P_i$ (the \emph{constraints}, $i>0$) must be \HAX subpatterns.
  \item $M_{n+1}$ (the \emph{conclusion}) is allowed occurrences of all meta-variables.
  \end{enumerate}
  %%
  An inference rule with $n=0$ is called an \emph{axiom}, with $n>0$ a \emph{proper inference}.
  %%
  The $M_i⇒P_i$ over the line are called \emph{premise judgments}. The $P_0⇒M_{n+1}$ under the line
  is called the \emph{conclusion judgment}.
  %%
  Below we will vary the indexing scheme to capture various enumerations of sets of inference rules.
\end{definition}

\begin{definition}[pattern family]\label{def:patfam}
  Consider a set of ground sequential inference rules.  Such a set can obviously be indexed by the
  distinct initial patterns into families of rules
  \begin{displaymath}
    \dfrac{ M_{ij1} ⇒ P_{ij1} \cdots M_{ijn_{ij}} ⇒ P_{ijn_{ij}} }{ P_i ⇒ M_{ij} } ~(L_{ij})
  \end{displaymath}
  where all the $P_i$ used to index the family are pairwise distinct.  The groups obtained in this
  way are a \emph{pattern family}.
\end{definition}

\begin{definition}[leftmost matching]
  Consider a pattern family as in Definition~\ref{def:patfam}.  The family is said to be
  \emph{leftmost matching} if the group of rules for each $P_i$ satisfies one of the following
  conditions:
  \begin{itemize}
  \item either the family contains a single axiom, \ie, $1≤j≤1$ with $n_{ij}=0$,
  \item or the family contains only proper inferences, \ie, $1≤j≤m_i$ with $n_{ij}>0$.
  \end{itemize}
\end{definition}

%% Sub-index each non-axiom $P_i$-group by leftmost premise construction into sub-families of
%%    the form
%%    \begin{displaymath}
%%      \dfrac{ M_{ij} ⇒ P_{ijk1} \quad M_{ijk2} ⇒ P_{ijk2} \quad\cdots\quad M_{ijkn_{ijk}} ⇒ P_{ijkn_{ijk}} }{ P_i ⇒ T_{ijk} }
%%    \end{displaymath}
%%    where all the $T_{ij}$ used to index the sub-family within a $P_i$-group are pairwise disjoint.

\begin{definition}[left-operations]
  Given a leftmost-matching pattern family. Each $P$-indexed group of proper inference rules will
  have the following form:
  \begin{displaymath}
    \dfrac{ T_{j1} ⇒ P_{j1} \quad T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ P ⇒ T_j } ~ (L_j)
  \end{displaymath}
  with one $j$ per rule in the family, which is by definition non-empty ($1≤j≤n$) and contains only
  proper inferences ($n_j≥1$).
  %%
  \begin{enumerate}

  \item Given a label $L$, the \emph{left-flattening} rewrite rules of the group are
    %% 
    \begin{align*}
      L(P) &→ L'(T_{11}, …,T_{n1}, P) \\[\jot]
      L'(P_{11}, m_2, …, m_n, P) &→ L_1(P, P_{11}) \\[-\jot]
      &~\vdots\\
      L'(m_1, …, m_{n-1}, P_{n1}, P) &→ L_n(P, P_{n1})
    \end{align*}
    %% 
    with $L'$ a fresh symbol associated with the group and the $m_j$ fresh meta-variables.

  \item The \emph{left-eliminated} rules for the group are the rules
    \begin{displaymath}
      \dfrac{ T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ L_j(P, P_{j1}) ⇒ T_j } ~ (L'_j)
    \end{displaymath}
    with the $L'_j$ fresh labels derived from the $L_j$ labels.

  \end{enumerate}
\end{definition}

\begin{definition}[left-unfolded]
  Given a leftmost-matching pattern family and consider the proper inference rule group indexed by
  $P$. The following system is the \emph{left-unfolded} inference system for the $P$-indexed group:
  \begin{enumerate}

  \item The left-flattening rewrite rules of the group for a fresh~$L$.

  \item The new inference rule (which refers to the rewrite rules)
    \begin{displaymath}
      \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m } ~ (L)
    \end{displaymath}

  \item The left-eliminated inference rules (which may be axioms or proper inferences).

  \end{enumerate}
\end{definition}

\begin{proposition}
  Given a set of ground sequential inference rules, which is a leftmost-matching pattern
  family. Pick one group of proper inference rules, indexed by the initial pattern $P$. The original
  system and the system where the group has been replaced with the left-unfolded group have the same
  normal forms.
\end{proposition}
\begin{proof}
  Easy: full proof tree before corresponds to proof tree after with simple conversion of the
  eliminated eliminated premise to an application of the new rule and a single use of the rewrite
  rule.
\end{proof}

Note that we can only prove that full ``big-step'' evaluations are equivalent: the new rules may
``get stuck'' in interesting ways (\TBD{example with overlapping patterns}).

\begin{lemma}
  Start with any leftmost matching ground sequential inference rule system and apply left-unfolding
  repeatedly except on axioms and the introduced inference rules
  \begin{displaymath}
    \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m }
  \end{displaymath}
  The resulting system has the same normal forms as the original system.
\end{lemma}

To finish the transform from inference rules to \HAX rules we need two additional notions.

\begin{definition}
  An inference system is \emph{rooted} if it has one rule that occurs as the root rule of every
  proof tree.
\end{definition}

\begin{definition}
  A leftmost-matching ground sequential inference rule system is \emph{left deterministic} if the
  left-flattening 
\end{definition}

\begin{theorem}
  A rooted and leftmost matching ground sequential inference system can be implemented by a rewrite
  system \TBD{fix the details!!}
\end{theorem}


\bibliography{crs}

\end{document}


%%---------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% TeX-master: t
% End:
