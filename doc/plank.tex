\documentclass[letterpaper,11pt]{article}
\input{setup}
\usepackage{cite}
\usepackage{stmaryrd}

%% Style.
\usepackage{charter}
\bibliographystyle{plain}
\usepackage[margin=1in]{geometry}

%% Topmatter.
\title{ \hax: a Core for Higher-order Attribute Contraction Schemes }
\author{ Kristoffer H. Rose \\
 Two Sigma Investments
 \and
 \textcolor{red}{Cynthia, Lionel, others} \\
 Where are you?
}

\begin{document}
\maketitle

\begin{abstract}\noindent
  %%
  We present \hax, a core calculus that can serve as the foundation (or ``reduced plank'') for the
  \HAX (Higher-order Attribute Contraction Schemes) and \CRSX (Combinatory Reductions Systems with
  eXtensions) compiler specification languages.
  %%
  Formally, \hax is a general higher order rewriting formalism extended with first class
  \emph{environments}, and equipped with a parametric polymorphic type system.
  %%
  In this paper we give the formal definition of the \hax calculus and its type system, and we show
  how the central constructs of the much richer \HAX and \CRSX formalisms can be represented in
  \hax. We also outline how \hax can be implemented, and summarize central properties of the system.
  %%
\end{abstract}

%------------------------------------------------------------------------

\section{Introduction}\label{sec:intro}

Several systems that manipulate programs, so-called \emph{meta-programming} systems, have emerged
over the years, ranging from generic specification languages, where the goal is not to define how
but only declare the semantics of the program manipulation, all the way to tools that support
specific aspects of program execution or compiler generation.

One direction has been to use a combination of \emph{higher order
  rewriting}~\cite{Jouannaud:klop2005} combined with \emph{higher order abstract syntax} (HOAS)
\cite{PfenningElliot:pldi1988}. This approach is used by \CRSX (Combinatory Reduction Systems with
eXtensions)~\cite{Rose:1996}, developed for writing industrial compilers at IBM
Research~\cite{Rose:hor2010,Rose:rta2011,dp60:ibm2013}, and the derived system \HAX (Higher-order
Attribute Contration Schemes)~\cite{Rose:ts2015}, developed to teach compiler construction at
NYU~\cite{RoseRose:cims2015}.

However, the direct implementation of the full \CRSX language~\cite{crsx} turned out to be quite
complex, and over time we have developed notions of what the ``core'' elements of the language
are. At the same time, \HAX has highlighted what additional programming paradigms one should add to
get a more useful programming language for writing compilers.

\TBD{Example of complex feature that can be simplified.}

The \hax calculus, presented here, represents the synthesis or what we have found to be the
essential features of a system for implementing most features of compilers.

\TBD{Plan}%
and finally Section~\ref{sec:conc} concludes and compares to related work.

%------------------------------------------------------------------------

\section{\bhax Overview}
\label{sec:overview}

In this section we outline the \hax calculus, with a minimal syntax that supports the \HAX source
language.

\begin{figure*}[ht]
  \begin{align}
    \tag{Declaration}
    D &::= \kw{sort}~S\,\kw\{\, F^*\,\kw\}
    \bigm| \kw{attribute}~a~\kw\{\,S\,\kw:\,S\,\kw\}\,\kw;
    \\[\jot]
    \tag{Form}
    F &::= \kw{data}~c\,\kw(\,\set{BF}^{*\kw,}\,\kw)~a^*\,\kw;
    \bigm| \kw{scheme}~f\,\kw(\,\set{BF}^{*\kw,}\,\kw)~a^*\,\kw;
    \bigm| \kw{variable}\,\kw;
    \bigm| O~\kw{rule}~T~\kw{$→$}~T\,\kw;
    \\
    \tag{BindersForm}
    \set{BF} &::= \kw[\,S^{*\kw,}\,\kw]\,S
    \\
    \tag{Sort}
    S &::= s\,\kw[\,S^{*\kw,}\,\kw]
    \bigm| α
    \\
    \tag{Option}
    O &::= ~\mid \kw{default} 
    \\[\jot]
    \tag{Term}
    T &::= c\,\kw(\,B^{*\kw,}\,\kw)~A^*
    \bigm| v ~ A^*
    \bigm| M\,\kw[\,T^{*\kw,}\,\kw]~A^*
    \\
    \tag{Binders}
    B &::= \kw[\,v^{*\kw,}\,\kw]\,T
    \\
    \tag{Attribute}
    A &::= a~\set{V}
    \\
    \tag{Value}
    \set{V} &::= \kw\{\,T\,\kw:\,T\,\kw\}
    \bigm| \kw\{\kw\}
    \bigm| \kw\{\,\kw{$¬$}\,T\,\kw\}
    \bigm| \kw\{\kw:\,M\,\kw\}
  \end{align}
  \caption{\hax syntax.}
  \label{fig:plank}
\end{figure*}

\begin{definition}[\hax]
  %%
  The \hax grammar is shown in Figure~\ref{fig:plank}. The top level of a \hax script is a sequence
  of declarations $D^*$, and the grammar assumes that we have three categories of tokens defined:
  %%
  \begin{itemize}

  \item $s,f,c$ stand for \emph{constructor} tokens, which are capitalized words like "Integer" or
    "A" or "CamelCaseWord", used for sort, function symbol, and data symbol names (respectively).

  \item $v,a,α$ stand for \emph{variable} tokens, which are lower case words like "x" or "foo" or
    even "lowWord", used for term variables, attributes, and sort variables (respectively).

  \item $M$ stands for \emph{meta-variable} tokens, which are tokens that start with "#" like "#arg"
    or "#BigFoot" or even just "#1" or merely~"#".

  \end{itemize}
  %%
  The ``$A^{*\kw,}$'' notation means zero or more $A$s separated by commas. In addition, we define
  the following:
  %%
  \begin{itemize}

  \item A term of the form $c(B_1,…,B_n)A_1…A_m$ ($m,n≥0$) is called a \emph{construction}; if
    furthermore the top symbol $c$ is declared with a "scheme c…" declaration then it is called a
    \emph{function construction}.

  \item A term of the form $v\,A_1…A_m$ ($m≥0$) is a \emph{variable occurrence}; if the variable $v$
    occurs contained in a binder $[…v…]T$ then the variable occurrence is \emph{bound}.

  \item A term of the form $M[T_1,…,T_n]A_1…A_m$ ($m,n≥0$) is a \emph{meta-application}; if the
    terms $T_i$ are distinct bound variable occurrences then this is a \emph{pattern
      meta-application}.

  \item A term is called a \emph{pattern fragment} if all contained meta-applications are pattern
    meta-applications, and a \emph{pattern} if it is also a function construction.

  \end{itemize}
  %%
\end{definition}

\begin{figure*}[p]
  %%
  \begin{hacs}[numbers=right,texcl]
sort N[] {                                                        // natural number sort
 data Z() ;                                                       // zero
 data S([]N[]) ;                                                 // successor
 scheme Plus([]N[], []N[]) ;                                    // $+$ operator
 rule Plus([]Z(), []#2[]) →  #2[] ;                             // $0+x = x$
 rule Plus([]S([]#1[]), []#2[]) →  S([]Plus([]#1[], []#2[])) ;  // $(1+x)+y=1+(x+y)$
}
  \end{hacs}
  \vspace*{-1em}
  \caption{Peano numerals in \hax.}
  \label{fig:peano}
  %%
  \vspace{1em}
  \begin{hacs}[numbers=right,texcl]
sort Λ[] {                                                       // sort of λ terms
 variable ;                                                      // permit variables
 data Lm([Λ[]]Λ[]) ;                                            // abstraction
 scheme Ap([]Λ[], []Λ[]) ;                                      // application
 rule Ap([]Lm([x]#body[x]), []#arg[]) → #body[#arg[]] ;   // β-reduction
}
  \end{hacs}
  \vspace*{-1em}
  \caption{Untyped λ calculus in \hax.}
  \label{fig:lambda}
  %%
  \vspace{1em}
  \small
  \begin{hacs}[numbers=right,texcl]
sort List[α] { data Nil(); data Cons([]α, []List[α]);
 scheme Appnd([]List[α], []List[α]);
 rule Appnd([]Nil(), []#2[]) →  #2[];
 rule Appnd([]Cons([]#11[], []#12[]), []#2[]) →  Cons([]#11[], Appnd([]#12[], []#2[]));
 scheme Map([β]α, []List[β]);
 rule Map([x]#[x], []Nil()) →  Nil();
 rule Map([x]#[x], []Cons([]#1[], []#2[])) →  Cons([]#[#1[]], Map([x]#[x], []#2[]));
}
  \end{hacs}
  \vspace*{-1em}
  \caption{Polymorphic lists in \hax.}
  \label{fig:list}
  %%
  \vspace{1em}
  \begin{hacs}[numbers=right,texcl]
sort Dummy[] { variable; }
attribute val {Dummy[] : Bool[]};
sort Bool[] { data T() val; data F() val;
 data Not([]Bool[]) val; data Or([]Bool[], []Bool[]) val;

 scheme Eval1([]Dummy[], []Bool[]); scheme Eval2([]Dummy[], []Bool[]);
 rule Eval1([]d, []T()) → T() val{d:T()};
 rule Eval1([]d, []F()) → F() val{d:F()};

 rule Eval1([]d, []Not([]#[])val{¬d}) → Eval2([]d, []Not([]Eval1([]d, []#[])));
 rule Eval2([]d, []Not([]#[]val{d:T()})) → Not([]#[]) val{d:F()};
 rule Eval2([]d, []Not([]#[]val{d:F()})) → Not([]#[]) val{d:T()};

 rule Eval1([]d, []Or([]#1[], []#2[])val{¬d})
   → Eval2([]d, []Or([]Eval1([]d, []#1[]), Eval1([]d, []#2[])));
 rule Eval2([]d, []Or([]#1[]val{d:F()}, []#2[]val{d:#v2[]})) → Or([]#1[], []#2[])val{d:#v2[]};
 rule Eval2([]d, []Or([]#1[]val{d:T()}, []#2[])) → Or([]#1[], []#2[]) val{d:T()};

 scheme Eval([]Bool[]); rule Eval([]#[]) →  Eval1([]dummy, []#[]);
}
  \end{hacs}
  \vspace*{-1em}
  \caption{Boolean \emph{value} attribute synthesis in \hax.}
  \label{fig:bool}
  %%
\end{figure*}

\begin{example}[Peano]\label{ex:peano}
  The classical first order Peano arithmetic rules are a simple \hax system, shown in
  Figure~\ref{fig:peano}.  The example illustrates how a sort is defined with data constructors and
  a scheme for rewriting, essentially following standard notations for many-sorted term rewriting,
  except for the slightly unusual (meta)variable notation with "#"s. The example illustrates the
  following points:
  %%
  \begin{itemize}

  \item The defined sort is "N", written "N[]", as it has no sort parameters. All the other
    declarations define artifacts of the "N" sort, so are inside the \kw{sort} declaration's
    \kw{\{\}}s.

  \item There are two \kw{data} constructors: "Z" with no parameters, and "S" with a single numeric
    argument. The single numeric argument is specified as "[]N[]" because it has no locally scoped
    binders ("[]"$_-$) and the "N" sort has no sort parameters ($_-$"[]").

  \item There is a single function (\kw{scheme}) constructor: "Plus" with two numeric arguments.

  \item There are two \kw{rule}s for the function symbol, implementing the usual Peano addition rules.

  \end{itemize}
  %%
  A sample rewrite sequence using this system, corresponding to the computation $1+1=2$, is
  %%
  \begin{displaymath}
    "Plus([]S([]Z()), []S([]Z()))" →
    "S([]Plus([]Z(), []S([]Z())))" →
    "S([]S([]Z()))"
  \end{displaymath}
\end{example}

\begin{remark}
  One difference between the CRSX family, including \hax, and other higher order rewriting
  formalisms, is that the binder mechanism is part of the parent construction, \eg, the sort of the
  "S" constructor defines that instances must have the shape "S([]…)" with "…" being itself a Peano
  number.  Otherwise, binding and substitution are in the style of CRS higher order rewrite
  systems~\cite{Klop+:tcs1993}.\footnote{The notation does differ from the original CRS notation in
    that we use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$,
    and we use square brackets for substitution variables instead of round.}
\end{remark}

\begin{example}[untyped λ calculus]\label{ex:lambda}
  The untyped λ calculus is shown in Figure~\ref{fig:lambda} in \hax.  The declarations can be
  explained as follows:
  %%
  \begin{itemize}

  \item The "Λ" sort includes a special "variable" case to indicate that variables can occur in
    terms.

  \item "Λ" also includes a usual case for application construction, which is a "scheme" because it
    can (sometimes) be rewritten.

  \item "Λ" includes an abstraction construction, which is a "data" case, and which includes a
    subterm with a single binder scoped over that subterm. The scoped subterm is written as
    "[Λ[]]Λ[]", which should be read as ``a subterm with a locally bound variable of sort "Λ" and a
    body of sort "Λ" in which it can occur.''

  \item We specify one rewrite "rule" for "Λ": β-reduction. As usual, the rule specifies how an
    application of an abstraction is simplified. The interesting aspect of the pattern is how the
    abstraction is matched: the part of the pattern "[x]#body[x]" means ``the scoped subterm with
    binder "x" and subterm "#bind" wherein "x" may occur.'' Note the similarity to the declaration
    of the subterm of the "Lm" constructor.

  \item Once an application of an abstraction is matched, the "rule" gives the result of
    simplification as "#body[#arg[]]", which means that we construct a copy of "#body" except all
    occurrences of the variable we matched in the pattern "#body[x]" is substituted with what
    "#arg[]" matched.

  \end{itemize}
  %%
  A usual λ term like $(λx.x x)(λy.y)$ is represented as
  \begin{displaymath}
    "Ap([]Lm([x]Ap([]x, []x)), []Lm([y]y))"    
  \end{displaymath}
  and simplifies like this:
  %%
  \begin{displaymath}
    "Ap([]Lm([x]Ap([]x, []x)), []Lm([y]y))" →
    "Ap([]Lm([y]y), []Lm([y]y))" →
    "Lm([y]y))"
  \end{displaymath}
  %%
\end{example}

\begin{example}[lists]\label{ex:list}
  Figure~\ref{fig:list} shows a standard definition of polymorphic lists over an arbitrary element
  sort.
  %%
  \begin{itemize}

  \item The target sort is "List[α]" which is a usual polymorphic way to express a list of members
    of an unspecified parameter sort~"α".

  \item Inside the scope of the "sort" declaration, "α" denotes the member sort of the result list
    of all constructs. So the declaration of "data Cons([]α, []List[α])" means that the "Cons"
    constructor takes one argument of the same sort as the member of the result list, as well as an
    argument of the same sort as the result, "List[α]".

  \end{itemize}
  %%
  \TBD{Example evaluation.}
  %%
\end{example}

\begin{example}[Boolean formulae]\label{ex:bool}
  Figure~\ref{fig:bool} shows how a Boolean expression can be annotated with an attribute "val",
  which has the computed logical value of the expression. Because \hax has no automatic propagation
  of attributes, the annotations are generated by helper "Eval1" and "Eval2" schemes.
  %%
  Line~1 sets up a "Dummy" sort for a dummy key variable for maps. %
  Line~2 sets up an attribute "val", which maps ``dummy variables'' to "Bool" values. %
  Lines 3~and 4 set up the "Bool" sort with data constructors for the Boolean expressions true
  ("T"), false ("F"), negation ("Not"), and disjunction ("Or"). %
  Line~6 declares the "Eval1" and "Eval2" schemes, which take a dummy variable and a Boolean term
  (and forms a Boolean term by being defined inside the "sort Bool").  %
  Lines 7~and 8 define the "Eval1" scheme on the two trivial cases: literal thruth values are
  annotated with a "val" that maps the dummy variable to the truth value. %
  Lines 10~through 12 define the "Eval1" scheme for negation. %
  The first rule in line~10 expresses that "Eval1" can rewrite a "Not" term where the "val"
  attribute does \emph{not} have a binding for the dummy variable: in that case, the result is
  obtained by applying the "Eval1" scheme recursively to the negated subterm and allowing the full
  negation to be ``postprocessed'' by the "Eval2" scheme. %
  Lines 11~and 12 give the details for how this works: once a negation term is obtained that has an
  actual "val" attribute, then the "Eval2" scheme can rewrite the term to one where the negated
  value is assigned to the negation term. %
  Similarly, Lines 14~through 17 give rules for evaluating a disjunction. %
  Finally, line~19 defines a root scheme that annotates an entire Boolean term by creating a "dummy"
  variable and then passing control to "Eval1".

  Here is a possible simplification using this scheme to annotate a term corresponding to the
  logical formula $(¬F)∨T$:
  %%
  \begin{hacs}
    Eval([]Or([]Not([]F()), []T()))
    →  Eval1([]d, []Or([]Not([]F()), []T()))
    →  Eval2([]d, []Or(Eval1([]d, []Not([]F())), Eval1([]d, []T())))
    →  Eval2([]d, []Or(Eval1([]d, []Not([]F())), []T()val{d:T()}))
    →  Eval2([]d, []Or(Eval2([]d, []Not(Eval1([]d, []F()))), []T()val{d:T()}))
    →  Eval2([]d, []Or(Eval2([]d, []Not([]F()val{d:F()})), []T()val{d:T()}))
    →  Eval2([]d, []Or([]Not([]F()val{d:F()})val{d:T()}, []T()val{d:T()}))
    →  Or([]Not([]F()val{d:F()})val{d:T()}, []T()val{d:T()})val{d:T()}
  \end{hacs}%
  %%
  The final term has every subterm annotated with its logical value.
  %%
\end{example}

\TBD{Summarize unexplained features, like default rules.}

%------------------------------------------------------------------------

\section{\bhax Rewriting}
\label{sec:rewriting}

In this section we formally define rewriting in the \hax calculus.

\TBD{mv, fv, substitution, rewriting.}


%------------------------------------------------------------------------

\section{\bhax Typing}
\label{sec:typing}

\begin{notation}
  We will use \emph{vector notation} with $\ov{X}$ denoting $X_1,…,X_n$ for some $n≥0$; $ε$ denotes
  all empty vectors. We use $·$ (dot) for vector \emph{catenation}, including adding single new
  elements, and will freely abuse this notation and in particular write $\ov{[\ov{x}]x}$ as an
  abbreviation of $[x_{11}…x_{1m_1}]x_1…[x_{n1}…x_{nm_n}]x_n$ for suitable $n,m_1,…,m_n ≥ 0$.
\end{notation}

\begin{figure*}[p]\small
  \begin{gather*}
    %
    \intertext{\shoveright{Sorting of Declarations\hfil\fbox{$ Γ ⊢ D $}}}
    %
    \dfrac
    { Γ, S ⊢ \ov{F} }
    { Γ ⊢ \kw{sort}~S\,\kw\{\, \ov{F} \,\kw\} }
    % 
    \\[\jot]
    % 
    \dfrac
    { }
    { Γ ⊢ \kw{attribute}~a~\kw\{\,S_1\,\kw:\,S_2\,\kw\}\,\kw; }
    \quad Γ(a) = \{S_1{:}S_2\};~ \op{KeySort}(S_1)
    % 
    \\[\jot]
    %
    \intertext{\shoveright{Sorting of Forms\hfil\smash{\fbox{$ Γ,S ⊢ F $}}}}
    %
    \dfrac
    { }
    { Γ,S ⊢ \kw{data}~c\,\kw(\,\ov{\set{BF}}\,\kw)~\ov{a}\,\kw; }
    \quad Γ(c) = [\ov{\set{BF}},\ov{a}⇒S];~ \op{DataAtts}\{\ov{a}\} ∈ Γ(S)
    % 
    \\[\jot]
    %
    \dfrac
    { }
    { Γ,S ⊢ \kw{scheme}~f\,\kw(\,\ov{\set{BF}}\,\kw)~\ov{a}\,\kw; }
    \quad Γ(c) = [\ov{\set{BF}},\ov{a}⇒S]
    % 
    \\[\jot]
    %
    \dfrac
    { }
    { Γ,S ⊢ \kw{variable}\,\kw; }
    \quad \op{Var}∈Γ(S)
    % 
    \\[1ex]
    %
    \dfrac
    { Γ,Δ[\op{Pattern}] ⊢ T_1 : S \qquad Γ,Δ[\op{Contract}] ⊢ T_2 : S }
    { Γ,S ⊢ O~\kw{rule}~T_1~\kw{$→$}~T_2\,\kw; }
    % 
    \\[\jot]
    %
    \intertext{\shoveright{Sorting of Terms\hfil\smash{\fbox{$ Γ,Δ ⊢ T : S $}}}}
    %
    \dfrac
    { Γ,Δ ⊢ \ov{B} : \ov{\set{BF}} \qquad Γ,Δ,\{\ov{a}\} ⊢ \ov{A} }
    { Γ,Δ ⊢ c\,\kw(\,\ov{B}\,\kw)\,\ov{A} : S }
    \quad Γ(c) = [\ov{\set{BF}},\ov{a}⇒S]
    % 
    \\[\jot]
    %
    \dfrac
    { Γ,Δ,\{\ov{a}\} ⊢ \ov{A} }
    { Γ,Δ ⊢ v \, \ov{A} : S }
    \quad Δ(v) = S;~ \op{DataAtts}\{\ov{a}\} ∈ Γ(S);~ \op{Var}∈Γ(S)
    % 
    \\[\jot]
    %
    \dfrac
    { Γ,Δ ⊢ \ov{T} : \ov{S} \qquad Γ,Δ,\{\ov{a}\} ⊢ \ov{A} }
    { Γ,Δ ⊢ M\,\kw[\,\ov{T}\,\kw] \, \ov{A} : S }
    \quad Δ(M) = [\ov{S}⇒S]~; \op{DataAtts}\{\ov{a}\} ∈ Γ(S)
    % 
    \\[\jot]
    %
    \intertext{\shoveright{Sorting of Binder\hfil\smash{\fbox{$ Γ,Δ ⊢ B : \set{BF} $}}}}
    %
    \dfrac
    { Γ,Δ[\ov{v}↦\ov{S}] ⊢ T : S }
    { Γ,Δ ⊢ \kw[\,\ov{v}\,\kw]\,T : \kw[\,\ov{S}\,\kw]\,S }
    %
    \\[\jot]
    %
    \intertext{\shoveright{Sorting of Attribute\hfil\smash{\fbox{$ Γ,Δ,\{\ov{a}\} ⊢ A $}}}}
    %
    \dfrac
    { Γ,Δ ⊢ V : \{S_1{:}S_2\} }
    { Γ,Δ,\{\ov{a}\} ⊢ a\,V }
    \quad a∈\{\ov{a}\};~ Γ(a) = \{S_1{:}S_2\}
    %
    \\[\jot]
    %
    \intertext{\shoveright{Sorting of Attribute Value\hfil\smash{\fbox{$ Γ,Δ ⊢ A : \{S:S\} $}}}}
    %
    \dfrac
    { Γ,Δ ⊢ T_1 : S_1 \qquad Γ,Δ ⊢ T_2 : S_2 }
    { Γ,Δ ⊢ \kw\{\,T_1\,\kw:\,T_2\,\kw\} : \{S_1{:}S_2\} }
    %
    \qquad
    %
    \dfrac
    { }
    { Γ,Δ ⊢ \kw\{\kw:\,M\,\kw\} : \{S_1{:}S_2\} }
    ~ Δ({:}M) = \{S_1{:}S_2\}
    %
    \\[\jot]
    %
    \dfrac
    { Γ,Δ ⊢ T : S_1 }
    { Γ,Δ ⊢ \kw\{\,\kw{$¬$}\,T\,\kw\} : \{S_1{:}S_2\} }
    ~ \op{Pattern}∈Δ
    % 
    \qquad
    %
    \dfrac
    { }
    { Γ,Δ ⊢ \kw\{\kw\} : \{S_1{:}S_2\} }
    ~ \op{Contract}∈Δ
    %
  \end{gather*}
  \caption{\hax type rules.}
  \label{fig:typerules}
\end{figure*}

\begin{definition}
  %%
  The rules in Figure~\ref{fig:typerules} give the type rules for~\hax.

  \TBD{Explain all the environments and judgments.}
\end{definition}

\TBD{Example type derivation.}

\begin{theorem}[subject reduction]
  A well-sorted term can only rewrite to a well-sorted term.
\end{theorem}

%------------------------------------------------------------------------

\section{Implementing \hax}
\label{sec:implement}

In this section we give a brief summary of how we see \hax implemented.

\TBD{Struct for nodes, reference counting, lazy free variable lists, dispatchify.}

%------------------------------------------------------------------------

\section{Supporting Compiler Paradigms}
\label{sec:compiling}

In this section we outline how the standard compiler construction idioms of the full \HAX language
translate into~\hax.

\begin{definition}[higher order inference rule]\label{def:infer}%
  %%
  A (higher order) \emph{inference rule} has the form
  %%
  \begin{displaymath}
    \dfrac
    { ∀\,\ov{x} : (\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,) }
    { P_0 ⇒ C_{n+1}}
    ~(L)
  \end{displaymath}
  %%
  where
  %%
  \begin{itemize}
  \item $L$ is the unique name of the rule.
  \item $P_0$ and all of $C_1,…,C_n$ are \emph{function constructions}.
  \item $P_0$ is a \emph{pattern} and all of $P_1,…,P_n$ are \emph{pattern fragments}.
  \item $∀i : \op{mv}(C_i) ⊆ \op{mv}(P_0…P_{i-1})$.
  \end{itemize}
  %%
  The \emph{inference simplification system} for the above rule is the system
  %%
  \begin{align}
    P_0 &→ L_1(P_0, [\ov{x}]C_1) \tag{$L_0$}\\
    L_1(P_0, [\ov{x}]P_1) &→ L_2(P_0, [\ov{x}]P_1, [\ov{x}]C_2) \tag{$L_1$}\\[-\jot]
    &~~\vdots\notag\\
    L_{n-1}(P_0, [\ov{x}]P_1, …, [\ov{x}]P_{n-1}) &→ L_n(P_0, [\ov{x}]P_1, …, [\ov{x}]P_{n-1}, [\ov{x}]C_n) \tag{$L_{n-1}$}\\
    L_n(P_0, [\ov{x}]P_1, …, [\ov{x}]P_n) &→ C_{n+1} \tag{$L_n$}
  \end{align}
  %%
  (where all symbols, including the variables $\ov{x}$, are the same as in the initial rule). All
  these rules need to be part of the "sort" declaration for the sort of $P_0$ and $C_{n+1}$, along
  with "scheme" declarations for all the introduced $L_i$ symbols.
  %%
\end{definition}

\begin{example}
  \TBD{Example inference simplification.}
\end{example}

We can prove that the inference simplification system for an inference rule implements the same
semantics for non-overlapping $P_0$s. Even with an identical prefix $P_0,\ov{x},C_1$ for two rules,
the system can be generated: in that case the two $L_1$ symbols of the rules must be aliased to a
common function symbol; in general $L_1…L_k$ must be collapsed for identical prefixes
$P_0,\ov{x},C_1,P_1, C_2,…,P_{k-1}, C_k$. \TBD{Explain?}

\begin{definition}[synthesized attributes]\label{def:synth}%
  %%
  A \emph{singleton synthesis rule} has the shape
  %%
  \begin{displaymath}
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{{↑}a_i\{{\cdots}\}}$\\
          $M_i[{\cdots}]\,{{↑}a_i\{{\cdots}\}}$
        }}\cdots\biggr)
    ~{{↑}a\{{\cdots}\}}
  \end{displaymath}
  %%
  (with the embedded subterms denoting all such subterms; the ``singleton'' restriction comes from
  the single synthesized attribute on all subterms).

  The \emph{synthesis simplification system} for the synthesis rule is
  %%
  \begin{align*}
    \op{Needs}_a\Biggl(
    c\biggl(\cdots \vcenter{\txt{
        $c_i({\cdots})$\\
        $M_i[{\cdots}]$
      }}\cdots\biggr)
    \Biggr)
    &→
    \op{Collect}\Biggl(
    c\biggl(\cdots \vcenter{\txt{
        $\op{Needs}_{{a_i}}(c_i({\cdots}))$\\
        $\op{Needs}_{{a_i}}(M_i[{\cdots}])$
      }}\cdots\biggr)    
    \Biggr)
    \\[1em]
    \op{Collect}\Biggl(
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{↑}a_i\{{\cdots}\}$\\
          $M_i[{\cdots}]\,{↑}a_i\{{\cdots}\}$
      }}\cdots\biggr)
    \Biggr)
    &→
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{↑}a_i\{{\cdots}\}$\\
          $M_i[{\cdots}]\,{↑}a_i\{{\cdots}\}$
        }}\cdots\biggr)
    ~{↑}a\{{\cdots}\}
  \end{align*}
  %%
\end{definition}

\begin{example}
  \TBD{Example synthesis simplification.}
\end{example}

\TBD{Discuss multiple dependent and independent synthesized attributes, and proof sketch that the
  simplification is correct; also the erasure of not-patterns, and check details from .}

\begin{definition}[inherited attributes]\label{def:synth}%
  %%
  \begin{align*}
    F\bigl(\cdots \vcenter{\txt{
          $A({·})\,{↑}a({·})$\\
          $X[{·}]\,{↑}x({·})$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    \cdots\vcenter{\txt{
        $B({·})\,{↑}b({·})$\\
        $Y[{·}]\,{↑}y({·})$}}
    \cdots\vcenter{\txt{
        $G({·})\,{↓}g({·})$\\
        $Z[{·}]\,{↓}z({·})$}}
    \cdots
    \\
    \intertext{becomes}
    %%
    F\bigl(\cdots \vcenter{\txt{
          $A({·})$\\
          $X[{·}]$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    F'\bigl(\cdots \vcenter{\txt{
          $\op{Needs}_a(A({·}))$)\\
          $\op{Needs}_x(X[{·}])$
        }}\cdots\bigr)
    {↓}c({·})
    \\[1em]
    F'\bigl(\cdots \vcenter{\txt{
          $A({·})\,{↑}a({·})$\\
          $X[{·}]\,{↑}x({·})$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    \cdots\vcenter{\txt{
        $B({·})\,{↑}b({·})$\\
        $Y[{·}]\,{↑}y({·})$}}
    \cdots\vcenter{\txt{
        $G({·})\,{↓}g({·})$\\
        $Z[{·}]\,{↓}z({·})$}}
    \cdots
  \end{align*}
  %% 
\end{definition}



%------------------------------------------------------------------------

\section{Conclusion}
\label{sec:conc}

With \hax, we have presented a rather small calculus that can serve as the underlying formalism for
reasoning about as well as implementing the \CRSX and \HAX languages.

\TBD{What is covered.}

~\cite{Knuth:mst1968} 
~\cite{Aho+:2006}


\paragraph*{Related work.}

We would like to give credit to SIS~\cite{Mosses:daimi1979}, which shares with \hax the use of
\emph{simplification} using a λ-calculus based formalism.

The most prominent system that supports implementation of compilers in formal (rewriting and
attribute grammar) form is ASF+SDF~\cite{Brand+:toplas2002}, which is based on first order
rewriting. While modules have been added for symbol table management, these lack the full
integration and easy way to handle scoped intermediate languages. The successor,
Rascal~\cite{Bos+:eptcs2011} adds a module for HOAS, but Rascal specifications operate in a world of
side effects, which we find hard to reconcile with higher-order term structures (with scopes).

The notion of ``higher-order'' used by \hax is similar to but not quite the same as in higher-order
attribute grammars (HAG)~\cite{VogtSwierstraKuiper:pldi1989}. Like HAGs, \hax specifications permit
constructing and passing of abstract syntax fragments in attributes but the ``higher order'' aspect
of \hax also covers the rewriting side, where we can build parameterized abstractions over any part
of a specification, including with attributes. Indeed, one can use substitution inside attributes,
and have absence of attributes and substitution block rewriting.

\paragraph*{Future work.} \TBD{Speculate!}


\paragraph*{Acknowledgements.} \TBD{Thank everyone.}

EU-funded Marie Skłodowska-Curie ``HORIP'' action collaboration with Cynthia Kop.


%------------------------------------------------------------------------

\bibliography{crs}


\TBD{End of sane part.}
\hrule
\vspace*{1pc}

%------------------------------------------------------------------------
\appendix

\section{Sugar}

\begin{notation}
  %% 
  \HAX permits some additional syntactic sugar:
  %% 
  \begin{itemize}

  \item Empty parenthesis and brackets can be omitted.

  \item The \kw{data} and \kw{rule} keywords can be omitted.

  \item \TBD{Update to simplified syntax.} Sort cases can be written with \kw{\texttt{|}} and without
    \kw{\texttt{\{\}}}…

  \item "attribute" declarations can be combined: $"attribute"~a_1~\set{AF}_1,…, a_n~\set{AF}_n ;$
    is an abbreviation of $"attribute"~a_1~\set{AF}_1;…; "attribute"~a_n~\set{AF}_n;$.

  \item An additional SortCase contruct is allowed:
    \begin{displaymath}
      \kw{template}~P~\kw{$→$}~T\,\kw;  \quad⇒\quad
      \kw{scheme}~P'\,\kw; ~ \kw{\texttt{|}} ~ \kw{data} ~ T'\,\kw; ~ \kw{rule} ~ P~\kw{$→$}~T\,\kw;
    \end{displaymath}
    where $P'$ and $T'$ are variants of $P$ and $P$ that have been cleared of "#"s.

  \item Finally, we rewrite special \emph{synthesis rules}:
    \begin{displaymath}
      c(\,\ov{\set{PB}}\,)~→~\ov{↑a~\set{V}}\,\kw;
      \quad⇒\quad
      \kw{rule}~c(\,\ov{\set{PB}}\,)~→~c(\,\ov{\set{PB}'}\,)~\ov{↑a~\set{V}}\,\kw;
    \end{displaymath}
    where $\set{PB}_i'$ is $\set{PB}_i$ with negative attribute patterns $\{¬{…}\}$ removed.

  \item We rewrite special \emph{inheritance rules}:
    \begin{displaymath}
      c(\,\ov{\set{PB}}\,)~→~\ov{↓v~\set{V}}\,\kw;
      \quad⇒\quad
      \kw{rule}~c(\,\ov{\set{PB'}}\,)~\ov{↓v~\set{V}}~→~c(\,\ov{\set{PB}'}\,)\,\kw;
    \end{displaymath}
    where 

  \item As defined below, every term $f(…)\ov{A}$ for a symbol $f$ defined with
    \begin{displaymath}
      \kw{\texttt{|} scheme}~f\,\kw(…\kw)~\ov{\set{AI}}
    \end{displaymath}
    must include an $A_i$ instance for every attribute defined by some $\set{AI}_i$.  The system
    automatically includes missing inherited attributes as follows:
    \begin{itemize}
    \item In patterns, a missing attribute is inserted as "↓a(#a)" or "↓a{:#a}" as appropriate.
    \item Missing attributes that were defined in the pattern are inserted the same.
    \item Remaining missing attributes must be of a map type and are inserted as~"↓a{}".
    \end{itemize}

  \item We allow two more forms of \set{PA}:
    \begin{displaymath}
      \set{PA} ::= {…} \bigm| \kw{$↑$}\,m \bigm| \kw{$↓$}\,m
    \end{displaymath}
    They expand to all relevant synthesized and inherited attributes, respectively.

  \end{itemize}
\end{notation}

\begin{example}
  With syntactic sugar, we can simplify the Peano example to
  %%
  \begin{hacs}[numbers=right]
    sort N | Z | S(N) | scheme Plus(N, N) ;
    Plus(Z, S(#2)) → #2 ; 
    Plus(S(#1), #2) → S(Plus(#1, #2)) ;
  \end{hacs}
\end{example}

\begin{example}[untyped λ calculus]
  The untyped λ calculus is specified as follows in \hax with syntactic sugar:
  %%
  \begin{hacs}
    sort L | variable | Lm([x]Lam[x as L]) | scheme Ap(L, L) | x ;
    rule Ap(Lm([x]#body[x]), #arg) →  #body[#arg] ;
  \end{hacs}
  %%
  The example shows how binding is declared and used for substitution in the style of CRS
  systems~\cite{Klop+:tcs1993}:\footnote{The notation differs from the original CRS notation in that
    we use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$, and we
    use square brackets for substitution variables instead of round.}
  %%
  (Note that the same example in the (non-raw) full \HAX notation can include a parser for the
  native custom λ calculus syntax:
  %%
  \begin{hacs}
    token ID | [a-z] [a-z0-9_]* ;
    sort V | symbol ⟦⟨ID⟩⟧ ;
    sort L | ⟦λ⟨V binds x⟩.⟨L[x as L]⟩⟧ | scheme ⟦⟨L@1⟩⟨L@2⟩⟧@1
           | ⟦⟨V⟩⟧@2 | sugar ⟦(⟨L#⟩)⟧@2 →  #;
    ⟦ (λx.⟨L#body[x]⟩) ⟨L#arg⟩ ⟧ →  #body[#arg] ;
  \end{hacs}
  %%
  including precedence markers, syntactic sugar, \etc; for details see the full \HAX
  manual. Essentially the syntax-rich example translates to a parser and the former.)
\end{example}

\section{Inference Systems}
\label{sec:infer}

A common notation for specifying program analysis and …

A set of of inference rules is ...

\begin{definition}
  %%
  A \HAX \emph{ground sequential inference rule} has the form
  %%
  \begin{equation}
    \dfrac{ T_1 ⇒ P_1 \quad\cdots\quad T_n ⇒ P_n }{ P_0 ⇒ T_{n+1} }
    \label{eq:infer}
  \end{equation}
  %%
  where $n≥0$ and
  %%
  \begin{enumerate}
  \item $P_0$ (the \emph{initial} pattern) can be any \HAX pattern.
  \item $T_i$ (the \emph{tests}, $1≤i≤n$) are \HAX terms, and are allowed occurrences of meta-variables from $P_0…P_{i-1}$.
  \item $P_i$ (the \emph{constraints}, $i>0$) must be \HAX subpatterns.
  \item $T_{n+1}$ (the \emph{conclusion}) is allowed occurrences of all meta-variables.
  \end{enumerate}
  %%
  An inference rule with $n=0$ is called an \emph{axiom}, with $n>0$ a \emph{proper inference}.
  %%
  The $T_i⇒P_i$ over the line are called \emph{premise judgments}. The $P_0⇒T_{n+1}$ under the line
  is called the \emph{conclusion judgment}.
  %%
  Below we will vary the indexing scheme to capture various enumerations of sets of inference rules.
\end{definition}

\begin{definition}[pattern family]\label{def:patfam}
  Consider a set of ground sequential inference rules.  Such a set can obviously be indexed by the
  distinct initial patterns into families of rules
  \begin{displaymath}
    \dfrac{ T_{ij1} ⇒ P_{ij1} \cdots T_{ijn_{ij}} ⇒ P_{ijn_{ij}} }{ P_i ⇒ T_{ij} } ~(L_{ij})
  \end{displaymath}
  where all the $P_i$ used to index the family are pairwise distinct.  The groups obtained in this
  way are a \emph{pattern family}.
\end{definition}

\begin{definition}[leftmost matching]
  Consider a pattern family as in Definition~\ref{def:patfam}.  The family is said to be
  \emph{leftmost matching} if the group of rules for each $P_i$ satisfies one of the following
  conditions:
  \begin{itemize}
  \item either the family contains a single axiom, \ie, $1≤j≤1$ with $n_{ij}=0$,
  \item or the family contains only proper inferences, \ie, $1≤j≤m_i$ with $n_{ij}>0$.
  \end{itemize}
\end{definition}

%% Sub-index each non-axiom $P_i$-group by leftmost premise construction into sub-families of
%%    the form
%%    \begin{displaymath}
%%      \dfrac{ T_{ij} ⇒ P_{ijk1} \quad T_{ijk2} ⇒ P_{ijk2} \quad\cdots\quad T_{ijkn_{ijk}} ⇒ P_{ijkn_{ijk}} }{ P_i ⇒ T_{ijk} }
%%    \end{displaymath}
%%    where all the $T_{ij}$ used to index the sub-family within a $P_i$-group are pairwise disjoint.

\begin{definition}[left-operations]
  Given a leftmost-matching pattern family. Each $P$-indexed group of proper inference rules will
  have the following form:
  \begin{displaymath}
    \dfrac{ T_{j1} ⇒ P_{j1} \quad T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ P ⇒ T_j } ~ (L_j)
  \end{displaymath}
  with one $j$ per rule in the family, which is by definition non-empty ($1≤j≤n$) and contains only
  proper inferences ($n_j≥1$).
  %%
  \begin{enumerate}

  \item Given a label $L$, the \emph{left-flattening} rewrite rules of the group are
    %% 
    \begin{align*}
      L(P) &→ L'(T_{11}, …,T_{n1}, P) \\[\jot]
      L'(P_{11}, m_2, …, m_n, P) &→ L_1(P, P_{11}) \\[-\jot]
      &~\vdots\\
      L'(m_1, …, m_{n-1}, P_{n1}, P) &→ L_n(P, P_{n1})
    \end{align*}
    %% 
    with $L'$ a fresh symbol associated with the group and the $m_j$ fresh meta-variables.

  \item The \emph{left-eliminated} rules for the group are the rules
    \begin{displaymath}
      \dfrac{ T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ L_j(P, P_{j1}) ⇒ T_j } ~ (L'_j)
    \end{displaymath}
    with the $L'_j$ fresh labels derived from the $L_j$ labels.

  \end{enumerate}
\end{definition}

\begin{definition}[left-unfolded]
  Given a leftmost-matching pattern family and consider the proper inference rule group indexed by
  $P$. The following system is the \emph{left-unfolded} inference system for the $P$-indexed group:
  \begin{enumerate}

  \item The left-flattening rewrite rules of the group for a fresh~$L$.

  \item The new inference rule (which refers to the rewrite rules)
    \begin{displaymath}
      \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m } ~ (L)
    \end{displaymath}

  \item The left-eliminated inference rules (which may be axioms or proper inferences).

  \end{enumerate}
\end{definition}

\begin{proposition}
  Given a set of ground sequential inference rules, which is a leftmost-matching pattern
  family. Pick one group of proper inference rules, indexed by the initial pattern $P$. The original
  system and the system where the group has been replaced with the left-unfolded group have the same
  normal forms.
\end{proposition}
\begin{proof}
  Easy: full proof tree before corresponds to proof tree after with simple conversion of the
  eliminated eliminated premise to an application of the new rule and a single use of the rewrite
  rule.
\end{proof}

Note that we can only prove that full ``big-step'' evaluations are equivalent: the new rules may
``get stuck'' in interesting ways (\TBD{example with overlapping patterns}).

\begin{lemma}
  Start with any leftmost matching ground sequential inference rule system and apply left-unfolding
  repeatedly except on axioms and the introduced inference rules
  \begin{displaymath}
    \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m }
  \end{displaymath}
  The resulting system has the same normal forms as the original system.
\end{lemma}

To finish the transform from inference rules to \HAX rules we need two additional notions.

\begin{definition}
  An inference system is \emph{rooted} if it has one rule that occurs as the root rule of every
  proof tree.
\end{definition}

\begin{definition}
  A leftmost-matching ground sequential inference rule system is \emph{left deterministic} if the
  left-flattening 
\end{definition}

\begin{theorem}
  A rooted and leftmost matching ground sequential inference system can be implemented by a 
\end{theorem}

\end{document}


%------------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% TeX-master: t
% TeX-auto-untabify: nil
% End:
