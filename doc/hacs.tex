%% Introduction to HACS.
%%
\documentclass[11pt]{article} %style: font size.
\input{setup}

%% Style.
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage{charter}
\SelectTips{eu}{}
\bibliographystyle{plainurl}

%% Topmatter.
\title{
  Compiler Generation Using \HAX\thanks{This version describes \HAX β version 0.9 released for use at NYU.}
}
\author{
  Kristoffer H. Rose\\
  Two Sigma Investments/New York University
}

\begin{document}
\maketitle

\begin{abstract}\noindent
  Higher-order Attribute Contraction Schemes---or \HAX---is a language for programming compilers.
  With \HAX it is possible to create a fully functional compiler from a single source file.  This
  document explains how to get \HAX up and running, and walks through the code of a simple example
  with each of the main stages of a compiler in \HAX: lexical analysis, syntax analysis, semantic
  analysis, intermediate code generation with optimization, and code generation.
\end{abstract}

\compacttableofcontents


\section{Introduction}\label{sec:intro}

\HAX abbreviates \emph{Higher-order Attribute Contraction Schemes}, which is a formal system for
symbolic rewriting extended with programming idioms commonly used when coding compilers. \HAX is
developed as a front-end to the \CRSX higher-order rewriting engine~\cite{crsx}.

A compiler written in \HAX consists of a single \emph{specification file} with a series of formal
sections, each corresponding to a stage of the compiler.  Each section is written in a formal style
suitable for that stage of the compiler. Specifically, \HAX supports the following notations:
%%
\begin{description}

\item[Regular Expressions.] Used to describe how an input text is partitioned into
  \emph{tokens}. The regular expressions of \HAX follows common
  conventions~\cite{Aho+:2006}. Section~\ref{sec:tokens} gives details of this notation.

\item[Context Free Grammars.] \HAX uses a form of BNF~\cite{NaurEtal:cacm1960} with common
  extensions to describe \emph{context free grammars}. \HAX includes simple mechanisms for automatic
  resolution of operator precedence and productions using immediate recursion such that the
  transformation from token stream to abstract syntax can be formalized. Details in
  Section~\ref{sec:syntax}.

\item[Recursive Translation Schemes.] Simple translations in general, and code generation in
  particular, are traditionally achieved by \emph{recursive translation} from one abstract form to
  another.  \HAX includes special notations for defining such translations, as well as a mechanism
  for defining auxiliary so-called ``semantic sorts,'' detailed in Section~\ref{sec:schemes}.

\item[Attribute Grammars.] Analyses can be described with attribute grammars in the style of
  \emph{Syntax-Directed Definitions}~\cite{Aho+:2006}, originally introduced as \emph{attribute
    grammars}~\cite{Knuth:mst1968}, which describe how properties propagate through the abstract
  syntax tree.  Section~\ref{sec:synthesized} details how the basic propagation rules work for
  synthesized attributes, Section~\ref{sec:inherited} explains how inherited atributes are
  described, and Section~\ref{sec:symbols} summarizes the special considerations needed when
  managing scoped symbols and binders using \emph{higher-order abstract syntax}.

\end{description}

\begin{plan}
  In the remainder of this document we introduce the most important features of the \HAX language by
  explaining the relevant parts of the included \emph{First.hx} example, inspired by \cite[Figure
  1.7]{Aho+:2006}, as well as several other minor examples. We first show in Section~\ref{sec:run}
  how to install \HAX and run the example, before we go on to how to write specifications. We
  explain lexical analysis in Section~\ref{sec:tokens}, syntax analysis in Section~\ref{sec:syntax},
  basic semantic sorts and recursive translation schemes in Section~\ref{sec:schemes}, bottom-up
  semantic analysis in Section~\ref{sec:collect}, general syntax-directed definitions in
  Section~\ref{sec:sdd}, and advanced features in Section~\ref{sec:advanced}.
  Appendix~\ref{app:manual} has a reference manual, %
  %%Appendix~\ref{app:bonus} has some bonus examples, %
  Appendix~\ref{app:errors} explains some cryptic error messages, and
  Appendix~\ref{app:limits} lists some current limitations.
\end{plan}


\section{Getting Started}\label{sec:run}

In this section we walk through the steps for getting a functional \HAX installation on your
computer.\footnote{\HAX is still a β release so please report any problems with this procedure to
  \emph{hacs@crsx.org}.}

\begin{requirements}
  To run the \HAX examples here you need a *nix system (including a shell and the usual utilities)
  with these common programs: a Java development environment (at least Java~1.6~SE SDK, with "java"
  and "javac" commands); and a standard *nix development setup including GNU Make and a C99 compiler
  with access to the \emph{icu} libraries.\footnote{See the included \emph{README} file for further
    details.} In addition, the setup process needs internet access to retrieve the \CRSX base
  system~\cite{crsx} and JavaCC parser generator~\cite{javacc}.
\end{requirements}

\begin{commands}[install \HAX]\label{com:all}
  Retrieve the \emph{hacs-0.9.zip} archive, extract it to a new directory, and install it, for
  example with the following commands:\footnote{User input is \textcolor{blue}{blue}.}
  %%
\begin{code}[commandchars=\^\{\}]
$ ^textcolor{blue}{^texttt{wget http://crsx.org/hacs-0.9.zip}}
$ ^textcolor{blue}{^texttt{unzip hacs-0.9.zip}}
$ ^textcolor{blue}{^texttt{make -C hacs prefix=$HOME/.hacs FROMZIP=yes install install-support}}
\end{code}
  %%
  These commands will need Internet access, using the wget command to retrieve utility
  libraries.\footnote{Specifically, \HAX needs the \CRSX system and and JavaCC parser generator.}
  You may change the \verb|prefix=|… definition to store \HAX in a different location, if you wish;
  if so the occurrences of \verb|$HOME/.hacs| in any examples below should be changed accordingly.

  The following command makes the main \emph{hacs} command available for use:
  %%
\begin{code}[commandchars=\^\{\}]
$ ^textcolor{blue}{^texttt{alias hacs=$HOME/.hacs/bin/hacs}}
\end{code}
  %%
  (It may be worth including this command in your setup, or including the \verb|$HOME/.hacs/bin|
  directory in your \verb|$PATH|.)

  Please check that your new installation works with these commands: \TBD{RERUN!}
\begin{code}[commandchars=\^\{\}]
$ ^textcolor{blue}{^texttt{mkdir myfirst}}
$ ^textcolor{blue}{^texttt{cd myfirst}}
$ ^textcolor{blue}{^texttt{cp $HOME/.hacs/share/doc/hacs/examples/First.hx .}}
$ ^textcolor{blue}{^texttt{hacs First.run}}
...
$ ^textcolor{blue}{^texttt{./First.run --scheme=Compile \}}
              ^textcolor{blue}{^texttt{--term="^{initial := 1; rate := 1.0; position := initial + rate * 60;^}"}}
  LDF T, #1
  STF name, T_51
  LDF T_84, #1.0
  STF name_40, T_56
  LDF T_98, name_43
  LDF T_70, name_3
  LDF T_90, #60
  MULF T_96, T_62, T_86
  ADDF T_50, T_82, T_177
  STF name_23, T_66                       
\end{code}
  %%
  Congratulations---you just built your first compiler! (It may have taken a few minutes, as \HAX
  also performed the initial setup, which is only needed on the first run.)
\end{commands}

\begin{example}[module wrapper]%
  The source file for the \emph{First.hx} file used in the example above has the structure
  %%
\begin{hacs}[mathescape,xleftmargin=\parindent]
/* Top comment. */
module org.crsx.hacs.samples.First
{
  // Remark.
  $\text{\it Lexical Analysis (Section~\ref{sec:tokens})}$
  $\text{\it Syntax Analysis (Section~\ref{sec:syntax})}$
  $\text{\it Semantic Analysis (Sections~\ref{sec:collect} and \ref{sec:sdd})}$
  $\text{\it Code Generator (Section~\ref{sec:schemes})}$
  $\text{\it Main (Section~\ref{sec:schemes})}$
}
\end{hacs}
  Notice that \HAX permits C style comments.
\end{example}

\begin{table}[t]
  \begin{displaymath}
    \begin{tabular}{c|c|c}
      \hline
      \hline
      \emph{Glyph} & \emph{Code Point} & \emph{Character} \Bigstrut \\
      \hline
      {¬} & U+00AC & logical negation sign \\
      {¶} & U+00B6 & paragraph sign \\
      \hline
      ↑ & U+2191 & upwards arrow \\
      → & U+2192 & rightwards arrow \\
      ↓ & U+2193 & downwards arrow \\
      \hline
      ⟦ & U+27E6 & mathematical left white square bracket \\
      ⟧ & U+27E7 & mathematical right white square bracket \\
      ⟨ & U+27E8 & mathematical left angle bracket \\
      ⟩ & U+27E9 & mathematical right angle bracket \\
      \hline
    \end{tabular}
  \end{displaymath}
  \caption{Unicode special characters used by \HAX.}
\label{tab:unicode}
\end{table}

\begin{notation}[special Unicode characters]\label{man:unicode}
  \HAX uses a number of special symbols from the standard Unicode repertoire of characters, shown in Table~\ref{tab:unicode}
\end{notation}


\section{Lexical Analysis}
\label{sec:tokens}

Lexical analysis is the process of splitting the input text into tokens. \HAX uses a rather standard
variation of \emph{regular expressions} for this.

\begin{example}[tokens and white space]\label{ex:lexical}
  %%
  Here is a \HAX fragment for setting up the concrete syntax of integers, basic floating point
  numbers, identifiers, and white space, for use by a simple language:
  %%
\begin{hacs}[xleftmargin=\parindent,numbers=right,texcl]
// White space convention.
space [ \t\n] ;

// Basic nonterminals.
token INT      | ⟨Digit⟩+ ;
token FLOAT    | ⟨Digit⟩* "." ⟨Digit⟩+ ;
token ID       | ⟨Lower⟩+ ('_'? ⟨INT⟩)? ;

// Special categories of letters.
token fragment Digit  | [0-9] ;
token fragment Lower  | [a-z] ;
\end{hacs}
  %%
  The example illustrates the following particulars of \HAX lexical expressions:
  %%
  \begin{itemize}

  \item Declarations generally start with a keyword or two and are terminated by a ";" (semicolon).

  \item "token" declarations in particular have the "token" keyword followed by a regular expression
    between a "|" (vertical bar) and a ";" (semicolon). It defines the token as a
    \emph{non-terminal} that can be used in syntax productions described in the next section.

  \item A regular expressions is a sequence of units, corresponding to the concatenation of
    sequences of characters that match each one.  Each unit can be a \emph{character class} such as
    "[a-z]", which matches a single character in the indicated range, a string such as \hacsc|"."|,
    or a reference to a token or fragment such as "⟨Lower⟩", enclosed in the special Unicode
    mathematical angle brackets (see Table~\ref{tab:unicode}).

  \item A "token fragment" declaration means that the defined token can only be used in other token
    declarations, and not as grammar non-terminal in syntax productions.

  \item Every regular expression component can be followed by a repetition marker "?", "+", or~"*",
    and regular expressions can be \emph{grouped} with parentheses.

  \item The regular expression for white space is setup by "space" followed by the regular
    expression of what to skip -- here spaces, tabs, and newlines, where \HAX uses backslash for
    escaping in character classes with usual C-style language escapes.

  \end{itemize}
  %%
  In addition, we have followed the convention of naming proper grammar terminals with ALL-CAPS
  names, like "INT", so they are easy to distinguish from non-terminals below.
  %%
\end{example}

Notice that while it is possible to make every keyword of your language into a named token in this
way, this is not necessary, as keywords can be given as literals in syntax productions, covered in
the next section.

\begin{commands}[lexical analysis]
  The fragment above is part of \emph{First.run} from Section~\ref{sec:intro}, which can thus be
  used as a lexical analyzer.  This is achieved by passing the \emph{First.run} command two
  arguments: a \emph{token sort} and a \emph{token term}.\footnote{The command has more options that
    we shall introduce as we need them.}  Execution proceeds by parsing the string following
  the syntax of the token. We can, for example, check the lexical analysis of a number:\TBD{RERUN!}
\begin{code}[commandchars=\\\{\}]
$ \textcolor{blue}{./First.run --sort=Float --term=34.56}
34.56
\end{code}
  If there is an error, the lexical analyzer will inform us of this:\TBD{RERUN!}
\begin{code}[commandchars=^\{\}]
$ ^textcolor{blue}{./First.run --sort=Int --term=34.56}
Exception in thread "main" java.lang.RuntimeException: net.sf.crsx.CRSException:
net.sf.crsx.parser.ParseException:
 Parse error in embedded firstInt term at line 1, column 27: ⟦ 34.56 ⟧ ...
 Encountered " <T_T_M_FLOAT> "34.56 "" at line 1, column 29.
Was expecting one of:
    <T_meta1_T_M_INT> ...
    "\u27e9" ...
    <T_T_M_INT> ...
\end{code}
  (where the trail of Java exceptions has been truncated: the important information is in the first
  few lines).
\end{commands}


\section{Syntax Analysis}
\label{sec:syntax}

Once we have tokens, we can use \HAX to program a complete syntax analysis with a grammar that
specifies how the input text is decomposed according to a \emph{concrete syntax} and how the desired
\emph{abstract syntax tree} (AST) is constructed from that. Notice that \HAX does not provide a
``parse tree'' in the traditional sense, \ie, a tree that represents the full concrete syntax parse:
only the AST is built.  Grammars are structured following the \emph{sorts} of AST nodes, with
concrete syntax details managed through annotations and ``syntactic sugar'' declarations.

\begin{example}\label{ex:syntax}
  %%
  Here is another extract from our \emph{First.hx} example, with a small syntax analysis, or
  grammar. Our small example source language merely has blocks, assignment statements, and a few
  forms of expression, like so:
  %%
\begin{hacs}[xleftmargin=\parindent,numbers=right]
// Main program construct.
main sort Stat  | ⟦ ⟨Name⟩ := ⟨Exp⟩ ; ⟧  | ⟦ { ⟨Stats⟩ } ⟧ ;
sort Stats      | ⟨Stat⟩ ⟨Stats⟩ | ;

sort Exp  | ⟦ ⟨Exp@1⟩ + ⟨Exp@2⟩ ⟧@1
          | ⟦ ⟨Exp@2⟩ * ⟨Exp@3⟩ ⟧@2
          | ⟦ ⟨INT⟩ ⟧@3
          | ⟦ ⟨FLOAT⟩ ⟧@3
          | ⟦ ⟨Name⟩ ⟧@3
          | sugar ⟦ ( ⟨Exp#⟩ ) ⟧@3 → Exp# ;

sort Name | symbol ⟦ ⟨ID⟩ ⟧ ;
\end{hacs}
  %%
  The grammar structures the input as four sorts: "Stat" for statements, "Stats" for multiple
  statements, "Exp" for expressions, and "Name" for names (which we shall need later for symbol
  tables). \HAX grammars follow these conventions:
  %%
  \begin{itemize}

  \item Each sort is defined by a "sort" declaration followed by a number of \emph{productions},
    each introduced by a "|" (bar). (The first "|" corresponds to what is usually written ``::='' or
    ``→'' in grammars.)

  \item Concrete syntax is enclosed in "⟦…⟧" (``double'' or ``white'' brackets). Everything inside
    double brackets should be seen as \emph{literal syntax}, even "\" (backslash), \emph{except} for
    \HAX white space (corresponding to "[ \t\n\r]"), which is ignored, and references in "⟨…⟩"
    (angle brackets), which are special.

  \item References to \emph{nonterminals} (other productions) are wrapped in "⟨…⟩" (angle brackets).

  \item \emph{Precedence} is indicated with "@"$n$, where higher numbers $n$ designate higher
    (tighter) precedence.  Any reference in as well as the alternative itself may have a precedence
    in this way; in the example we establish that "*" binds tighter than "+", and that both
    operators are left recursive. Note that we specify the precedence of both the entire expression,
    after the "⟦⟧"s, and of each component, inside the "⟨⟩". (In fact where the precedence is
    omitted we could have written "@0".)

  \item The special "sugar" declaration expresses that the concrete syntax can use parentheses to
    raise the precedence of the enclosed expression to~3: it is the first example of a \emph{rewrite
      rule} with a "→" that we see, where we remark that the expression is marked "#" so we can use
    the "#" to indicate that it is extracted as the abstract result of concrete syntax with
    parenthesis.  (In fact the general rule is that when an "→" is used then all sort specifiers
    must be ``disambiguated'' with distinct markers like "#" or "#5" in this way.)

  \item The "Name" sort is defined as a "symbol", which is only allowed because the underlying "Id"
    token permits a trailing "_"$n$ (underscore and count); this permits the use as binders and
    automatic symbol generation.

  \end{itemize}
\end{example}

\begin{commands}
  %%
  We can parse an expression from the command line:
  %%
\begin{code}[commandchars=\\\{\}]
$ \textcolor{blue}{./First.run --sort=Exp --term="(2+(3*(4+5)))"}
2 + 3 * ( 4 + 5 )
\end{code}
  %%
  Notice that the printout differs slightly from the input term as it has been ``resugared'' from
  the AST with minimal insertion of parentheses.
  %%
\end{commands}


\section{Sorts and Recursive Translation Schemes}
\label{sec:schemes}

In this section we explain how basic algebraic structures and transformations are expressed in \HAX.

\begin{example}\label{ex:unif}
  %%
  Another fragment of the \emph{First.hx} example has the semantic sorts and operations that are
  used. For our toy language that just means the notion of a \emph{type} with the way that types are
  ``unified'' to construct new types.
  %%
\begin{hacs}[xleftmargin=\parindent,numbers=right,texcl]
// Types to associate to AST nodes.
sort Type | Int | Float ;

// The Type sort includes a scheme for unifying two types.
| scheme Unif(Type,Type) ;
Unif(Int, Int) → Int;
Unif(#1, Float) → Float;
Unif(Float, #2) → Float;
\end{hacs}
  %%
  The code declares a new sort, "Type", which is a \emph{semantic} sort because it does not include
  any syntactic cases: all the possible values (as usual listed after leading "|"s) are simple \emph{term
    structures} written without any ⟦⟧s.  Structures are written with a leading ``constructor,'' which
  should be a capitalized word (the same as sort names), optionally followed by some ``arguments''
  in "()"s, where the declaration gives the sort for each argument (here there are none).

  The semantic sort also includes a "scheme" declaration for the "Unif" constructor, which must be
  followed by an argument list with two "Type" arguments. The scheme declaration is ``instantiated''
  by \emph{rules} of the form ``pattern→replacement,'' which must specify for each possible shape of
  "Unif"-construction how it should be simplified by the scheme.  Rules may include
  ``meta-variables'' starting with "#" (hash), like "#1", to designate ``function arguments'' that
  should be copied from the pattern to the replacement.

  The rules above can, for example, be used to simplify a composite term as follows:
  %%
\begin{hacs}[xleftmargin=\parindent]
Unif(Unif(Int, Float), Int) → Unif(Float, Int) → Float
\end{hacs}
  %%
  Note how overlaps are allowed but please do verify determinacy, \ie, if a particular combination
  of arguments can be subjected to two rules then theyshould give the same result!
  %%
\end{example}

\begin{example}[Syntactic scheme]\label{ex:leftmost}
  The "Unif" scheme defined in the example is a simple example of a recursive translation scheme,
  defined by rewrite rules.  We are permitted to define such schemes over the syntactic sorts, as
  well.  Here is, for example, code to extract the leftmost leaf expression from an "Exp" tree from
  Example~\ref{ex:syntax}:
  %%
\begin{hacs}[xleftmargin=\parindent,texcl]
sort Exp | scheme Leftmost(Exp) ;
Leftmost(⟦⟨Exp#1⟩ + ⟨Exp#2⟩⟧)  →  Leftmost(Exp#1) ;
Leftmost(⟦⟨Exp#2⟩ * ⟨Exp#3⟩⟧)  →  Leftmost(Exp#1) ;
Leftmost(⟦⟨INT#⟩⟧)  →  ⟦⟨INT#⟩⟧ ;
Leftmost(⟦⟨FLOAT#⟩⟧)  →  ⟦⟨FLOAT#⟩⟧ ;
Leftmost(⟦⟨Name#⟩⟧)  →  ⟦⟨Name#⟩⟧ ;
\end{hacs}
  %%
  Notice how:
  \begin{itemize}

  \item We first set the current sort to "Exp" and then add a "scheme" called "Leftmost" that takes
    one argument of "Exp" sort.

  \item There is precisely one rule with a pattern applying "Leftmost" to each non-"sugar"
    production for "Exp" from Example~\ref{ex:syntax}.

  \item Each non-terminal reference has the non-terminal name followed by a "#"$n$ marker to
    identify the subexpression of that non-terminal sort for use on the right side of the "→".

  \item Each rule rewrites an "Exp" expression to another "Exp" expression, either by recursively
    invoking the defined "Leftmost" scheme on a smaller part of the term or by returning the term
    itself.

  \item We \emph{have} to write "⟦⟨Name#⟩⟧" rather than just "Name#" or "#" in the last rules
    because the form "Name#" describes something of "Name" sort, not "Exp" sort.  Indeed in the last
    rule, "Name#" stands for the subterm of the "Exp" expression that is a "Name".

  \end{itemize}
\end{example}

\begin{commands}[invoke scheme]
  We can invoke the "Leftmost" scheme from the command line, since it operates on a syntactic
  expression. 

  \TBD{Do!}

  Note that we cannot meaningfully invoke the "Unif" scheme from the command line because there is
  no user syntax for types in our example!
\end{commands}

\begin{example}
  The \emph{First.hx} example defines the "Compile" scheme as a top level function to be used from
  the command line. This looks as follows:
\begin{hacs}[xleftmargin=\parindent,numbers=right]
sort A_Progr | scheme Compile(Stat);
Compile(#stat) → ⟦ CG ICG TA ⟨Stat#1⟩ ⟧ ;
\end{hacs}
  (You will see later what the contraction here means.)  This is the reason for the
  \verb|--scheme=Compile| option we invoked back in the getting started section.  Such wrapper raw
  schemes must have a single argument.
\end{example}


\section{Collecting Information}
\label{sec:collect}

\HAX has special support for assembling information in a ``bottom-up'' manner, corresponding to how
\emph{synthetic attributes} are used in syntax-directed definitions (or attribute grammars).  In
this section we explain \emph{how} you convert any SDD synthetic attribute definition into a \HAX
one.

Consider the following single definition of the synthesized attribute $t$ for expressions $E$:
%%
\begin{equation}
  \begin{array}{l|l}
    \hline
    \hline
    \textsc{Production}  & \textsc{Semantic Rules} \Bigstrut\\
    \hline
    E → E_1 + E_2 & E.t = \op{Unif}(E_1.t, E_2.t) \Bigstrut\\
    \hline
  \end{array}
  \tag{E1}
\end{equation}
%% 
The rule is ``S-attributed'' because it exclusively relies on synthesized attributes. This allows is
to express it directly in \HAX as follows.
%% 
\begin{enumerate}

\item The first thing to do is declare the attribute and associate it with the $E$ sort.
\begin{hacs}
   attribute ↑t(Type);
   sort E | ↑t ;
\end{hacs}
  the "↑" indicates ``synthesized'' because the attribute moves ``up'' in the tree. The declaration
  of the attribute indicates with "(Type)" that the \emph{value} of the synthesized attribute is a
  "Type".  Attributes are always named with lower case names.

\item The second thing to do is copy the corresponding syntax production but omit any "@"-markings
  and add a unique "#"$n$ disambiguation mark to each production.  Since \thetag{E1} is based on the
  alternative
\begin{hacs}
   sort E   | ⟦ ⟨E@1⟩ + ⟨E@2⟩ ⟧@1
\end{hacs}
  similarly to Example~\ref{ex:syntax}, we start with 
\begin{hacs}
   ⟦ ⟨E#1⟩ + ⟨E#2⟩ ⟧
\end{hacs}
  where we have used the subscripts from \thetag{E1} as "#"-disambiguation marks.

\item Next add in \emph{synthesis patterns} for the attributes we are reading.  Each attribute
  reference like $E_1.t$ becomes a pattern like "⟨E#1 ↑t(#t1)⟩", where the meta-variables like
  "#t1" should each be unique.  For our example, this gives us
\begin{hacs}
   ⟦ ⟨E#1 ↑t(#t1)⟩ + ⟨E#2 ↑t(#t2)⟩ ⟧
\end{hacs}
  which sets up "#t1" and "#t2" as synonyms for $E_1.t$ and $E_2.t$, respectively.

\item Finally, add in the actual synthesized attribute, using the same kind of pattern at the
  \emph{end} of the rule (and add a ";"), and we get
\begin{hacs}
   ⟦ ⟨E#1 ↑t(#t1)⟩ + ⟨E#2 ↑t(#t2)⟩ ⟧ ↑t(Unif(#t1,#t2)) ;
\end{hacs}
  %%
  This is read ``When considering an "E" (the current sort) which has the shape
  $⟦⟨E⟩+⟨E⟩⟧$ where furthermore the first expression has a value matching "#t1" for the
  synthesized attribute "t", and the second expression has a value matching "#t2" for the
  synthesized attribute "t", then the entire expression has the value "Unif(#t1,#t2)" for the
  synthesized attribute "t".''

\end{enumerate}

\begin{example}\label{ex:collect}
  %%
  In Example~\ref{ex:syntax} we presented the abstract syntax of the small language processed by
  \emph{First.hx}. A type analysis of the expressions of the language excluding variables might look
  as follows as a standard SDD (syntax directed definition), where we use $E$ for the "Exp"
  non-terminal, and one attribute: $E.t$ is the synthesized "Type" of the expression $E$.  In the
  notations of \cite{Aho+:2006}, the SDD can be specified something like this:
  %% 
  \begin{equation*}
    \begin{array}{l|l}
      \hline
      \hline
      \textsc{Production}  & \textsc{Semantic Rules} \Bigstrut\\
      \hline
      E → E_1 + E_2 & E.t = \op{Unif}(E_1.t, E_2.t) \Bigstrut\\[\jot]
      \quad\mid E_1 \ast E_2 & E.t = \op{Unif}(E_1.t, E_2.t) \\[\jot]
      \quad\mid \textbf{int} & E.t = \op{Int} \\[\jot]
      \quad\mid \textbf{float} & E.t = \op{Float} \\[\jot]
      \hline
    \end{array}
  \end{equation*}
  %%
  where we assume that $\op{Unif}$ is defined as discussed in Example~\ref{ex:unif}.
  %%
  We can convert this SDD to the following \HAX (using the proper names for the sorts as actually
  found in \emph{First.hx}):
  %%
\begin{hacs}[xleftmargin=\parindent,numbers=right,texcl]
attribute ↑t(Type);       // synthesized type

sort Exp | ↑t ;           // expressions have an associated synthesized type, $E.t$

// Synthesis rules for $E.t$.
⟦ ⟨Exp#1 ↑t(#t1)⟩ + ⟨Exp#2 ↑t(#t2)⟩ ⟧ ↑t(Unif(#t1,#t2));
⟦ ⟨Exp#1 ↑t(#t1)⟩ * ⟨Exp#2 ↑t(#t2)⟩ ⟧ ↑t(Unif(#t1,#t2));
⟦ ⟨INT#⟩ ⟧ ↑t(Int);
⟦ ⟨FLOAT#⟩ ⟧ ↑t(Float);
\end{hacs}
  %%
  The first line declares the value of the synthesized "t" attribute to be a "Type".
  %%
  The second line associates the synthetic attribute "t" to the "Exp" sort: all synthetic
  attributes are associated with one or more abstract syntax sorts.
  %%
  The remaining lines are \emph{synthesis rules} that show for each form of "Exp" what the value
  should be, based on the values passed ``up'' from the subexpressions; these are generated
  mechanically as discussed above from the synthesis semantic rules.
\end{example}


\section{Full Syntax-Directed Definitions}
\label{sec:sdd}

In general, however, we wish to implement analyses that are more general than what can be achieved
with S-attributed syntax-directed definitions: we also want to use \emph{inherited} attributes.
This section introduces inherited attributes and explains how they are implemented in \HAX.

Consider the following two simple semantic rules:
%% 
\begin{equation*}
  \begin{array}{l|ll}
    \hline
    \hline
    \textsc{Production}  & \textsc{Semantic Rules} \Bigstrut&\\
    \hline
    S → \textbf{name}_1 := E_2; S_3
    &
    E_2.e = S.e; 
    S_3.e = \op{Extend}(S.e, \textbf{name}_1.sym, E_2.t) \Bigstrut\quad
    &\thetag{1}
    \\[\jot]
    E → E_1 + E_2
    &
    E_1.e = E.e; E_2.e = E.e
    &\thetag{2}
    \\[\jot]
    \hline
  \end{array}
\end{equation*}
%% 
(which refers to the otherwise not mentioned $E.t$ attribute from the previous section). Here are
the steps to follow to translate the inheritance to \HAX.
%%
\begin{enumerate}

\item The first thing to do is, again, to declare the attribute.  Since $S.e$ and $E.e$ are a
  \emph{map} from names to types, this is written as follows:
\begin{hacs}
   attribute ↓e{Name:Type} ;
\end{hacs}
  The "↓" indicates an inherited attribute, and the "{Name:Type}" part declares the value of the
  attribute to be a mapping from values of "Name" sort to values of "Type" sort. (We'll assume that
  we still have the $E.t$ synthesized attribute defined as previously.)  As above, attributes are
  always given lower case names.

  Note that only sorts with a "symbol" declaration can be used for keys of mappings: the mappings
  take the rôle of \emph{symbol tables} from traditional compilers.

\item The second thing to do is to associate the inherited attribute to a \emph{recursive scheme},
  which will be responsible for propagating that inherited attribute over a values of a certain
  sort.  This has to be done separately for each sort that $e$ propagates over.  Rule \thetag{2} is
  the simplest, so we take that first.  The rule propagates the $e$ attribute over $E$
  subexpressions, so we invent a scheme, "Ee", which does that.
\begin{hacs}
   sort E | scheme Ee(E) ↓e ;
\end{hacs}
  As can be seen, the scheme generates results of the "E" sort and also takes parameters of the "E"
  sort; in addition it \emph{carries} the inherited attribute "e".

\item We first observe that \thetag{2} operates on sums, which in our case have a syntax like this:
\begin{hacs}
   sort E | ⟦ ⟨E@1⟩ + ⟨E@2⟩ ⟧@1 ;
\end{hacs}
  As before, we create a \emph{pattern} that is equivalent to this, using the subscripts from \thetag{2}:
\begin{hacs}
   ⟦ ⟨E#1⟩ + ⟨E#2⟩ ⟧
\end{hacs}

\item Now \emph{insert} the pattern into the scheme:
\begin{hacs}
   Ee(⟦⟨E#1⟩ + ⟨E#2⟩⟧)
\end{hacs}
  This clearly respects the sort constraints we defined above, with "Ee" being applied to an "E" expression.

\item Since there are no complicated dependencies in \thetag{2}, we are almost done: we just have to
  create a rule where we on the right side of the "→" \emph{apply} the "Ee" scheme recursively to
  the subexpressions that should inherit the "e" attribute:
\begin{hacs}
   Ee(⟦⟨E#1⟩ + ⟨E#2⟩⟧)  → ⟦⟨E Ee(#1)⟩ + ⟨E Ee(#2)⟩⟧ ;
\end{hacs}
  This implements \thetag{2}. Notice that there are no explicit mentions of the "e" attribute, only
  the \emph{implicit} copying that is implied by the use of the "Ee" scheme. The recursive
  arrangement of the "Ee" wrappers implies the two attribute equations $E_1.e=E.e$ and $E_2.e=E.e$
  from \thetag{2}.

\item Rule \thetag{1} is slightly more complicated, because the inherited attribute has non-trivial
  dependencies. We must know the dependency relationship of the attributes to devise a
  \emph{recursive strategy} for the attribute evaluation.  Let us assume that we have the following
  (realistic) dependency for \thetag{1}: ``The $E_2.t$ attribute cannot be computed until
  \emph{after} $E_2.e$ has been instantiated (and recursively propagated).''  In that case we have
  to evaluate \thetag{1} in two steps:
  \begin{enumerate}
  \item Do $E_2.e = S.e$, establishing the precondition for allowing the system to compute $E_2.t$.
  \item When the system has computed $E_2.t$ then do $S_3.e=\op{Extend}(S.e,\textbf{name}_1.sym,E_2.t)$.
  \end{enumerate}
  These two steps are achieved by having \emph{two} carrier schemes, one for each step:
\begin{hacs}
   sort S | scheme SeA(S) ↓e | scheme SeB(S) ↓e ;
\end{hacs}
  The first propagates into statements in the same way as for \thetag{2}, except only into the first
  subterm, and \emph{chains to the next stage}:
\begin{hacs}
   SeA(⟦name := ⟨E#2⟩; ⟨S#3⟩⟧)  →    SeB(⟦name := ⟨E Ee(#2)⟩; ⟨S#3⟩⟧) ;
\end{hacs}
  Notice how we invoke the "Ee" scheme to pass $E_2.e$ (the system understands that $S.e$ and
  $E_2.e$ refer to the same attribute), and how we do \emph{not} wrap "#3" in anything as nothing
  should be passed there; instead we just leave the top wrapper "SeB" to wait for when it can process.

  The second stage then finishes the job but \emph{includes the synthetic dependency} using the
  notation of the previous section, and starts (the first stage) recursively on the appropriate
  subterm.  However, it also needs to compute the $\op{Extend}$ result, which is achieved with the
  following rule:
\begin{hacs}
   SeB(⟦x := ⟨E#2 ↑t(#t2)⟩; ⟨S#3⟩⟧) →  ⟦x := ⟨E#2⟩; ⟨S  SeA(#3)↓e{x:#t2} ⟩⟧) ;
\end{hacs}
  The last bit of notation is the way we call "SeA" with an \emph{extended} $S_3.e$ attribute: the
  notation "SeA(#3)↓e{x:#t2}" means ``call "SeA" (passing "e") on the statement "#3" but use an
  "e" which has been extended with the mapping from "x" to "#t2".''

  Also note that because the "Name" sort is a "symbol" sort, we should \emph{directly} use the
  variable "x" (which is a legal "ID" token) in the rules instead of "⟨Name#x⟩" or such.

\end{enumerate}

\begin{figure}[h]
  \begin{equation*}
    \begin{array}{r@{\,}l|lr}
      \hline
      \hline
      \multicolumn{2}{c|}{\textsc{Production}}  & \textsc{Semantic Rules} &\Bigstrut\\
      \hline\Bigstrut
      S &→ \textbf{name} := E_1; S_2
      & E_1.e = S.e; S_2.e = \op{Extend}(S.e, \textbf{name}.sym, E_1.t) &\thetag{S1}
      \\[\jot]
      &\mid \{~S_1~\}~S_2 & S_1.e = S.e; S_2.e = S.e &\thetag{S2}
      \\[\jot]
      &\mid ε & &\thetag{S3}
      \\[\jot]
      \hline\Bigstrut
      E &→ E_1 + E_2 & E_1.e=E.e; E_2.e=E.e; E.t = \op{Unif}(E_1.t, E_2.t) &\thetag{E1}\\[\jot]
      &\mid E_1 \ast E_2 & E_1.e=E.e; E_2.e=E.e; E.t = \op{Unif}(E_1.t, E_2.t) &\thetag{E2}\\[\jot]
      &\mid \textbf{int} & E.t = \op{Int}&\thetag{E3}\\[\jot]
      &\mid \textbf{float} & E.t = \op{Float}&\thetag{E4}\\[\jot]
      &\mid \textbf{name} & E.t = \text{if}~\op{Defined}(E.e,\textbf{name}.sym)&\thetag{E5}\\
      && \qquad\quad\text{then}~\op{Lookup}(E.e,\textbf{name}.sym)\\
      && \qquad\quad\text{else}~\op{TypeError}
      \\[\jot]
      \hline
    \end{array}
  \end{equation*}
  \caption{SDD for type checking.}
  \label{fig:sdd}
\end{figure}

\begin{figure}[p]\small
\begin{hacs}[numbers=right,texcl]
// TYPE ANALYSIS

sort Type  | Int | Float | TypeError
           | scheme Unif(Type,Type) ;

Unif(Int, Int) → Int;
Unif(#t1, Float) → Float;
Unif(Float, #t2) → Float;
default Unif(#1,#2) → TypeError; // fall-back

attribute↑t(Type);  // synthesized expression type
sort Exp | ↑t;

⟦ (⟨Exp#1 ↑t(#t1)⟩ + ⟨Exp#2 ↑t(#t2)⟩) ⟧ ↑t(Unif(#t1,#t2));
⟦ (⟨Exp#1 ↑t(#t1)⟩ * ⟨Exp#2 ↑t(#t2)⟩) ⟧ ↑t(Unif(#t1,#t2));
⟦ ⟨INT#⟩ ⟧ ↑t(Int);
⟦ ⟨FLOAT#⟩ ⟧ ↑t(Float);
// Missing case: variables -- handled by Ee below.

attribute↓e{Name:Type};  // inherited type environment

sort Exp | scheme Ee(Exp) ↓e ;  // propagates e over Exp

// These rules associate t attribute with variables (missing case above).
Ee(⟦id⟧) ↓e{⟦id⟧ : #t} → ⟦ id ⟧ ↑t(#t);
Ee(⟦id⟧) ↓e{¬⟦id⟧} → error⟦Undefined identifier ⟨id⟩⟧;

Ee(⟦⟨Exp#1⟩ + ⟨Exp#2⟩⟧) → ⟦ ⟨Exp Ee(#1)⟩ + ⟨Exp Ee(#2)⟩ ⟧;
Ee(⟦⟨Exp#1⟩ * ⟨Exp#2⟩⟧) → ⟦ ⟨Exp Ee(#1)⟩ * ⟨Exp Ee(#2)⟩ ⟧;
Ee(⟦⟨INT#⟩⟧) → ⟦⟨INT#⟩⟧;
Ee(⟦⟨FLOAT#⟩⟧) → ⟦⟨FLOAT#⟩⟧;

sort Stat | scheme SeA(Stat) ↓e ;  // propagates e over Stat

SeA(⟦id := ⟨Exp#1⟩; ⟨Stat#2⟩⟧) → SeB(⟦id := ⟨Exp Ee(#1)⟩; ⟨Stat#2⟩⟧);
{
  | scheme SeB(Stat) ↓e;  // helper scheme for assignment after expression typeanalysis
  SeB(⟦id := ⟨Exp#1 ↑t(#t1)⟩; ⟨Stat#2⟩ ⟧) → ⟦id := ⟨Exp#1⟩; ⟨Stat SeA(#2)⟩⟧ ↓e{⟦id⟧:#t1} ;
}

SeA (⟦ { ⟨Stat#1⟩ } ⟨Stat#2⟩ ⟧) → ⟦ { ⟨Stat SeA(#1)⟩ } ⟨Stat SeA(#2)⟩ ⟧;

SeA (⟦ ⟧) → ⟦ ⟧;
\end{hacs}
  \caption{\HAX code for type analysis.}
  \label{fig:sdd-hacs}
\end{figure}

\begin{example}\label{ex:sdd}
  %%
  An SDD for a simple type analysis can be implemented with two attributes (and using the usual
  convention that the SDD uses $E$ and $S$ where the \HAX grammar has "Exp" and "Stat"):
  %%
  \begin{itemize}

  \item The inherited \emph{environment} attribute $e$, which is a map from variables to types on
    both the statement and expression non-terminals $S$ and $E$.

  \item The synthesized \emph{type} attribute $t$ on expressions $E$, which contains the type of the
    expression.

  \end{itemize}
  %%
  With those, the SDD can be expressed as shown in Figure~\ref{fig:sdd}, where we use the helpers
  \op{Extend}, \op{Defined}, and \op{Lookup} to build an extended environment with an additional
  type declaration, check for existence, and look one up, respectively, and \op{Unif} to find the
  type of an arithmetic operation with operands of two specific types.

  If we use the translation mechanism, then we obtain the \HAX fragment in
  Figure~\ref{fig:sdd-hacs}.
  %% 
\end{example}


\section{Advanced Features}
\label{sec:advanced}

After the analysis we are ready for generating code.

\begin{figure}[p]\small
\begin{hacs}[numbers=right]
/* 6. INTERMEDIATE CODE GENERATION. */

token T | T ('_' ⟨INT⟩)? ; // temporary

// Concrete syntax & abstract syntax sorts.

sort I_Progr | ⟦⟨I_Instr⟩ ⟨I_Progr⟩⟧ | ⟦⟧ ;

sort I_Instr | ⟦⟨Tmp⟩ = ⟨I_Arg⟩ + ⟨I_Arg⟩; ¶⟧
             | ⟦⟨Tmp⟩ = ⟨I_Arg⟩ * ⟨I_Arg⟩; ¶⟧
             | ⟦⟨Tmp⟩ = ⟨I_Arg⟩; ¶⟧
             | ⟦⟨Name⟩ = ⟨Tmp⟩; ¶⟧ ;

sort I_Arg | ⟦⟨Name⟩⟧
           | ⟦⟨FLOAT⟩⟧
           | ⟦⟨INT⟩⟧
           | ⟦⟨Tmp⟩⟧ ;

sort Tmp | symbol ⟦ ⟨T⟩ ⟧ ;

// Translation scheme.

attribute ↓tmpType{Tmp:Type} ;

sort I_Progr ;

| scheme ⟦ ICG ⟨Stat⟩ ⟧ ↓tmpType ;
⟦ ICG id := ⟨Exp#2 ↑HasType(#t2)⟩; ⟧
  → ⟦ { ⟨I_Progr ⟦ICGExp T ⟨Exp#2⟩⟧ ↓tmpType{T:#t2}⟩ } id = T; ⟧ ;
⟦ ICG { } ⟧ → ⟦ ⟧;
⟦ ICG { ⟨Stat#s⟩ ⟨Stats#ss⟩ } ⟧ → ⟦ { ICG ⟨Stat#s⟩ } ICG { ⟨Stats#ss⟩ } ⟧ ;

| scheme ⟦ ICGExp ⟨Tmp⟩ ⟨Exp⟩ ⟧ ;

⟦ ICGExp T ⟨INT#1⟩ ⟧ → ⟦ T = ⟨INT#1⟩; ⟧ ;
⟦ ICGExp T ⟨FLOAT#1⟩ ⟧ → ⟦ T = ⟨FLOAT#1⟩; ⟧ ;
⟦ ICGExp T id ⟧ → ⟦ T = id; ⟧ ;

⟦ ICGExp T ⟨Exp#1⟩ + ⟨Exp#2⟩ ⟧
  → ⟦ {ICGExp T_1 ⟨Exp#1⟩} {ICGExp T_2 ⟨Exp#2⟩} T = T_1 + T_2; ⟧ ;

⟦ ICGExp T ⟨Exp#1⟩ * ⟨Exp#2⟩ ⟧
  → ⟦ {ICGExp T_1 ⟨Exp#1⟩} {ICGExp T_2 ⟨Exp#2⟩} T = T_1 * T_2; ⟧ ;

// Helper to flatten code sequence.
| scheme ⟦ {⟨I_Progr⟩} ⟨I_Progr⟩ ⟧;
⟦ {} ⟨I_Progr#3⟩ ⟧ → #3 ;
⟦ {⟨I_Instr#1⟩ ⟨I_Progr#2⟩} ⟨I_Progr#3⟩ ⟧ → ⟦ ⟨I_Instr#1⟩ {⟨I_Progr#2⟩} ⟨I_Progr#3⟩ ⟧;
\end{hacs}
  \caption{Intermediate Code Generation.}
  \label{fig:icgen}
\end{figure}

\begin{example}\label{ex:icgen}
  %%
  A further part of \emph{First.hx} is the translation from abstract syntax to the intermediate
  representation, shown in Fig.~\ref{fig:icgen}. The fragment contains the usual components: a
  syntax specification, rewrite schemes, and rewrite rules for the "ICG" scheme.

  The code only uses two new features: "¶" markers in the syntax to indicate newlines, and rules
  that introduce \emph{fresh} variables (of "Tmp" sort): when the replacement of a rule uses a
  symbol, which was not in the pattern, then this corresponds to \emph{generating} a new globally
  unique symbol. So each time the rule
\begin{hacs}
   ⟦ ICG id := ⟨Exp#2 ↑HasType(#t2)⟩; ⟧
     → ⟦ { ⟨I_Progr ⟦ICGExp T ⟨Exp#2⟩⟧ ↓tmpType{T:#t2}⟩ } id = T; ⟧ ;
\end{hacs}
  is used, "T" denotes a new so-called ``fresh'' symbol.  When printed, the various incarnations of
  "T" will be named "T_1", "T_86", \etc
  %%
\end{example}

\begin{figure}[p]\small
\begin{hacs}[numbers=right]
/* 7. CODE GENERATOR. */

sort A_Progr | ⟦ ⟨A_Instr⟩ ⟨A_Progr⟩ ⟧ | ⟦⟧ ;

sort A_Instr | ⟦ LDF ⟨Tmp⟩, ⟨A_Arg⟩ ¶⟧
             | ⟦ STF ⟨Name⟩, ⟨Tmp⟩ ¶⟧
             | ⟦ ADDF ⟨A_Arg⟩, ⟨A_Arg⟩, ⟨A_Arg⟩ ¶⟧
             | ⟦ MULF ⟨A_Arg⟩, ⟨A_Arg⟩, ⟨A_Arg⟩ ¶⟧ ;

sort A_Arg | ⟦ #⟨FLOAT⟩ ⟧ | ⟦ #⟨INT⟩ ⟧ | ⟦ ⟨Name⟩ ⟧ | ⟦ ⟨Tmp⟩ ⟧ ;

sort A_Progr | scheme ⟦ CG ⟨I_Progr⟩ ⟧ ;

⟦ CG ⟧ → ⟦⟧ ;

⟦ CG T = ⟨I_Arg#1⟩ + ⟨I_Arg#2⟩ ; ⟨I_Progr#⟩ ⟧
  → ⟦ ADDF T, [⟨I_Arg#1⟩], [⟨I_Arg#2⟩] CG ⟨I_Progr#⟩ ⟧ ;

⟦ CG T = ⟨I_Arg#1⟩ * ⟨I_Arg#2⟩ ; ⟨I_Progr#⟩ ⟧
  → ⟦ MULF T, [⟨I_Arg#1⟩], [⟨I_Arg#2⟩] CG ⟨I_Progr#⟩ ⟧ ;
  
⟦ CG T = ⟨I_Arg#1⟩ ; ⟨I_Progr#⟩ ⟧
  → ⟦ LDF T, [⟨I_Arg#1⟩] CG ⟨I_Progr#⟩ ⟧ ;

⟦ CG name = T ; ⟨I_Progr#⟩ ⟧
  → ⟦ STF name, T CG ⟨I_Progr#⟩ ⟧ ;

sort A_Arg | scheme ⟦ [⟨I_Arg⟩] ⟧ ;
⟦ [T] ⟧ → ⟦ T ⟧ ;
⟦ [name] ⟧ → ⟦ name ⟧ ;
⟦ [⟨FLOAT#1⟩] ⟧ → ⟦ #⟨FLOAT#1⟩ ⟧ ;
⟦ [⟨INT#1⟩] ⟧ → ⟦ #⟨INT#1⟩ ⟧ ;
\end{hacs}
  \caption{Code Generation.}
  \label{fig:cgen}
\end{figure}

\begin{example}\label{ex:cgen}
  The seventh part of \emph{First.hx} is the final translation "CG" from the intermediate
  representation to assembly code. This uses no new features, and is shown in Fig.~\ref{fig:cgen},
  however, it is still worth a sanity check, walking through the "CG" scheme and checking that all
  syntactic cases are covered.
\end{example}

\begin{remark}[concrete \emph{vs.} raw syntax]
  In the presentation we have chosen to use \emph{concrete syntax} even for semantic
  operations. This has the advantage of allowing direct invocation of even complex structured
  calculations from the command line but it does ``pollute'' the syntax of the defined language.
  (Production versions of \HAX (not yet released) will have the option of generating parsers that
  ignore concrete syntax of schemes when running the compiler.) It is sometimes practical to define
  ``bridge schemes'' that make schemes available both in syntax and raw; we give an example of this
  in the following section.
\end{remark}


\appendix\small

\section{Manual}\label{app:manual}

\begin{manual}[grammar structure]\label{man:structure}
  A \HAX compiler is specified as a single \emph{.hx} module file with the following structure:
  %%
\begin{hacs}[mathescape,xleftmargin=\parindent]
module $\text{\it\color{blue}modulename}$
{
  $\text{\it\color{blue}Declarations}$
}
\end{hacs}
  %%
  where the \emph{modulename} should be a Java style fully qualified class name with the last
  component is capitalized, like \verb|org.crsx.hacs.samples.First|. The individual sections specify
  the compiler, and the possible contents is documented in the manual blocks throughout this
  document.
\end{manual}

\begin{manual}[lexical declarations]\label{man:token}
  %%
  A token is declared with the keyword "token" followed by the token (sort) name, a "|" (vertical
  bar), and a \emph{regular expression}, which has one of the following forms (with increasing order
  of precedence):
  %%
  \begin{enumerate}

  \item Several alternative regular expressions can be combined with further "|" characters.

  \item Concatenation denotes the regular expression recognizing concatenations of what matches the
    subexpressions.

  \item A regular expression (of the forms following this one) can be followed by a \emph{repetition
      marker}: "?" for zero or one, "+" for one or more, and "*" for zero or more.

  \item A simple word without special characters stands for itself.

  \item A string in single or double quotes stands for the contents of the string except that "\"
    introduces an \emph{escape code} that stands for the encoded character in the string (see next item).

  \item A stand-alone "\" followed by an \emph{escape code} stands for that character: escape codes
    include the usual C and Java escapes: "\n", "\r", "\a", "\f", "\t", octal escapes like "\177",
    special character escapes like "\\", "\'", \hacsc|\"|, and Unicode hexadecimal escapes like
    "\u27e9".

  \item A \emph{character class} is given in "[ ]", with these rules:
   \begin{enumerate}
    \item if the first character is "^" then the character class is negated;
    \item if the first (after "^") character is "]" then that character is (not) permitted;
    \item a "\" followed by an \emph{escape code} is encountered then it stands for the encoded
      character;
    \item two characters connected with a "-" (dash) stands for a single character in the indicated
      (inclusive) \emph{range}.
    \end{enumerate}
    Note that a character class cannot be empty, however, "[^]" is permitted and stands for all
    characters.

  \item The "." (period) character stands for the character class "[^\n]".

  \item A nested regular expression can be given in "( )".

  \item An entire other token "T" can be included (by literal substitution, so recursion is not
    allowed) by writing "⟨T⟩" (the angle brackets are unicode characters U+27E8 and U+27E9). Tokens
    declared with "token fragment" can \emph{only} be used this way.

  \item The special declaration "space" defines what constitutes white space for the generated
    grammar. (Note that this does not influence what is considered space in the specification
    itself, even inside syntax productions.) A spacing declaration permits the special alternative
    "nested" declaration for nested comments, illustrated by the following, which defines usual
    C/Java style spacing with comments as used by \HAX itself:
\begin{hacs}[xleftmargin=\parindent]
space [ \t\f\r\n] | nested "/*" "*/" | "//" .* ;
\end{hacs}

  \end{enumerate}
  %%
  Notice that spacing is not significant in regular expressions, except (1) in character classes,
  (2) in literal strings, and (3) if escaped (as in "\ ").
  %%
\end{manual}

\begin{manual}[syntactic sorts]\label{man:syntax}
  %%
  Formally, \HAX uses the following notations for specifying the syntax to use for terms.
  %%
  \begin{enumerate}

  \item \HAX \emph{production names} are capitalized words, so we can for example use "Exp" for the
    production of expressions.  The name of a production also serves as the name of its \emph{sort},
    \ie, the semantic category that is used internally for abstract syntax trees with that root
    production.  If particular instances of a sort need to be referenced later they can be
    \emph{disambiguated} with a "#"$i$ suffix, \eg, "Exp#2", where $i$ is an optional number or
    other simple word.

  \item A sort is declared by one or more "sort" declarations of the name optionally followed by a
    number of \emph{abstract syntax production} alternatives, each starting with a~"|". A sort
    declaration sets the \emph{current sort} for subsequent declarations and in particular any
    stand-alone production alternatives. All sort declarations for a sort are cumulative.

  \item Double square brackets "⟦…⟧" (unicode U+27E6 and U+27E7) are used for \emph{concrete syntax}
    but can contain nested angle brackets "⟨…⟩" (unicode U+27E8 and U+27E9) with \emph{production
      references} like "⟨Exp⟩" for an expression (as well as several other things that we will come
    to later).  We for example write "⟦⟨Exp⟩+⟨Exp⟩⟧" to describe the form where two expressions are
    separated by a "+" sign.

  \item Concrete syntax specification can include "¶" characters to indicate where \emph{newlines}
    should be inserted in the printed output. (The system can also control indentation but that is
    not enabled yet.)

  \item A trailing "@"$p$ for some precedence integer $p$ indicates that either the subexpression or
    the entire alternative (as appropriate) should be considered to have the indicated precedence,
    with higher numbers indicating higher precedence, \ie, tighter association.  (For details on the
    limitations of how the precedence and left recursion mechanisms are implemented, see
    Appendix~\ref{app:limits}.)

  \item "sugar ⟦…⟧→…" alternatives specify equivalent forms for existing syntax: anything matching
    the left alternative will be interpreted the same as the right one (which must have been
    previously defined); references must be disambiguated.

  \item If a production contains only a reference to a token, where furthermore the token is defined
    such that it can end with "_"$n$ (an underscore followed by a count), then the sort can be
    qualified as a "symbol" sort, which can be used for variables and binders.

  \end{enumerate}
  %%
\end{manual}

\begin{manual}[parsed terms]\label{man:parsed}
  Man.~\ref{man:raw} documented terms without concrete syntax. The full term model combines this
  with \emph{parsed terms}.
  %%
  \begin{enumerate}

  \item Double square brackets "⟦…⟧" (unicode U+27E6 and U+27E7) can be used for \emph{concrete
      terms}, provided the \emph{sort} is clear, either
    \begin{enumerate}
    \item by immediately prefixing with the sort (as in "Exp⟦1+2⟧"), or
    \item by using as the argument of a defined constructor (as "IsType(⟦mytype⟧)"), or
    \item by usng as an attribute value, or
    \item by using as a top level rule pattern or replacement term with a defined current sort.
    \end{enumerate}

  \item Concrete terms can contain nested raw terms in "⟨…⟩" (unicode U+27E8 and U+27E9). Such
    nested raw terms \emph{must} have an explicit sort prefix.

  \item The special term "error⟦…⟧" will print the error message embedded in "⟦…⟧", where one is
    permitted to embed "symbol"-declared variables in "⟨…⟩".

  \end{enumerate}

\end{manual}

\begin{manual}[raw terms, schemes, and rules]\label{man:raw}
  %%
  ``Raw'' declarations consist of the following elements:
  %%
  \begin{enumerate}

  \item A \emph{constructor} is a capitalized word (similar to a sort name but in a separate name
    space).

  \item A \emph{variable} is a lower case word (subject to scoping, described below).

  \item A sort can be given a \emph{semantic production} as a "|" (bar) followed by a \emph{form},
    which consists of a constructor name, optionally followed by a list of the subexpression sorts
    in parenthesis.

%%% "()"ed ","-separated list of
%%%    \emph{scope forms}, which each consist of a \emph{sort} optionally preceded by a \emph{binder
%%%      form}, which is a list of sorts followed by a "." (dot). Thus in the most general case, a
%%%    semantic production has the form
%%%    %%
%%%    \begin{equation*}
%%%      \texttt{|}~C~\texttt{(}
%%%      %~[S_{11},\cdots,S_{1n_1}]~S_1~\texttt{,}
%%%      …~\texttt{,}
%%%      ~S_{m1}\cdots S_{mn_m}~\texttt{.}~S_m
%%%      \texttt{)}
%%%    \end{equation*}
%%%    %%
%%%    with $C$ a constructor name and all $S_i$ and $S_{ij}$ sort names. The $S_i$ declares the
%%%    \emph{argument sort} for the $i$th argument of the construction term, and the $S_{ij}$ is the
%%%    \emph{binder sort} of the $j$th binder for the $i$th argument; $m$ is the \emph{arity} of the
%%%    construction and $n_i$ the \emph{rank} of the $i$th argument.

  \item A semantic production can be qualified as a "scheme", which marks the declared construction
    as a candidate for rewrite rules (defined below).

  \item A \emph{raw term} is either a \emph{construction}, a \emph{variable use}, or a
    \emph{meta-application}, as follows
    %%
    \begin{enumerate}

    \item A \emph{construction} term is a constructor name followed by an optional "()"ed
      ","-separated list of subterms.

%%% \emph{scope arguments}, which each consist of a term optionally preceded
%%%      by a \emph{binder list}, which is a list of variables followed by a "." (dot).  So in the most
%%%      general case, a term looks like this:
%%%      %% 
%%%      \begin{equation*}
%%%        C~\texttt{(}
%%%        ~x_{11}\cdots x_{1n_1}~\texttt{.}~t_1~\texttt{,}
%%%        ~…\texttt{,}
%%%        ~x_{m1}\cdots x_{mn_m}~\texttt{.}~t_m
%%%        \texttt{)}
%%%      \end{equation*}
%%%      %%
%%%      The ``$C$-construction'' is said to have the \emph{subterms} $t_1,…,t_m$, and the arity $m$
%%%      and ranks $n_1…n_m$ must correspond to a semantic production.  If present, the binder prefix
%%%      of each introduces the specified variables \emph{only} for the appropriate subterm modulo
%%%      usual renaming, \ie, writing \texttt{A(x y.x, x y.y)} and \texttt{A(a b.a, a b.b)} and even
%%%      \texttt{A(s t.s, t s.s)} all denote the same term following the conventions of
%%%      \emph{α-equivalence}.  In a scope argument $x\texttt{.}t$ we say that occurrences of $x$ in
%%%      $t$ are \emph{bound} by the binder.

    \item A \emph{variable use} term is a variable, subject to the usual lexical scoping rules.

    \item A \emph{meta-application} term is a \emph{meta-variable}, consisting of a "#" (hash)
      followed by a number or word and optionally by a meta-argument list of ","-separated terms
      enclosed in "[]". Examples include "#t1" (with no arguments), "#[a,b,c]", and "#1[OK,#]".

    \end{enumerate}

  \item A term can have a \emph{sort prefix}. So the term "Type Unif(Type #t1, Type Float)" is the
    same as "Unif(#t1,Float)" provided "Unif" was declared with the raw production
    "|Unif(Type,Type)".

  \item A \emph{rewrite rule} is a pair of terms separatede by "→" (arrow, U+2192), with a few
    additional constraints: in the rule $p→t$, $p$ must be a \emph{pattern}, which means it must be
    a construction term that has been declared as a "scheme" (syntactic or raw) and with the
    restriction that all contained arguments to meta-applications must be bound variables, and all
    meta-applications in $t$ must have meta-variables that also occur in $p$ with the same number of
    meta-arguments.

    Rule declarations must either occur with the appropriate current sort or have a pattern with a
    sort prefix.

  \item One rule per scheme can be prefixed with the qualifier "default". If so then the pattern can
    have no structure: all subterms of the pattern scheme construction must be plain
    meta-applications. Such a default rule is applied \emph{after} it has been ensured that all
    other rules fail for the scheme.

  \item Finally, a rule can be prefixed with the word "rule" for clarity, which can be followed by a
    raw term and a ":" (TODO: document possible name/option choices).

  \end{enumerate}
  %%
  Rules are used for \emph{rewriting}, a definition of which is beyond the scope of this document;
  please refer to the literature on higher order rewriting for details~\cite{Klop+:tcs1993}.
  %%
\end{manual}

\begin{manual}[attributes and synthesis rules]\label{man:attributes}\leavevmode
  %%
  \begin{enumerate}

  \item Attributes are declared by "attribute" declarations followed by an \emph{attribute form} of
    one of the following shapes:
    %%
    \begin{enumerate}
    \item "↑Name(ValueSort)" defines that the synthesized attribute "Name" has "ValueSort" values;
    \item "↓Name(ValueSort)" similarly for a simple inherited attribute;
    \item "↓Name{SymbolSort:ValueSort}" defines the inherited symbol table attribute "Name" which
      for each constant or variable of "SymbolSort" has a distinct "ValueSort" value.
    \end{enumerate}

  \item One can add a simple \emph{synthesized attributes} after a raw data term as
    "↑"\emph{name}"("\emph{value}")", where the \emph{name} is an attribute name and the
    \emph{value} can be any term.

  \item Simple \emph{inherited attributes} are added similarly after a raw scheme term as
    "↓"\emph{name}"("\emph{value}")".

  \item An \emph{inherited symbol table attribute extension} is added to a raw scheme term as
    "↓"\emph{name}"{"\emph{symbol}":"\emph{value}"}", where the \emph{symbol} is either a variable
    or a constant (of the appropriate sort).

  \item A \emph{synthesized attribute reference} has the simple form "↑"\emph{name}";" and declares
    that the current sort synthesizes \emph{name} attributes.

  \item A scheme declaration can include \emph{inherited attribute references} of the form
    "↓"\emph{name}, which declares that the scheme inherits the \emph{name} attributes.

  \item A \emph{synthesis rule} is a special rule of the form $t↑name(t')$, where the term $t$ may
    contain subterms with attribute constraints. The rule specifies how terms of the current sort
    and shape $t$ synthesize \emph{name} attributes.

  \end{enumerate}
  %%
  Inherited attributes are managed with regular rules (for schemes) with inherited attribute
  constraints and extensions.
  %%
\end{manual}

\begin{manual}[building and running]\label{man:run}\leavevmode
  %%
  To use \HAX you need a copy of the \emph{hacs} directory somewhere.

  where you have replaced \texttt{\textcolor{blue}{\emph{hacs}}} with the path to the \HAX directory
  on your system (as written the system expects to find \emph{hacs} as a local subdirectory of your
  working directory). With this setup, and a suitable \emph{mycompiler.hx}, you have the following
  options:
  %%
  \begin{enumerate}

  \item "hacs Mycompiler.run" will generate the script \emph{Mycompiler.run}, which implements the
    compiler you specify in \emph{Mycompiler.hx} (with presumed class name Mycompiler). Generation
    creates a number of support files, specifically
    \begin{enumerate}
    \item \emph{build} subdirectory has runtime resources needed by the script.
    \item \emph{src} subdirectory contains auxiliary Java resources used by the build process.
    \item \emph{mycompiler.crs-installed} and \emph{mycompiler.pg-installed} record when the
      generated parser and rewrite system were installed.
    \end{enumerate}
    Note that the first time, some utility programs are compiled from C to ensure that \HAX is fully
    enabled on your system.

  \item "make clean" will remove all temporaries not needed for running the compiler script.

  \item "make realclean" will remove all traces of the generated compiler.

  \item "make distclean" will remove all traces of the generated compiler as well as all generated
    \HAX tooling files. Do not do this unless you really mean it: recovering a useable \HAX system
    requires getting a fresh copy of \emph{hacs.zip} or half an hour of CPU time on nontrivial
    hardware.

  \end{enumerate}
  %%
  The generated script refers absolutely to files under the \emph{hacs} directory, so the generated
  \emph{mycompiler.run} script itself can be moved but the \emph{hacs} directory cannot.

  The script accepts a number of options:
  %% 
  \begin{enumerate}

  \item "--sort="\emph{Sort} sets the expected sort (and thus parser productions) for the input to
    \emph{Sort}. The input is read, normalized, and printed.

  \item "--scheme="\emph{Constructor} sets the computation for the compiler to \emph{Constructor},
    which must be a unary raw scheme; the argument sort of \emph{Constructor} defines the parser
    productions to use.  The input is read, wrapped in the action, normalized, and printed.

  \item "--term="\emph{term} use the \emph{term} as the input.

  \item "--input="\emph{file} reads the input from \emph{file}.

  \item "--output="\emph{file} sends the input to \emph{file} (the default is the standard output).

  \item "--verbose="\emph{n} sets the verbosity of the underlying \CRSX rewrite engine to $n$. The
    default is 0 (quiet) but 1--3 are useful (above 3 you get a lot of low level diagnostic output).

  \item "--parse-verbose" activates verbose output from JavaCC of the parsing.

  \end{enumerate}
  %%
  You must provide one of "--sort" or "--action", and one of "--term" and "--input".

  \HAX will eventually contain a convention for defining ``main'' sorts and schemes such that
  defaults can be provided for the configuration options.
\end{manual}


%%% \section{Bonus Examples}\label{appbonus}
%%% 
%%% Some additional \emph{untested} examples. \emph{Note: still need to be worked through.}
%%% 
%%% \begin{example}[\emph{hacs/samples/Bool.hx}]\leavevmode
%%% \inputhacs{../samples/Bool.hx}
%%% \end{example}
%%% 
%%% \begin{example}[\emph{hacs/samples/Deriv.hx}]\leavevmode
%%% \inputhacs{../samples/Deriv.hx}
%%% \end{example}


\section{Common Errors}\label{app:errors}

\begin{error}[\HAX syntax]\leavevmode
\begin{code}
Exception in thread "main" java.lang.RuntimeException: net.sf.crsx.CRSException:
 Encountered " "." ". "" at line 35, column 6.
Was expecting one of:
    <MT_Repeat> ...
    "%Repeat" ...
    <MT_Attributes> ...
\end{code}
  Indicates a simple syntax errors in the \emph{.hx} file.
\end{error}

\begin{error}[user syntax]\leavevmode
\begin{code}
Exception in thread "main" java.lang.RuntimeException:
  net.sf.crsx.CRSException: net.sf.crsx.parser.ParseException:
mycompiler.crs: Parse error in embedded myDecSome term at line 867, column 42:
 ⟦ $TA_Let2b ⟨Dec (#d)⟩{ ⟨DecSome (#ds)⟩} ⟧ at line 867, column 42
 Encountered " "\u27e9" "\u27e8Dec (#d)\u27e9 "" at line 867, column 53
…
\end{code}
  This indicates a concrete syntax error in some parsed syntax---inside "⟦…⟧"---in the \emph{.hx}
  file. The offending fragment is given in double angles in the message. Check that it is correctly
  entered in the \HAX specification in a way that corresponds to a syntax production. Note that the
  line/column numbers refer to the generated \emph{build/…Rules.crs} file, which us not immediately
  helpful (this is a known bug). In error messages a sort is typically referenced as a lower case
  prefix followed by the sort name---here "myDecSome" indicates that the problem is with parsing the
  "DecSome" sort of the "My" parser.
\end{error}

\begin{error}[JavaCC noise]\leavevmode
\begin{code}
Java Compiler Compiler Version ??.??_?? (Parser Generator)
(type "javacc" with no arguments for help)
Reading from file net/sf/crsx/samples/gentle/FirstParser.jj . . .
Warning: Line 769, Column 51: Non-ASCII characters used in regular expression.
Please make sure you use the correct Reader when you create the parser,
 one that can handle your character set.
File "TokenMgrError.java" does not exist.  Will create one.
File "ParseException.java" does not exist.  Will create one.
File "Token.java" does not exist.  Will create one.
File "SimpleCharStream.java" does not exist.  Will create one.
Parser generated with 0 errors and 1 warnings.
Note: net/sf/crsx/samples/gentle/FirstParser.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
\end{code}
  These are ``normal'' messages from JavaCC.
\end{error}

\begin{error}[missing library]\leavevmode
\begin{code}
gcc -std=c99 -g    -c -o crsx_scan.o crsx_scan.c
crsx.c:11:30: fatal error: unicode/umachine.h: No such file or directory
\end{code}
  The \HAX tools only use one library in C: ICU. You should get the \emph{libicu-dev} package (or
  similar) for your system.
\end{error}

\begin{error}[meta-variable mistake]\leavevmode
\begin{code}
Error in rule Tiger-Ty2222222222111_9148-1: contractum uses undefined meta-variable (#es)
Errors prevent normalization.
make: *** [pr3.crs-installed] Error 1
\end{code}
  A rule uses the metavariable "#es" in the replacement without defining it in the corresponding
  pattern.
\end{error}

\begin{error}[]\leavevmode
\begin{code}
/home/krisrose/Desktop/teaching/.../hacs/cookmain PG pr3.hxt > pr3.pg
cookmain: crsx.c:528: bufferEnd: Assertion
   `(((childTerm)->descriptor == ((void *)0)) ? 0 :
        (childTerm)->descriptor->arity) == bufferTop(buffer)->index' failed.
/bin/sh: line 1: 14278 Aborted
  (core dumped) /home/krisrose/Desktop/teaching/.../hacs/cookmain PG pr3.hxt > pr3.pg
\end{code}
  This indicates an arity error: a raw term in the \emph{.hx} file does not have the right number of
  arguments.
\end{error}


\section{Limitations}\label{app:limits}

\begin{itemize}

\item At most one "nested" declaration per "token".

\item Precedence can only be used on self references, \ie, "⟨E@2⟩" can only occur inside
  productions for the sort "E".

\item It is not possible to use binders and left recursion in the same production with the same
  precedence.

\item Only \emph{direct} left recursion is currently supported, \ie, the left recursion should be
  within a single production.<

\item Productions can share a prefix but only within productions for the same sort, and the prefix
  has to be literally identical unit by unit, \ie,
  \begin{code}
sort S | ⟦ ⟨A⟩ then ⟨B⟩ then C ⟧
       | ⟦ ⟨A⟩ then ⟨B⟩ or else D ⟧ ;
\end{code}
is fine but
\begin{code}
sort S | ⟦ ⟨A⟩ then ⟨B⟩ then C ⟧
       | ⟦ ⟨A⟩ ⟨ThenB⟩ or else D ⟧ ;
sort ThenB | ⟦ then ⟨B⟩ ⟧;
\end{code}
is not.

\item It is not possible to left-factor a binder (so multiple binding constructs cannot have the
  same binder prefix).

\item Variables embedded in "error⟦…⟧" instructions must start with a lower case letter.

\item When using the "symbol" qualifier on a reference to a token then the token \emph{must} allow
  ending in "_"$n$ for $n$ any natural number.

\item When using the same name for a symbol inside of "⟦…⟧" and the corresponding raw variable
  outside of the ⟦⟧, then the common symbol and variable name must be a plain word starting with a
  lower case letter.

\item Special terms like "error⟦…⟧" cannot be used as raw subterms.

\item The "default" rule qualifier is rather fragile and does not yet always work.

\end{itemize}


\bibliography{crs}


\end{document}


%% $Log: hacs-gently.tex,v $
%% Revision 1.29  2014/02/11 15:49:11  krisrose
%% Hash.crs fixed to allow linear use of hash.
%%
%% Revision 1.28  2014/01/26 21:14:34  krisrose
%% Compiled NumericEqual primitive fixed for rounding errors.
%%
%% Revision 1.27  2014/01/21 18:40:46  krisrose
%% Regenerated rulecompiler.
%%
%% Revision 1.26  2014/01/16 14:07:17  krisrose
%% Update compiled $[Decimal] to also handle double.
%%
%% Revision 1.25  2013/12/05 04:10:03  krisrose
%% Manual fix.
%%
%% Revision 1.24  2013/12/03 21:41:55  krisrose
%% Update of hacs.zip.
%%
%% Revision 1.23  2013/12/02 12:21:21  krisrose
%% Option fixes.
%%
%% Revision 1.22  2013/11/25 06:35:09  krisrose
%% HACS cleanup.
%%
%% Revision 1.21  2013/11/21 21:10:55  krisrose
%% Duplicate table row removed.
%%
%% Revision 1.20  2013/11/21 06:19:39  krisrose
%% HACS documentation rough version done.
%%
%% Revision 1.19  2013/11/21 04:01:32  krisrose
%% Newline support in HACS.
%%
%% Revision 1.18  2013/11/20 05:08:17  krisrose
%% HACS functional.
%%
%% Revision 1.17  2013/11/19 21:00:12  krisrose
%% first.hx refactored for hacs-gently runs again.
%%
%% Revision 1.16  2013/11/18 02:28:07  krisrose
%% HACS fully functional.
%%
%% Revision 1.15  2013/11/17 03:20:20  krisrose
%% reify option respects simple-terms.
%% Main .dr not output when modules generated.
%%
%% Revision 1.14  2013/10/30 04:28:28  krisrose
%% HACS synthesized attributes almost ready!
%%
%% Revision 1.13  2013/10/21 18:02:12  krisrose
%% HACS attribute grammar fixed.
%%
%% Revision 1.12  2013/10/17 16:51:43  krisrose
%% Locify avoids $[PassLocationProperties] when possible.
%%
%% Revision 1.11  2013/10/12 21:35:40  krisrose
%% Location and HACS work.
%% Checkpoint before major attribute distribution fix.
%%
%% Revision 1.10  2013/10/06 15:38:28  krisrose
%% First attempt at VariableUse with propserties.
%% Preparing for HACS for unmetaness.
%%
%% Revision 1.9  2013/09/30 11:06:42  krisrose
%% All HACS examples work again.
%%
%% Revision 1.8  2013/09/29 05:49:58  krisrose
%% Attributes next...
%%
%% Revision 1.7  2013/09/27 10:05:12  krisrose
%% Document RegExps.
%%
%% Revision 1.6  2013/09/25 17:14:15  krisrose
%% Change default action to Drop.
%%
%% Revision 1.5  2013/09/20 08:32:04  krisrose
%% Formatting.
%%
%% Revision 1.4  2013/09/20 08:17:57  krisrose
%% Drop diagnostic output.
%%
%% Revision 1.3  2013/09/20 08:11:58  krisrose
%% jar refresh
%%
%% Revision 1.2  2013/09/20 08:03:50  krisrose
%% Ready for the NYU students...
%%
%% Revision 1.1  2013/09/18 14:42:24  krisrose
%% Moved 'dragon' to 'gentle'.
%%
%% New.

%%---------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% End:
