%% Introduction to HACS.
%%
\documentclass[11pt]{article} %style: font size.
\input{setup}

%% Style.
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage{charter}
\SelectTips{eu}{}
\bibliographystyle{plainurl}

%% Topmatter.
\def\version{0.9.16\xspace}
\title{
  Compiler Generation Using \HAX%
  \thanks{This version describes \HAX β version \version released for use at NYU. This printing \today.}
}
\author{
  Kristoffer H. Rose\\
  Two Sigma Investments/New York University
}

\begin{document}
\maketitle

\begin{abstract}\noindent
  Higher-order Attribute Contraction Schemes---or \HAX---is a language for programming compilers.
  With \HAX it is possible to create a fully functional compiler from a single source file.  This
  document explains how to get \HAX up and running, and walks through the code of a simple example
  with each of the main stages of a compiler in \HAX: lexical analysis, syntax analysis, semantic
  analysis, and code generation.
\end{abstract}

\compacttableofcontents


\section{Introduction}\label{sec:intro}

\HAX abbreviates \emph{Higher-order Attribute Contraction Schemes}, which is a formal system for
symbolic rewriting extended with programming idioms commonly used when coding compilers. \HAX is
developed as a front-end to the \CRSX higher-order rewriting engine~\cite{crsx}.

A compiler written in \HAX consists of a single \emph{specification file} with a series of formal
sections, each corresponding to a stage of the compiler.  Each section is written in a formal style
suitable for that stage of the compiler. Specifically, \HAX supports the following notations:
%%
\begin{description}

\item[Regular Expressions.] Used to describe how an input text is partitioned into
  \emph{tokens}. The regular expressions of \HAX follows common
  conventions~\cite{Aho+:2006}. Section~\ref{sec:tokens} gives details of this notation.

\item[Context Free Grammars.] \HAX uses a form of BNF~\cite{NaurEtal:cacm1960} \emph{context free
    grammars}; the notation has been tweaked to look more like \emph{templates} to allow for reuse
  of the notation in rewrite rules later. \HAX includes simple mechanisms for automatic resolution
  of operator precedence and productions using immediate recursion such that the transformation from
  token stream to abstract syntax can be formalized. Details in Section~\ref{sec:syntax}.

\item[Recursive Translation Schemes.] Simple translations in general, and code generation in
  particular, are traditionally achieved by \emph{recursive translation} from one abstract form to
  another.  \HAX includes special notations for defining such translations, as well as a mechanism
  for defining auxiliary so-called ``semantic sorts,'' detailed in Section~\ref{sec:schemes}.

\item[Attribute Grammars.] Analyses can be described with attribute grammars in the style of
  \emph{Syntax-Directed Definitions}~\cite{Aho+:2006}, originally introduced as \emph{attribute
    grammars}~\cite{Knuth:mst1968}, which describe how properties propagate through the abstract
  syntax tree.  Section~\ref{sec:collect} details how the basic propagation rules work for
  synthesized attributes, Section~\ref{sec:sdd} explains how inherited atributes are integrated such
  that full syntax-directed definitions can be encoded.

%%%  Section~\ref{sec:advanced} summarizes the special considerations needed when managing scoped
%%%  symbols and binders using \emph{higher-order abstract syntax}.

\end{description}
%%
In the remainder of this document we introduce the most important features of the \HAX language by
explaining the relevant parts of the included \emph{First.hx} example, inspired by
\cite[Figure~1.7]{Aho+:2006}, as well as several other minor examples. %
We first show in Section~\ref{sec:run} how to install \HAX and run the example, before we go on to
how to write specifications. %
We explain lexical analysis in Section~\ref{sec:tokens}, %
syntax analysis in Section~\ref{sec:syntax}, %
basic semantic sorts and recursive translation schemes in Section~\ref{sec:schemes}, %
bottom-up semantic analysis in Section~\ref{sec:collect}, %
and general syntax-directed definitions in Section~\ref{sec:sdd}. %
In Section~\ref{sec:comp} we explain how primitive values can be manipulated, %
and in Section~\ref{sec:examples} we give several examples of how everything can be combined.

%%and advanced features in Section~\ref{sec:advanced}. %
Appendix~\ref{app:manual} has a reference manual, %
%% Appendix~\ref{app:bonus} has some bonus examples, %
Appendix~\ref{app:errors} explains some of the (still) cryptic error messages, %
and Appendix~\ref{app:limits} lists some current limitations.


\section{Getting Started}\label{sec:run}

In this section we walk through the steps for getting a functional \HAX installation on your
computer.\footnote{\HAX is still a β release so please report any problems with this procedure to
  \emph{hacs-bugs@crsx.org}.}

\begin{requirements}
  To run the \HAX examples here you need a *nix system (including a shell and the usual utilities)
  with these common programs: a Java development environment (at least Java~1.6~SE SDK, with "java"
  and "javac" commands); and a standard *nix development setup including GNU Make and a C99
  compiler. In addition, the setup process needs internet access to retrieve the \CRSX base
  system~\cite{crsx}, JavaCC parser generator~\cite{JavaCC}, and \emph{icu} Unicode C
  libraries~\cite{ICU}.
\end{requirements}

\begin{commands}[install \HAX]\label{com:all}
  Retrieve the \emph{hacs-\version.zip} archive, extract it to a new directory, and install it, for
  example with the following commands:\footnote{User input is \textcolor{blue}{blue}.}
  %%
\begin{code}[commandchars=\^\{\}]
energon1[~]$ ^textcolor{blue}{^texttt{wget http://crsx.org/hacs-^version.zip}}
energon1[~]$ ^textcolor{blue}{^texttt{unzip hacs-^version.zip}}
energon1[~]$ ^textcolor{blue}{^texttt{cd hacs}}
energon1[hacs]$ ^textcolor{blue}{^texttt{make FROMZIP=1 install install-support}}
\end{code}
  %%
  These commands will need Internet access, using the wget command to retrieve support
  libraries.\footnote{Specifically, \HAX needs the \CRSX system, JavaCC parser generator, and ICU4C
    Unicode library. The setup is documented in \emph{src/Env.mk}.} The above command will install
  \HAX in a \emph{.hacs} subdirectory of your home directory. You can change this with the option
  \verb|prefix=|…  to (all uses of) \emph{make}; if so then make sure to replace occurrences of
  \verb|$HOME/.hacs| everywhere below with your chosen directory.

  The main \emph{make} command will take some time (of the order of 3 minutes) but should end
  without error.

  The following command makes the main \emph{hacs} command available for use:
  %%
\begin{code}[commandchars=\^\{\}]
energon1[hacs]$ ^textcolor{blue}{^texttt{alias hacs=$HOME/.hacs/bin/hacs}}
\end{code}
  %%
  (It may be worth including this command in your setup, or including the \verb|$HOME/.hacs/bin|
  directory in your \verb|$PATH|.)

  Please check that your new installation works with these commands:
\begin{code}[commandchars=\^\{\}]
energon1[hacs]$ ^textcolor{blue}{^texttt{cd}}
energon1[~]$ ^textcolor{blue}{^texttt{mkdir myfirst}}
energon1[~]$ ^textcolor{blue}{^texttt{cd myfirst}}
energon1[~]$ ^textcolor{blue}{^texttt{cp $HOME/.hacs/share/doc/hacs/examples/First.hx .}}
energon1[~]$ ^textcolor{blue}{^texttt{$HOME/.hacs/bin/hacs First.hx}}
energon1[~]$ ^textcolor{blue}{^texttt{./First.run --scheme=Compile \}}
           ^textcolor{blue}{^texttt{--term="^{initial := 1; rate := 1.0; position := initial + rate * 60;^}"}}
  LDF T_2,  #1 
    STF initial, T_2
    LDF T_2_37,  #1.0 
    STF rate, T_2_37
    LDF T_3,  initial 
    LDF T_3_42,  rate 
    LDF T_4,  #60 
    MULF  T_4_71 ,  T_3_42 ,  T_4 
    ADDF  T_2_49 ,  T_3 ,  T_4_71 
    STF position, T_2_49
\end{code}
  %%
  Congratulations---you just built your first compiler!\footnote{Please do not mind the spacing --
    that is how \HAX prints in its present state.}
\end{commands}

\begin{example}[module wrapper]%
  The source file for the \emph{First.hx} file used in the example above has the structure
  %%
\begin{hacs}[mathescape,xleftmargin=\parindent]
/* Top comment. */
module org.crsx.hacs.samples.First
{
  // Remark.
  $\text{\it Lexical Analysis (Section~\ref{sec:tokens})}$
  $\text{\it Syntax Analysis (Section~\ref{sec:syntax})}$
  $\text{\it Semantic Analysis (Sections \ref{sec:schemes}, \ref{sec:collect} and \ref{sec:sdd})}$
  $\text{\it Code Generator (Section~\ref{sec:examples})}$
  $\text{\it Main (Section~\ref{sec:schemes})}$
}
\end{hacs}
  Notice that \HAX permits C/Java style comments.
\end{example}

\begin{table}[t]
  \begin{displaymath}
    \begin{tabular}{c|c|c}
      \hline
      \hline
      \emph{Glyph} & \emph{Code Point} & \emph{Character} \Bigstrut \\
      \hline
      {¬} & U+00AC & logical negation sign \\
      {×} & U+00D7 & multiplication sign \\
      {÷} & U+00F7 & multiplication sign \\
      {¶} & U+00B6 & paragraph sign \\
      \hline
      ↑ & U+2191 & upwards arrow \\
      → & U+2192 & rightwards arrow \\
      ↓ & U+2193 & downwards arrow \\
      \hline
      ⟦ & U+27E6 & mathematical left white square bracket \\
      ⟧ & U+27E7 & mathematical right white square bracket \\
      ⟨ & U+27E8 & mathematical left angle bracket \\
      ⟩ & U+27E9 & mathematical right angle bracket \\
      \hline
    \end{tabular}
  \end{displaymath}
  \caption{Unicode special characters used by \HAX.}
\label{tab:unicode}
\end{table}

\begin{notation}[special Unicode characters]\label{man:unicode}
  \HAX uses a number of special symbols from the standard Unicode repertoire of characters, shown in Table~\ref{tab:unicode}
\end{notation}


\section{Lexical Analysis}
\label{sec:tokens}

Lexical analysis is the process of splitting the input text into tokens. \HAX uses a rather standard
variation of \emph{regular expressions} for this.

\begin{example}[tokens and white space]\label{ex:lexical}
  %%
  Here is a \HAX fragment for setting up the concrete syntax of integers, basic floating point
  numbers, identifiers, and white space, for use by a simple language:
  %%
\begin{hacs}[xleftmargin=\parindent,numbers=right,texcl]
// White space convention.
space [ \t\n] ;

// Basic nonterminals.
token INT      | ⟨DIGIT⟩+ ;
token FLOAT    | ⟨DIGIT⟩* "." ⟨DIGIT⟩+ ;
token ID       | ⟨LOWER⟩+ ('_'? ⟨INT⟩)* ;

// Special categories of letters.
token fragment DIGIT  | [0-9] ;
token fragment LOWER  | [a-z] ;
\end{hacs}
  %%
  The example illustrates the following particulars of \HAX lexical expressions:
  %%
  \begin{itemize}

  \item Declarations generally start with a keyword or two and are terminated by a ";" (semicolon).

  \item "token" declarations in particular have the "token" keyword followed by a regular expression
    between a "|" (vertical bar) and a ";" (semicolon). It defines the token as a
    \emph{non-terminal} that can be used in syntax productions described in the next section.

  \item A regular expressions is a sequence of units, corresponding to the concatenation of
    sequences of characters that match each one.  Each unit can be a \emph{character class} such as
    "[a-z]", which matches a single character in the indicated range (or, more generally, a sequence
    of individual characters and ranges), a \emph{string} such as \hacsc|"."|, or a \emph{reference}
    to a token or fragment such as "⟨Lower⟩", enclosed in the special Unicode mathematical angle
    brackets (see Table~\ref{tab:unicode}).

  \item A "token fragment" declaration means that the defined token can only be used in other token
    declarations, and not as grammar non-terminal in syntax productions.

  \item Every regular expression component can be followed by a repetition marker "?", "+", or~"*",
    and regular expressions can be \emph{grouped} with parentheses.

  \item The regular expression for white space is setup by "space" followed by the regular
    expression of what to skip -- here spaces, tabs, and newlines, where \HAX uses backslash for
    escaping in character classes with usual C-style language escapes.

  \end{itemize}
  %%
  In addition, we have followed the convention of naming proper grammar terminals with ALL-CAPS
  names, like "INT", so they are easy to distinguish from non-terminals below.
  %%
\end{example}

Notice that while it is possible to make every keyword of your language into a named token in this
way, this is not necessary, as keywords can be given as literals in syntax productions, covered in
the next section.

\begin{commands}[lexical analysis]
  The fragment above is part of \emph{First.run} from Section~\ref{sec:intro}, which can thus be
  used as a lexical analyzer.  This is achieved by passing the \emph{First.run} command two
  arguments: a \emph{token sort} and a \emph{token term}.\footnote{The command has more options that
    we shall introduce as we need them.}  Execution proceeds by parsing the string following
  the syntax of the token. We can, for example, check the lexical analysis of a number:
\begin{code}[commandchars=\\\{\}]
$ \textcolor{blue}{./First.run --sort=FLOAT --term=34.56}
34.56
\end{code}
  If there is an error, the lexical analyzer will inform us of this:
\begin{code}[commandchars=^\{\}]
$ ^textcolor{blue}{./First.run --sort=INT --term=34.56}
Exception in thread "main" java.lang.RuntimeException: net.sf.crsx.CRSException:
  Encountered " <T_FLOAT> "34.56 "" at line 1, column 1.
Was expecting:
    <T_INT> ...
\end{code}
  (where the trail of Java exceptions has been truncated: the important information is in the first
  few lines).
\end{commands}


\section{Syntax Analysis}
\label{sec:syntax}

Once we have tokens, we can use \HAX to program a syntax analysis with a grammar that specifies how
the input text is decomposed according to a \emph{concrete syntax} and how the desired
\emph{abstract syntax tree} (AST) is constructed from that. Notice that \HAX does not provide a
``parse tree'' in the traditional sense, \ie, a tree that represents the full concrete syntax parse:
only the AST is built.  Grammars are structured following the \emph{sorts} of AST nodes, with
concrete syntax details managed through annotations and ``syntactic sugar'' declarations.

\begin{example}\label{ex:syntax}
  %%
  Here is another extract from our \emph{First.hx} example, with a small syntax analysis, or
  grammar. Our small example source language merely has blocks, assignment statements, and a few
  forms of expression, like so:
  %%
\begin{hacs}[xleftmargin=\parindent,xrightmargin=\parindent,numbers=right]
// Main program construct.
main sort Stat  | ⟦ ⟨Name⟩ := ⟨Exp⟩ ; ⟨Stat⟩ ⟧
                | ⟦ { ⟨Stat⟩ } ⟨Stat⟩ ⟧
                | ⟦⟧ ;

sort Exp  | ⟦ ⟨Exp⟩ + ⟨Exp@1⟩ ⟧
          | ⟦ ⟨Exp@1⟩ * ⟨Exp@2⟩ ⟧@1
          | ⟦ ⟨INT⟩ ⟧@2
          | ⟦ ⟨FLOAT⟩ ⟧@2
          | ⟦ ⟨Name⟩ ⟧@2
          | sugar ⟦ ( ⟨Exp#⟩ ) ⟧@2 → Exp# ;

sort Name | symbol ⟦⟨ID⟩⟧ ;
\end{hacs}
  %%
  The grammar structures the input as three sorts: "Stat" for statements, "Exp" for expressions, and
  "Name" for names (which we shall need later for symbol tables).
  %%
\end{example}

The example grammar above captures the \HAX version of several standard parsing notions:
\begin{description}

\item[Literal syntax] is indicated by the double ``syntax brackets,'' $⟦…⟧$.  Text inside $⟦…⟧$
  consists of three things only: space, literal character ``words,'' and references to non-terminals
  and predefined tokens inside (nested) $⟨…⟩$.  In this way, literal syntax is similar to macro
  notation or ``quasi-quotation'' of other programming languages.

\item[Syntactic sugar] is represented by the "sugar" part of the "Exp" sort declaration, which
  states that the parser should accept an "Exp" in parenthesis, identified as "#", and replace it
  with just that same "Exp", indicated by the "→ Exp#" part.  This avoids any need to think of
  parentheses in the generated AST.

\item[Precedence rules] are represented by the "@"-annotations, which assign precedence and
  associativity to each operator. Thus the same "Exp" language would be recognized by
  something like the following concrete \HAX specification (where we have also made the sugar
  concrete):
  %% 
\begin{hacs}[xleftmargin=\parindent]
sort Exp   | ⟦ ⟨Exp0⟩ ⟧ ;
sort Exp0  | ⟦ ⟨Exp0⟩ + ⟨Exp1⟩ ⟧ | ⟦ ⟨Exp1⟩ ⟧ ;
sort Exp1  | ⟦ ⟨Exp1⟩ * ⟨Exp2⟩ ⟧ | ⟦ ⟨Exp2⟩ ⟧ ;
sort Exp2  | ⟦ ⟨Int⟩ ⟧ | ⟦ ⟨Float⟩ ⟧ | ⟦ ⟨Name⟩ ⟧ | ⟦ ( ⟨Exp⟩ ) ⟧ ;
\end{hacs}%|
  %%
  However, this grammar generates a different result tree, where the nodes have the four
  different sorts used instead of all being of the single "Exp" sort that the precedence
  annotations make possible.  The transformed system also illustrates how \HAX deals with left
  recursion with "@"-annotations: each becomes an instance of \emph{immediate left recursion},
  which is eliminated automatically.

\end{description}
%%
The precedence notation allows us to define one sort per ``sort of abstract syntax tree node.''
This allows us to use a single kind of AST node to represent all the ``levels'' of expression, which
helps the subsequent steps.

The notation is admittedly dense: this is intentional, as we generalize this very same notation to
serve all the formalisms of the following sections.
Here are the formal rules:
%% 
\begin{itemize}

\item Each sort is defined by a "sort" declaration followed by a number of \emph{productions},
  each introduced by a "|" (bar). (The first "|" corresponds to what is usually written ``::='' or
  ``→'' in grammars.)

\item Concrete syntax is enclosed in "⟦…⟧" (``double'' or ``white'' brackets). Everything inside
  double brackets should be seen as \emph{literal syntax}, even "\" (backslash), \emph{except} for
  \HAX white space (corresponding to "[ \t\n\r]"), which is ignored, and references in "⟨…⟩" (angle
  brackets), which are special.

\item References to \emph{nonterminals} (other productions) are wrapped in "⟨…⟩" (angle brackets).

\item \emph{Precedence} is indicated with "@"$n$, where higher numbers $n$ designate higher
  (tighter) precedence. After every top-level "⟦⟧" and inside every "⟨⟩" there is a precedence,
  which defaults to "@0".

\item The special "sugar" declaration expresses that the concrete syntax can use parentheses to
  raise the precedence of the enclosed expression to~2: it is the first example of a \emph{rewrite
    rule} with a "→" that we see, where we remark that the expression is marked "#" so we can use
  "Exp#" to the right of the "→" to indicate that the result of simplifying concrete syntax with
  parenthesis.  (In fact the general rule is that when an "→" is used then all sort specifiers must
  be ``disambiguated'' with distinct markers like "#" or "#5" in this way.)

\item As a special case, A sort can be defined with a single "symbol" declaration. If so, then the
  actual syntax must refer to a single token, and that token must allow multiple trailing "_"$n$
  (underscore and count), which is added to any instance (this permits automatic symbol generation).

\end{itemize}
%%
Of all these rules, the one thing that is unique to parsing is the precedence notation with "@".
When specifying a grammar then \emph{every} subterm has a precedence, which determines how ambiguous
terms should be parsed. So imagine that every "⟨⟩" contains a "@" marker, defaulting to "@0", and
that every "⟦⟧" is terminated with a "@" marker, again defaulting to "@0".

Notice that \HAX will do two things automatically:
%%
\begin{enumerate}
\item Eliminate immediate left recursion, such as found in the example.
\item Split the productions into subproductions according to the precedence assignments.
\item Left factor the grammar, which means that productions within a sort may start with a common
  prefix.
\end{enumerate}
%%
However, this is \emph{not} reflected in the generated trees: they will follow the grammar as
specified, so you do not need to be aware that this conversion happens.

\begin{commands}
  %%
  We can parse an expression from the command line:
  %%
\begin{code}[commandchars=\\\{\}]
$ \textcolor{blue}{./First.run --sort=Exp --term="(2+(3*(4+5)))"}
2 + 3 * ( 4 + 5 )
\end{code}
  %%
  Notice that the printout differs slightly from the input term as it has been ``resugared'' from
  the AST with minimal insertion of parentheses.
  %%
\end{commands}


\section{Sorts and Recursive Translation Schemes}
\label{sec:schemes}

In this section we explain how basic algebraic structures and transformations are expressed in \HAX.

\begin{example}\label{ex:unif}
  %%
  Another fragment of the \emph{First.hx} example has the semantic sorts and operations that are
  used. For our toy language that just means the notion of a \emph{type} with the way that types are
  ``unified'' to construct new types.
  %%
\begin{hacs}[xleftmargin=\parindent,xrightmargin=\parindent,numbers=right]
// Types to associate to AST nodes.
sort Type | Int | Float ;

// The Type sort includes a scheme for unifying two types.
| scheme Unif(Type,Type) ;
Unif(Int, Int) → Int;
Unif(#1, Float) → Float;
Unif(Float, #2) → Float;
\end{hacs}
  %%
  The code declares a new sort, "Type", which is a \emph{semantic} sort because it does not include
  any syntactic cases: all the possible values (as usual listed after leading "|"s) are simple \emph{term
    structures} written without any ⟦⟧s.  Structures are written with a leading ``constructor,'' which
  should be a capitalized word (the same as sort names), optionally followed by some ``arguments''
  in "()"s, where the declaration gives the sort for each argument (here there are none).

  The semantic sort also includes a "scheme" declaration for the "Unif" constructor, which must be
  followed by an argument list with two "Type" arguments. The scheme declaration is ``instantiated''
  by \emph{rules} of the form
  \begin{displaymath}
    "pattern→replacement"
  \end{displaymath}
  which must specify for each possible shape of "Unif"-construction how it should be simplified by
  the scheme.  Rules may include \emph{parameters} in the form of ``meta-variables'' starting with
  "#" (hash), like "#1", to designate ``function arguments'' that should be copied from the pattern
  to the replacement.

  The rules for the "Unif" scheme above can, for example, be used to simplify a composite term as
  follows:
  %%
\begin{hacs}[xleftmargin=\parindent,xrightmargin=\parindent]
Unif(Unif(Int, Float), Int) → Unif(Float, Int) → Float
\end{hacs}
  %%
  Note how overlaps are allowed but please do verify determinacy, \ie, if a particular combination
  of arguments can be subjected to two rules then they should give the same result! In this example
  i happens because the term "Unif(Float,Float)" can be rewritten by both the rule in line 7 and 8,
  but it does not matter, because the result is the same.
  %% 
\end{example}

\begin{example}[scheme over syntax]\label{ex:leftmost}
  The "Unif" scheme defined in the example is a simple example of a semantic recursive translation
  scheme, defined by rewrite rules.  We are permitted to define such schemes over the syntactic
  sorts, as well.  Here is, for example, code to extract the leftmost leaf expression from an "Exp"
  tree from Example~\ref{ex:syntax}:
  %%
\begin{hacs}[xleftmargin=\parindent,xrightmargin=\parindent]
sort Exp | scheme Leftmost(Exp) ;
Leftmost(⟦⟨Exp#1⟩ + ⟨Exp#2⟩⟧)  →  Leftmost(Exp#1) ;
Leftmost(⟦⟨Exp#2⟩ * ⟨Exp#3⟩⟧)  →  Leftmost(Exp#1) ;
Leftmost(⟦⟨INT#⟩⟧)  →  ⟦⟨INT#⟩⟧ ;
Leftmost(⟦⟨FLOAT#⟩⟧)  →  ⟦⟨FLOAT#⟩⟧ ;
Leftmost(⟦⟨Name#⟩⟧)  →  ⟦⟨Name#⟩⟧ ;
\end{hacs}
  %%
  Notice how:
  \begin{itemize}

  \item We first set the current sort to "Exp" and then add a "scheme" called "Leftmost" that takes
    one argument of the syntactic "Exp" sort.

  \item There is precisely one rule with a pattern applying "Leftmost" to each non-"sugar"
    production for "Exp" from Example~\ref{ex:syntax}.

  \item Each non-terminal reference has the non-terminal name followed by a "#"$n$ marker to
    identify the subexpression of that non-terminal sort for use on the right side of the "→".

  \item Each rule rewrites an "Exp" expression to another "Exp" expression, either by recursively
    invoking the defined "Leftmost" scheme on a smaller part of the term or by returning the term
    itself.

  \item We \emph{have} to write "⟦⟨Name#⟩⟧" rather than just "Name#" or "#" in the last rules
    because the form "Name#" describes something of "Name" sort, not "Exp" sort.  Indeed in the last
    rule, "Name#" stands for the subterm of the "Exp" expression that is a "Name".

  \end{itemize}
\end{example}

\begin{commands}[invoke scheme]
  The "Leftmost" scheme above is also included in \emph{First.hx}.  Since it operates on a syntactic
  expression, we can invoke the "Leftmost" scheme from the command line as follows:
  %%
\begin{code}[commandchars=\\\{\}]
$ \textcolor{blue}{./First.run --scheme=Leftmost --sort=Exp --term="(2*3)+4"}
 2
\end{code}
  %%
  We specify the sort of our input expression here because "Leftmost" takes an "Exp" argument, which
  is different from the main "Stat" sort.

  Note that we cannot meaningfully invoke the "Unif" scheme from the command line because there is
  no user syntax for types in our example!
\end{commands}

\begin{example}[syntactic scheme]\label{ex:append}
  We can even go all the way and define a purely ``syntactic scheme.''  This is best explained with
  an example. Consider the list sort
  %%
\begin{hacs}
sort List | ⟦ ⟨Elem⟩ ⟨List⟩ ⟧ | ⟦⟧ ;
\end{hacs}
  %%
  If we want to allow appending and flattening of lists, then we can define
  %%
\begin{hacs}
sort List | scheme ⟦ { ⟨List⟩ } ⟨List⟩ ⟧ ;
⟦ { ⟨Elem#1⟩ ⟨List#2⟩ } ⟨List#3⟩ ⟧ → ⟦ ⟨Elem#1⟩ { ⟨List#2⟩ } ⟨List#3⟩ ⟧ ;
⟦ { } ⟨List#⟩ ⟧ → # ;
\end{hacs}
  %%
  Notice that:
  %%
  \begin{itemize}

  \item The two rules differ on the content of the braces, and are clearly designed to fully
    eliminate all braces used: this is essential, and we say that the scheme should be
    \emph{complete}.

  \item This is very like "sugar" productions except we can have more than one rule for a given
    construct -- sugar is limited to a single rule that cannot depend on the inner structure of the
    construct.

  \item If you work with synthesized attributes (explained in the next section) then be aware that
    syntactic rules such as the ones presented this one will mess with any synthetic attributes.

  \end{itemize}
  %%
\end{example}

\begin{example}
  The \emph{First.hx} example defines the "Compile" scheme as a top level function to be used from
  the command line. This looks as follows:
\begin{hacs}[xleftmargin=\parindent,numbers=right]
sort AProgr | scheme Compile(Stat);
Compile(#) → ⟦ CG ICG TA ⟨Stat#⟩ ⟧ ;
\end{hacs}
  The "Compile" scheme reflects how our compiler is structured, and in particular that the input is
  a "Stat" and the output an "AProgr", which stands for ``assembly program.''
  (You will see later what the right side of the "→" here means.)  This is the reason for the
  \verb|--scheme=Compile| option we invoked back in the getting started section.  Such wrapper raw
  schemes must have a single argument.
\end{example}


\section{Collecting Information}
\label{sec:collect}

\HAX has special support for assembling information in a ``bottom-up'' manner, corresponding to how
\emph{synthetic attributes} are used in syntax-directed definitions (or attribute grammars).  In
this section we explain \emph{how} you convert any SDD synthetic attribute definition into a \HAX
one.

Consider the following single definition of the synthesized attribute $t$ for expressions $E$:
%%
\begin{equation}
  \begin{array}{l|l}
    \hline
    \hline
    \textsc{Production}  & \textsc{Semantic Rules} \Bigstrut\\
    \hline
    E → E_1 + E_2 & E.t = \op{Unif}(E_1.t, E_2.t) \Bigstrut\\
    \hline
  \end{array}
  \tag{E1}
\end{equation}
%% 
The rule is ``S-attributed'' because it exclusively relies on synthesized attributes. This allows us
to express it directly in \HAX as follows.
%% 
\begin{enumerate}

\item The first thing to do is declare the attribute and associate it with the $E$ sort.
\begin{hacs}
   attribute ↑t(Type);
   sort E | ↑t ;
\end{hacs}
  the "↑" indicates ``synthesized'' because the attribute moves ``up'' in the tree. The declaration
  of the attribute indicates with "(Type)" that the \emph{value} of the synthesized attribute is a
  "Type".  Attributes are always named with lower case names.

\item The second thing to do is copy the corresponding syntax production but omit any "@"-markings
  and add a unique "#"$n$ disambiguation mark to each production, essentially ``upgrading'' each
  nonterminal reference to a meta-variable.  Since \thetag{E1} is based on the alternative
\begin{hacs}
   sort E   | ⟦ ⟨E@1⟩ + ⟨E@2⟩ ⟧@1
\end{hacs}
  similarly to Example~\ref{ex:syntax}, we start with 
\begin{hacs}
   ⟦ ⟨E#1⟩ + ⟨E#2⟩ ⟧
\end{hacs}
  where we have used the subscripts from \thetag{E1} as "#"-disambiguation marks.

\item Next add in \emph{synthesis patterns} for the attributes we are reading.  Each attribute
  reference like $E_1.t$ becomes a pattern like "⟨E#1 ↑t(#t1)⟩", where the meta-variables like
  "#t1" should each be unique.  For our example, this gives us
\begin{hacs}
   ⟦ ⟨E#1 ↑t(#t1)⟩ + ⟨E#2 ↑t(#t2)⟩ ⟧
\end{hacs}
  which sets up "#t1" and "#t2" as synonyms for $E_1.t$ and $E_2.t$, respectively.

\item Finally, add in the actual synthesized attribute, using the same kind of pattern at the
  \emph{end} of the rule (and add a ";"), and we get
\begin{hacs}
   ⟦ ⟨E#1 ↑t(#t1)⟩ + ⟨E#2 ↑t(#t2)⟩ ⟧ ↑t(Unif(#t1,#t2)) ;
\end{hacs}
  %%
  This is read ``When considering an "E" (the current sort) which has the shape
  $⟦⟨E⟩+⟨E⟩⟧$ where furthermore the first expression has a value matching "#t1" for the
  synthesized attribute "t", and the second expression has a value matching "#t2" for the
  synthesized attribute "t", then the entire expression should be assigned the value "Unif(#t1,#t2)"
  for the synthesized attribute~"t".''

\end{enumerate}

\begin{example}\label{ex:collect}
  %%
  In Example~\ref{ex:syntax}, we presented the abstract syntax of the small language processed by
  \emph{First.hx}. A type analysis of the expressions of the language excluding variables might look
  as follows as a standard SDD (syntax directed definition), where we use $E$ for the "Exp"
  non-terminal, and one attribute: $E.t$ is the synthesized "Type" of the expression $E$.  In the
  notations of \cite{Aho+:2006}, the SDD can be specified something like this:
  %% 
  \begin{equation*}
    \begin{array}{l|l}
      \hline
      \hline
      \textsc{Production}  & \textsc{Semantic Rules} \Bigstrut\\
      \hline
      E → E_1 + E_2 & E.t = \op{Unif}(E_1.t, E_2.t) \Bigstrut\\[\jot]
      \quad\mid E_1 \ast E_2 & E.t = \op{Unif}(E_1.t, E_2.t) \\[\jot]
      \quad\mid \textbf{int} & E.t = \op{Int} \\[\jot]
      \quad\mid \textbf{float} & E.t = \op{Float} \\[\jot]
      \hline
    \end{array}
  \end{equation*}
  %%
  where we assume that $\op{Unif}$ is defined as discussed in Example~\ref{ex:unif}.
  %%
  We can convert this SDD to the following \HAX (using the proper names for the sorts as actually
  found in \emph{First.hx}):
  %%
\begin{hacs}[xleftmargin=\parindent,numbers=right,texcl]
attribute ↑t(Type);       // synthesized type

sort Exp | ↑t ;           // expressions have an associated synthesized type, $E.t$

// Synthesis rules for $E.t$.
⟦ ⟨Exp#1 ↑t(#t1)⟩ + ⟨Exp#2 ↑t(#t2)⟩ ⟧ ↑t(Unif(#t1,#t2));
⟦ ⟨Exp#1 ↑t(#t1)⟩ * ⟨Exp#2 ↑t(#t2)⟩ ⟧ ↑t(Unif(#t1,#t2));
⟦ ⟨INT#⟩ ⟧ ↑t(Int);
⟦ ⟨FLOAT#⟩ ⟧ ↑t(Float);
\end{hacs}
  %%
  Line 1 declares the value of the synthesized "t" attribute to be a "Type".
  %%
  Line 3 associates the synthetic attribute "t" to the "Exp" sort: all synthetic attributes are
  associated with one or more abstract syntax sorts.
  %%
  The remaining lines 5--9 are \emph{synthesis rules} that show for each form of "Exp" what the
  value should be, based on the values passed ``up'' from the subexpressions; these are generated
  mechanically as discussed above from the synthesis semantic rules.
\end{example}

Finally, note that if you have multiple synthetic attributes then a synthesis rule \emph{only} adds
one new attribute to the program construct in question, it does not remove any other attributes
already set for it.


\section{Full Syntax-Directed Definitions}
\label{sec:sdd}

In general, however, we wish to implement analyses that are more general than what can be achieved
with S-attributed syntax-directed definitions: we also want to use \emph{inherited} attributes.
This sectionexplains how inherited attributes are implemented in \HAX.

Consider the following two simple semantic rules:
%% 
\begin{equation*}
  \begin{array}{l|ll}
    \hline
    \hline
    \textsc{Production}  & \textsc{Semantic Rules} \Bigstrut&\\
    \hline
    S → \textbf{name}_1 := E_2; S_3
    &
    E_2.e = S.e; 
    S_3.e = \op{Extend}(S.e, \textbf{name}_1.sym, E_2.t) \Bigstrut\quad
    &\thetag{1}
    \\[\jot]
    E → E_1 + E_2
    &
    E_1.e = E.e; E_2.e = E.e
    &\thetag{2}
    \\[\jot]
    \hline
  \end{array}
\end{equation*}
%% 
where we furthermore have the property that th4 $E.t$ property cannot be synthesized until
\emph{after} the inherited attribute $E.e$ has been ``spread'' into the term (we shall see later why
this is typical).

Here are the steps to follow to translate the inheritance to \HAX.
%%
\begin{enumerate}

\item The first thing to do is, again, to declare the attribute.  Since $S.e$ and $E.e$ are a
  \emph{map} from names to types, this is written as follows:
\begin{hacs}
   attribute ↓e{Name:Type} ;
\end{hacs}
  The "↓" indicates an inherited attribute, and the "{Name:Type}" part declares the value of the
  attribute to be a mapping from values of "Name" sort to values of "Type" sort. (We'll assume that
  we still have the $E.t$ synthesized attribute defined as previously.)  As above, attributes are
  always given lower case names.

  Note that only sorts with a "symbol" declaration can be used for keys of mappings: the mappings
  take the rôle of \emph{symbol tables} from traditional compilers.

\item The second thing to do is to associate the inherited attribute to a \emph{recursive scheme},
  which will be responsible for propagating that inherited attribute over a values of a certain
  sort.  This has to be done separately for each sort that $e$ propagates over.  Rule \thetag{2} is
  the simplest, so we take that first.  The rule propagates the $e$ attribute over $E$
  subexpressions, so we invent a scheme, "Ee", which does that.
\begin{hacs}
   sort E | scheme Ee(E) ↓e ;
\end{hacs}
  As can be seen, the scheme generates results of the "E" sort and also takes parameters of the "E"
  sort; in addition it \emph{carries} the inherited attribute "e".

\item We first observe that \thetag{2} operates on sums, which in our case have a syntax like this:
\begin{hacs}
   sort E | ⟦ ⟨E@1⟩ + ⟨E@2⟩ ⟧@1 ;
\end{hacs}
  As before, we create a \emph{pattern} that is equivalent to this, using the subscripts from \thetag{2}:
\begin{hacs}
   ⟦ ⟨E#1⟩ + ⟨E#2⟩ ⟧
\end{hacs}

\item Now \emph{insert} the pattern into the scheme:
\begin{hacs}
   Ee(⟦⟨E#1⟩ + ⟨E#2⟩⟧)
\end{hacs}
  This clearly respects the sort constraints we defined above, with "Ee" being applied to an "E" expression.

\item Since there are no complicated dependencies in \thetag{2}, we are almost done: we just have to
  create a rule where we on the right side of the "→" \emph{apply} the "Ee" scheme recursively to
  the subexpressions that should inherit the "e" attribute:
\begin{hacs}
   Ee(⟦⟨E#1⟩ + ⟨E#2⟩⟧)  → ⟦⟨E Ee(#1)⟩ + ⟨E Ee(#2)⟩⟧ ;
\end{hacs}
  Notice that there is no explicit mention of the "e" attribute, only the \emph{implicit} copying
  that follows from the use of the "Ee" scheme. The recursive  arrangement of the "Ee" wrappers
  implies the two attribute equations $E_1.e=E.e$ and $E_2.e=E.e$ from \thetag{2}.

\item The above rule implements \thetag{2}, with one caveat: every time the "e" attribute is
  propagated through, a new expression is created, which thus loses all the synthesized properties
  it may have had. If we know that the transformation does not invalidate any of the already
  synthesized attributes, then we express that by augmenting the rule to
\begin{hacs}
   Ee(⟦⟨E#1⟩ + ⟨E#2⟩⟧ ↑#syn)  → ⟦⟨E Ee(#1)⟩ + ⟨E Ee(#2)⟩⟧ ↑#syn ;
\end{hacs}
  which now explicitly declares that the new expression should keep all synthetic attributes (again
  named with a meta-variable so several sets can be preserved by a single rule).

\item Rule \thetag{1} is slightly more complicated, because the inherited attribute has non-trivial
  dependencies. We must know the dependency relationship of the attributes to devise a
  \emph{recursive strategy} for the attribute evaluation.  Recall that we have the following
  (realistic) dependency for \thetag{1}: ``The $E_2.t$ attribute cannot be computed until
  \emph{after} $E_2.e$ has been instantiated (and recursively propagated).''  In that case we have
  to evaluate \thetag{1} in two steps:
  \begin{enumerate}
  \item Do $E_2.e = S.e$, establishing the precondition for allowing the system to compute $E_2.t$.
  \item When the system has computed $E_2.t$ then do $S_3.e=\op{Extend}(S.e,\textbf{name}_1.sym,E_2.t)$.
  \end{enumerate}
  These two steps are achieved by having an extra carrier schemes:
\begin{hacs}
   sort S | scheme Se(S) ↓e | scheme SeB(S) ↓e ;
\end{hacs}
  The first propagates into statements in the same way as for \thetag{2}, except only into the first
  subterm, and \emph{chains to the next stage}:
\begin{hacs}
   Se(⟦x := ⟨E#2⟩; ⟨S#3⟩⟧ ↑#syn)  →    SeB(⟦x := ⟨E Ee(#2)⟩; ⟨S#3⟩⟧ ↑#syn) ;
\end{hacs}
  Notice how we invoke the "Ee" scheme to pass $E_2.e$ (the system understands that $S.e$ and
  $E_2.e$ refer to the same attribute), and how we do \emph{not} wrap "#3" in anything as nothing
  should be passed there; instead we just leave the extra top wrapper "SeB" to wait for when it can
  process.

  Once the synthetic is satisfied, \ie, once $E_2.t$ is computed, then the second stage can finishes
  the job, using the notation of the previous section, and proceed recursively on the appropriate
  subterm.  However, it also needs to compute the $\op{Extend}$ result, which is achieved with the
  following rule:
\begin{hacs}
   SeB(⟦x := ⟨E#2 ↑t(#t2)⟩; ⟨S#3⟩⟧ ↑#syn) →  ⟦x := ⟨E#2⟩; ⟨S  Se(#3)↓e{⟦x⟧:#t2} ⟩⟧ ↑#syn ;
\end{hacs}
  The last bit of notation is the way we call "Se" with an \emph{extended} $S_3.e$ attribute: the
  notation "Se(#3)↓e{⟦x⟧:#t2}" means ``call "Se" (passing "e") on the statement "#3" but use an
  "e" which has been extended with the mapping from "x" to "#t2",'' which corresponds to the
  notation $S_3.e=\op{Extend}(S.e,\textbf{name}_1.sym,E_2.t)$ of the SDD.

  Also note that because the "Name" sort is a "symbol" sort, we should \emph{directly} use the
  variable "x" (which is a legal "ID" token) in the rules instead of "⟨Name#x⟩" or such.  However,
  we still take care to distinguish a symbol that is part of the syntax, like "x", from the other
  symbols that are part of the formalism, like "S" and "Se": "x" is always enclosed in $⟦⟧$s

\end{enumerate}

\begin{figure}[h]
  \begin{equation*}
    \begin{array}{r@{\,}l|lr}
      \hline
      \hline
      \multicolumn{2}{c|}{\textsc{Production}}  & \textsc{Semantic Rules} &\Bigstrut\\
      \hline\Bigstrut
      S &→ \textbf{name} := E_1; S_2
      & E_1.e = S.e; S_2.e = \op{Extend}(S.e, \textbf{name}.sym, E_1.t) &\thetag{S1}
      \\[\jot]
      &\mid \{~S_1~\}~S_2 & S_1.e = S.e; S_2.e = S.e &\thetag{S2}
      \\[\jot]
      &\mid ε & &\thetag{S3}
      \\[\jot]
      \hline\Bigstrut
      E &→ E_1 + E_2 & E_1.e=E.e; E_2.e=E.e; E.t = \op{Unif}(E_1.t, E_2.t) &\thetag{E1}\\[\jot]
      &\mid E_1 \ast E_2 & E_1.e=E.e; E_2.e=E.e; E.t = \op{Unif}(E_1.t, E_2.t) &\thetag{E2}\\[\jot]
      &\mid \textbf{int} & E.t = \op{Int}&\thetag{E3}\\[\jot]
      &\mid \textbf{float} & E.t = \op{Float}&\thetag{E4}\\[\jot]
      &\mid \textbf{name} & E.t = \text{if}~\op{Defined}(E.e,\textbf{name}.sym)&\thetag{E5}\\
      && \qquad\quad\text{then}~\op{Lookup}(E.e,\textbf{name}.sym)\\
      && \qquad\quad\text{else}~\op{TypeError}
      \\[\jot]
      \hline
    \end{array}
  \end{equation*}
  \caption{SDD for type checking.}
  \label{fig:sdd}
\end{figure}

\begin{figure}[p]
\begin{hacs}[numbers=right,texcl]
sort Type  | Int | Float | TypeError
           | scheme Unif(Type,Type) ;

Unif(Int, Int) → Int;
Unif(#t1, Float) → Float;
Unif(Float, #t2) → Float;
default Unif(#1,#2) → TypeError; // fall-back

attribute↑t(Type);  // synthesized expression type
sort Exp | ↑t;

⟦ (⟨Exp#1 ↑t(#t1)⟩ + ⟨Exp#2 ↑t(#t2)⟩) ⟧ ↑t(Unif(#t1,#t2));
⟦ (⟨Exp#1 ↑t(#t1)⟩ * ⟨Exp#2 ↑t(#t2)⟩) ⟧ ↑t(Unif(#t1,#t2));
⟦ ⟨INT#⟩ ⟧ ↑t(Int);
⟦ ⟨FLOAT#⟩ ⟧ ↑t(Float);
// Missing case: variables -- handled by Ee below.

attribute↓e{Name:Type};  // inherited type environment

sort Exp | scheme Ee(Exp) ↓e ;  // propagates e over Exp

// These rules associate t attribute with variables (missing case above).
Ee(⟦id⟧) ↓e{⟦id⟧ : #t} → ⟦ id ⟧ ↑t(#t);
Ee(⟦id⟧) ↓e{¬⟦id⟧} → error⟦Undefined identifier ⟨id⟩⟧;

Ee(⟦⟨Exp#1⟩ + ⟨Exp#2⟩⟧ ↑#syn) → ⟦ ⟨Exp Ee(#1)⟩ + ⟨Exp Ee(#2)⟩ ⟧ ↑#syn ;
Ee(⟦⟨Exp#1⟩ * ⟨Exp#2⟩⟧ ↑#syn) → ⟦ ⟨Exp Ee(#1)⟩ * ⟨Exp Ee(#2)⟩ ⟧ ↑#syn ;
Ee(⟦⟨INT#⟩⟧ ↑#syn) → ⟦⟨INT#⟩⟧ ↑#syn ;
Ee(⟦⟨FLOAT#⟩⟧ ↑#syn) → ⟦⟨FLOAT#⟩⟧ ↑#syn ;

sort Stat | scheme Se(Stat) ↓e ;  // propagates e over Stat

Se(⟦id := ⟨Exp#1⟩; ⟨Stat#2⟩⟧ ↑#syn) → SeB(⟦id := ⟨Exp Ee(#1)⟩; ⟨Stat#2⟩⟧ ↑#syn);
{
  | scheme SeB(Stat) ↓e;  // helper scheme for assignment after expression typeanalysis
  SeB(⟦id := ⟨Exp#1 ↑t(#t1)⟩; ⟨Stat#2⟩ ⟧ ↑#syn)
   → ⟦id := ⟨Exp#1⟩; ⟨Stat Se(#2) ↓e{⟦id⟧:#t1}⟩⟧ ↑#syn ;
}

Se (⟦ { ⟨Stat#1⟩ } ⟨Stat#2⟩ ⟧ ↑#syn) → ⟦ { ⟨Stat Se(#1)⟩ } ⟨Stat Se(#2)⟩ ⟧ ↑#syn ;

Se (⟦ ⟧ ↑#syn) → ⟦ ⟧ ↑#syn ;
\end{hacs}
  \caption{\HAX code for type analysis.}
  \label{fig:sdd-hacs}
\end{figure}

\begin{example}\label{ex:sdd}
  %%
  An SDD for a simple type analysis can be implemented with two attributes (and using the usual
  convention that the SDD uses $E$ and $S$ where the \HAX grammar has "Exp" and "Stat"):
  %%
  \begin{itemize}

  \item The inherited \emph{environment} attribute $e$, which is a map from variables to types on
    both the statement and expression non-terminals $S$ and $E$.

  \item The synthesized \emph{type} attribute $t$ on expressions $E$, which contains the type of the
    expression.

  \end{itemize}
  %%
  With those, the SDD can be expressed as shown in Figure~\ref{fig:sdd} using the helpers
  \op{Extend}, \op{Defined}, and \op{Lookup} to build an extended environment with an additional
  type declaration, check for existence, and look one up, respectively, and \op{Unif} to find the
  type of an arithmetic operation with operands of two specific types.

  We can translate this to the \HAX in Figure~\ref{fig:sdd-hacs}, with the following schemes:
  %%
  \begin{itemize}

  \item "Unif" -- unify two types as needed for typing the operators.

  \item "Ee" -- scheme to propagate the $e$ attribute over "Exp" values.

  \item "Se" -- scheme to propagate the $e$ attribute over "Stat" values.

  \item "SeB" -- helper scheme to propagate the $e$ attribute from left to right part of assignment
    statements.
    
  \end{itemize}
  %% 
  The environment helpers get translated to native \HAX environment patterns as follows:
  %% 
  \begin{itemize}

  \item A ``$\op{Defined}(N.e, x)$'' test is encoded by having two rules: one for the ``true''
    branch with the constraint "↓e{⟦x⟧}" in a pattern, and one for the ``false'' case with the
    constraint "↓e{⟦¬x⟧}" in the pattern.

  \item ``$\op{Lookup}(N.e, x)$'' is encoded by adding a constraint "↓e{⟦x⟧:#}" in a pattern, which
    then binds the meta-variable "#" to the result of the lookup. (This will imply the ``defined''
    pattern discussed above.)

  \item ``$\op{Extend}(N.e, x, V)$'' is encoded by additing a constraint "↓e{⟦x⟧:V}" in the
    \emph{replacement}.

  \end{itemize}
  %% 
\end{example}


\section{Compile-time Computations}
\label{sec:comp}

\begin{figure}[t]
  \begin{displaymath}
    \begin{array}{c|p{.5\linewidth}}
      \hline
      \textit{Operators} & \textit{Explanation} \\
      \hline
      +,- & \text{addition, subtraction} \\
      \mid, \caret, \backslash & \text{bitwise or, exclusive or, clear} \\
      \hline
      ×, ÷, \% & \text{multiplication, divison, modulo} \\
      \& & \text{bitwise and} \\
      \ll, \gg & \text{bitwise shift left and right} \\
      \hline
      +,- & \text{unary plus and minus}\\
      {\sim} & \text{bitwise not} \\
      \hline
    \end{array}
  \end{displaymath}
  \caption{Operations permitted in Computed syntax.}
  \label{fig:ops}
\end{figure}

We may sometimes need to compute helper values, most commonly for counting. \HAX supports this
through a special sort, "Computed", which has special syntax for operations on primitive values.

The mechanism is quite simple: in rule replacements, arguments of sort "Computed" can contain
expressions in ⟦⟧s, which include
%%
\begin{itemize}
\item References to meta-variables of sort "Computed".
\item Integers in decimal and "0x"-hexadecimal notation.
\item Standard operators and parentheses.
\end{itemize}

\begin{example}[count]\label{ex:count}
  Consider the list from Example~\ref{ex:append}. The following computes the length of the list.
  %%
\begin{hacs}
sort Computed | scheme ListLength(List, Computed) ;
ListLength(⟦ ⟨Elem#1⟩ ⟨List#2⟩ ⟧, #n) →  ListLength(#2, ⟦ #n + 1 ⟧) ;
ListLength(⟦ ⟧, #n) → #n ;
\end{hacs}
  %%
\end{example}

%Finally, it is possible to extract strings from tokens and reinsert computed values back into
%syntactic expressions as tokens with the following two constructs:
%\begin{itemize}
%
%\item A \emph{token string value} can be inserted into a "Computed" construction with the \$ prefix.
%\item A "Computed" value can be converted to a token string with the 
%
%\end{itemize}

\section{Examples}
\label{sec:examples}

Once the structure of a specification is clear, we can start analyzing and manipulating our internal
representation.  In this section we work through some examples of this.

\begin{remark}
  Before we start, here is a short checklist of recommended practices for \HAX processing:
  %% 
  \begin{itemize}

  \item Separate token names from sort names, for example by using ALL CAPS for token names.

  \item If you use some kind of identifier then declare it as a special sort like
    \begin{displaymath}
      "sort Symbol | symbol ⟦⟨SYMBOL⟩⟧ ;"
    \end{displaymath}
    with "SYMBOL" defined as a token that always allows numeric extensions, like
    \begin{displaymath}
      "token SYMBOL | [a-z]+ ('_'"~"[0-9]+)* ;"
    \end{displaymath}
    When you do this then you are allowed to use symbols of the specified kind in patterns, \ie, a
    rule lile
    \begin{displaymath}
      "F(⟦x_1⟧) →   ⟦ x_1 + x_2 ⟧ ;"
    \end{displaymath}
    will allow "F" to be applied to \emph{any} "Symbol", with "x_1" being the \emph{representative} of
    that symbol for the purpose of the rule. Similarly, "x_2" will correspond to a \emph{globally fresh} symbol,
    as it only occurs left of the "→".

  \end{itemize}
\end{remark}

\begin{figure}[t]
\begin{hacs}[numbers=right,texcl]
module org.crsx.hacs.samples.IsCat {

token WORD | [A-Za-z]+ ;
main sort Word | ⟦⟨WORD⟩⟧ ;

sort Boolean | ⟦True⟧ | ⟦False⟧ ;

sort Boolean | scheme IsCat(Word) ;
IsCat(#word) → IsSameWord(#word, ⟦cat⟧) ;

sort Boolean | scheme IsSameWord(Word, Word) ;
IsSameWord(#, #) → ⟦True⟧ ;
default IsSameWord(#1, #2) → ⟦False⟧ ;
}
\end{hacs}
\caption{\emph{IsCat.hx}: Finding cats.}
\label{fig:cats}
\end{figure}

\begin{example}[finding cats]
  The small example in Figure~\ref{fig:cats} illustrates how to test for equality using a
  non-linear rule in line 12 combined with a ``catch-all'' default rule in line 13.

  Note that we cannot use "⟦cat⟧" directly in a pattern: patterns are restricted to \emph{syntactic
    cases} of the grammar.  Also note that we have here defined the "Boolean" sort to have syntactic
  values rather than just constructors: this allows us to print them.

  Here is a possible run using this command:
  %%
\begin{code}[commandchars=\\\{\}]
$ \textcolor{blue}{hacs IsCat.hx}
...
$ \textcolor{blue}{./IsCat.run --scheme=IsCat --term="dog"}
False
$ \textcolor{blue}{./IsCat.run --scheme=IsCat --term="cat"}
True
\end{code}
\end{example}

\begin{figure}[t]
\begin{hacs}[numbers=right,texcl]
module org.crsx.hacs.samples.WordSet {

// Simple word membership query.
main sort Query | ⟦ ⟨WORD⟩ in ⟨List⟩ ⟧ ;
sort List | ⟦ ⟨WORD⟩, ⟨List⟩ ⟧ | ⟦ ⟨WORD⟩ ⟧ ;
token WORD | [A-Za-z0-9]+ ;

// Collect set of words.
attribute ↑z{WORD} ;
sort List | ↑z ;
⟦ ⟨WORD#w⟩, ⟨List#rest ↑z{:#ws}⟩ ⟧ ↑z{:#ws} ↑z{#w} ;
⟦ ⟨WORD#w⟩ ⟧ ↑z{#w} ;

// We'll provide the answer in clear text.
sort Answer
| ⟦Yes, the list contains ⟨WORD⟩.⟧
| ⟦No, the list does not contain ⟨WORD⟩.⟧
;

// Check is main query scheme, which gives an Answer.
sort Answer | scheme Check(Query) ;

// The main program needs the synthesized list before it can check membership.
Check( ⟦ ⟨WORD#w⟩ in ⟨List#rest ↑z{#w}⟩ ⟧ ) → ⟦Yes, the list contains ⟨WORD#w⟩.⟧ ;
Check( ⟦ ⟨WORD#w⟩ in ⟨List#rest ↑z{¬#w}⟩ ⟧ ) → ⟦No, the list does not contain ⟨WORD#w⟩.⟧ ;
}
\end{hacs}
\caption{\emph{WordSet.hx}: Sets of Words.}
\label{fig:wordset}
\end{figure}

\begin{example}[set of words]
  %%
  One common task is to synthesize a set from some syntactic construct, and subsequently search the
  set. Figure~\ref{fig:wordset} shows a small toy syntax allowing simple queries of word set
  membership.

  The example uses some new mechanisms for synthesizing the set:
  %%
  \begin{itemize}

  \item A helper "z" synthetic attribute contains a \emph{set} of word tokens, which is indicated by
    the attribute declaration "↑z{WORD}" in line~9.

  \item We associate a "z" set with all values of the syntactic sort "List" in line 10.

  \item Lines 11 and 12 capture the synthesis of the set. Line 12 captures the simple case where a
    singleton list synthesizes a singleton set.

  \item Line 11 has a few more notations in play.  First, the \emph{pattern} part of the rule
    includes the inner pattern "↑z{:#ws}". This specifies that the special meta-variable ``":#ws"''
    captures all the existing members of the "z" set.  Second, the result of the rule is to add
    \emph{two} new things to the top level of the rule: "↑z{:ws} ↑z{#w}". This adds \emph{both} the
    existing members (just matched) \emph{and} the one new member "#w" to the result set.

  \item Lines 24 and 25 are almost the same: the one difference is that 24 matches sets that contain
    the "#w" word, whereas 25 matches sets that do not because of the "¬" logical negation sign.
  \end{itemize}
  %%
  We can run the example as follows:
  %%
\begin{code}[commandchars=\^\{\}]
energon1[~]$ ^textcolor{blue}{^texttt{hacs WordSet.hx}}
energon1[~]$ ^textcolor{blue}{^texttt{./WordSet.run --scheme=Check --term="a in a,b,b,a"}}
Yes, the list contains a.
energon1[~]$ ^textcolor{blue}{^texttt{./WordSet.run --scheme=Check --term="Foo in Bar"}}
No, the list does not contain Foo.
\end{code}
\end{example}

\begin{figure}[tp]
\begin{hacs}[numbers=right,texcl]
module org.crsx.hacs.samples.WordMap {

// Simple word map over list.
main sort Query | ⟦ ⟨Map⟩ in ⟨List⟩ ⟧ ;
sort List | ⟦ ⟨WORD⟩ ⟨List⟩ ⟧ | ⟦ ⟧ ;
sort Map | ⟦ ⟨WORD⟩ : ⟨WORD⟩ , ⟨Map⟩ ⟧ | ⟦ ⟨WORD⟩ : ⟨WORD⟩ ⟧ ;
token WORD | [A-Za-z0-9]+ ;

// Collect word mapping.
attribute ↑m{WORD:WORD} ;
sort Map | ↑m ;
⟦ ⟨WORD#key⟩ : ⟨WORD#value⟩, ⟨Map#map ↑m{:#ms}⟩ ⟧ ↑m{:#ms} ↑m{#key:#value} ;
⟦ ⟨WORD#key⟩ : ⟨WORD#value⟩ ⟧ ↑m{#key:#value} ;

// Main program takes a Query and gives a List.
sort List | scheme Substitute(Query) ;

// Environment for mappings during List processing.
attribute ↓e{WORD:WORD} ;
sort List | scheme ListE(List) ↓e ;

// The main program needs the synthesized map before it can substitute.
Substitute( ⟦ ⟨Map#map ↑m{:#ms}⟩ in ⟨List#list⟩ ⟧ ) → ListE( #list ) ↓e{:#ms} ;

// Replace any mapped words.
ListE( ⟦ ⟨WORD#word⟩ ⟨List#words⟩ ⟧ ↑#syn ) ↓e{#word : #replacement}
→ 
⟦ ⟨WORD#replacement⟩ ⟨List ListE(#words)⟩ ⟧↑#syn
;

ListE( ⟦ ⟨WORD#word⟩ ⟨List#words⟩ ⟧ ↑#syn ) ↓e{¬#word}
→ 
⟦ ⟨WORD#word⟩ ⟨List ListE(#words)⟩ ⟧↑#syn
;

ListE( ⟦ ⟧ ↑#syn ) → ⟦ ⟧ ↑#syn ;
}
\end{hacs}
\caption{\emph{WordMap.hx}: Apply Word Substitution as Map.}
\label{fig:wordmap}
\end{figure}

\begin{example}[map of words]\label{ex:wordmap}
  Figure~\ref{fig:wordmap} shows how a map can be synthesized and then used as an environment. The
  pattern is similar to the set example, except here we not only synthesize the map attribute "m"
  but also ``copy'' it over to an inherited map -- an environment -- "e". Notice these extras:
  %%
  \begin{itemize}

  \item The map attribute is synthesized in lines 12--13 just like the set attribute was in the
    previous example, the only difference is that the map of course includes both a key and value.

  \item In line 23 we simply capture all the ``mappings'' of the "m" attribute with the special
    ":#ms" pattern, which we then \emph{reuse} to populate the "e" environment.

  \item We actually combine the distribution of the inherited map with a recursive transformation
    that replaces words, in lines 26--34. The two rules for an initial "WORD" are mutually exclusive
    because the pattern in line 26 requires that the word is present with a mapping in the "e"
    attribute, whereas the pattern in line 31 requires that the word is not present.

  \end{itemize}
  Here is a run demonstrating the program:
\begin{code}[commandchars=\^\{\}]
energon1[~]$ ^textcolor{blue}{^texttt{hacs WordMap.hx}}
energon1[~]$ ^textcolor{blue}{^texttt{./WordMap.run --scheme=Substitute --term="a:b in a b b a"}}
b b b b
energon1[~]$ ^textcolor{blue}{^texttt{./WordSet.run --scheme=Substitute --term="k:v in a b c"}}
a b c
\end{code}
\end{example}

\begin{figure}[tp]\scriptsize
\begin{hacs}[numbers=right,texcl]
module org.crsx.hacs.samples.WordSubst {

// Grammar.
sort Units | ⟦ ⟨Unit⟩ ⟨Units⟩ ⟧ | ⟦⟧ ;
sort Unit | ⟦⟨Variable⟩=⟨NAT⟩⟧ | ⟦⟨Variable⟩⟧ | ⟦⟨NAT⟩⟧ | ⟦ { ⟨Units⟩ } ⟧ ;
sort Variable | symbol ⟦⟨ID⟩⟧ ;

token ID | [A-Za-z]+ ;
token NAT | [0-9]+ ;
space [\ \t\n\r] ;

// Helper Subst structure: lists of variable-NAT pairs.
sort Subst | MoreSubst(Variable, NAT, Subst) | NoSubst ;

// Append operation for Subst structures.
| scheme SubstAppend(Subst, Subst) ;
SubstAppend(MoreSubst(#var, #nat, #subst1), #subst2) → MoreSubst(#var, #nat, SubstAppend(#subst1, #subst2)) ;
SubstAppend(NoSubst, #subst2) → #subst2 ;

// Attributes.
attribute ↑subst(Subst) ;        // collected Subst structure
attribute ↓env{Variable:NAT} ;   // mappings to apply

// Top scheme.
main sort Units | scheme Run(Units) ;
Run(#units) → Run1(#units) ;

// Strategy: two passes.
// 1. force synthesis of subst attribute.
// 2. convert subst attribute to inherited environment (which forces replacement).

| scheme Run1(Units) ;
Run1(#units ↑subst(#subst)) → Run2(#units, #subst) ;

| scheme Run2(Units, Subst) ↓env ;
Run2(#units, MoreSubst(#var, #nat, #subst)) → Run2(#units, #subst) ↓env{#var : #nat} ;
Run2(#units, NoSubst) → Unitsenv(#units) ;

// Synthesis of subst.

sort Units | ↑subst ;
⟦ ⟨Unit #1 ↑subst(#subst1) ⟩ ⟨Units #2 ↑subst(#subst2)⟩ ⟧ ↑subst(SubstAppend(#subst1, #subst2)) ;
⟦ ⟧ ↑subst(NoSubst) ;

sort Unit | ↑subst ;
⟦v=⟨NAT#n⟩⟧ ↑subst(MoreSubst(⟦v⟧, #n, NoSubst)) ;
⟦v⟧ ↑subst(NoSubst) ;
⟦⟨NAT#n⟩⟧ ↑subst(NoSubst) ;
⟦ { ⟨Units#units ↑subst(#subst)⟩ } ⟧ ↑subst(#subst) ;

// Inheritance of env combined with substitution.

sort Units | scheme Unitsenv(Units) ↓env ;
Unitsenv( ⟦ ⟨Unit#1⟩ ⟨Units#2⟩ ⟧↑#s ) →  ⟦ ⟨Unit Unitenv(#1)⟩ ⟨Units Unitsenv(#2)⟩ ⟧↑#s ;
Unitsenv( ⟦ ⟧↑#s ) → ⟦ ⟧↑#s ;

sort Unit | scheme Unitenv(Unit) ↓env ;
Unitenv( ⟦v=⟨NAT#n⟩ ⟧↑#s) → ⟦v=⟨NAT#n⟩⟧↑#s ;
Unitenv( ⟦v⟧ ) ↓env{⟦v⟧:#n} → ⟦⟨NAT#n⟩⟧ ;
Unitenv( ⟦v⟧↑#s ) ↓env{¬⟦v⟧} → ⟦v⟧↑#s ;
Unitenv( ⟦⟨NAT#n⟩⟧↑#s ) → ⟦⟨NAT#n⟩⟧↑#s ;
Unitenv( ⟦ { ⟨Units#units⟩ } ⟧↑#s ) → ⟦ { ⟨Units Unitsenv(#units)⟩ } ⟧↑#s ;
}
\end{hacs}
\caption{\emph{WordSubst.hx}: Combining list, maps, and transformation.}\label{fig:wordsubst}
\end{figure}

\begin{example}[word substitution]
  Figure~\ref{fig:wordsubst} shows a \HAX program to collect substitutions from a document and apply
  them to the entire document.  Notice the following:
  \begin{itemize}

  \item The strategy is a typical two-pass one: first one pass to collect the substitutions into a
    synthesized attribute, then a second pass where the full list of substitutions is applied
    everywhere.

  \item We have chosen to synthesize the map as a \emph{data structure} instead of a native \HAX map
    as in the previous Example~\ref{ex:wordmap} because we here need to \emph{append} two maps (in
    line 42), which is not supported for the native maps.  The synthesis happens in lines 41--49.

  \item We translate the synthesized map in list form into a native \HAX map before starting the
    second pass: notice how "Run2" starts by recursing over the list of substitutions, inserting
    each into the carried inherited "env" map.  Since the map is consumed from left to right, the
    \emph{latest} substitution for any variable is always used.

  \item Since the inheritance schemes for "env" in lines 53--63 are doing a recursive traversal of
    the term, we benefit by building the actual substitutions into the traversal.

  \item In the inheritance rules we are careful to preserve the synthesized attributes only when the
    term does not change. In our case this is manifest by just the rule in line 59 not including the
    "↑#s" marker to capture and copy the synthesized attributes; in general this should be
    considered for every situation.

  \end{itemize}
  %%
  Here is a run with this system:
  %%
\begin{code}[commandchars=\\\{\}]
energon1[~]$ \textcolor{blue}{hacs WordSubst.hx}
...
energon1[~]$ \textcolor{blue}{./WordSubst.run --scheme=Run --term="a=1 a"}
 a=1  1   
energon1[~]$ \textcolor{blue}{./WordSubst.run --scheme=Run --term="b a \{a=1 b=2\}"}
 2  1   {  a=1  b=2    }     
energon1[~]$ \textcolor{blue}{./WordSubst.run --scheme=Run --term="\{a=1 b=2 c=3\} a b c \{a=4\} a b c"}
  \{  a=1  b=2  c=3     \}   4  2  3   \{  a=4   \}   4  2  3         
\end{code}
  %%
  The last example shows how the latest substitution for "a" ``wins.''
  %%
\end{example}


%%% \section{Advanced Features}
%%% \label{sec:advanced}
%%% 
%%% After the analysis we are ready for generating code.
%%% 
%%% \begin{figure}[p]\small
%%% \begin{hacs}[numbers=right]
%%% token T | T ('_' ⟨INT⟩)? ; // temporary
%%% 
%%% // Concrete syntax & abstract syntax sorts.
%%% 
%%% sort I_Progr | ⟦⟨I_Instr⟩ ⟨I_Progr⟩⟧ | ⟦⟧ ;
%%% 
%%% sort I_Instr | ⟦⟨Tmp⟩ = ⟨I_Arg⟩ + ⟨I_Arg⟩; ¶⟧
%%%              | ⟦⟨Tmp⟩ = ⟨I_Arg⟩ * ⟨I_Arg⟩; ¶⟧
%%%              | ⟦⟨Tmp⟩ = ⟨I_Arg⟩; ¶⟧
%%%              | ⟦⟨Name⟩ = ⟨Tmp⟩; ¶⟧ ;
%%% 
%%% sort I_Arg | ⟦⟨Name⟩⟧
%%%            | ⟦⟨FLOAT⟩⟧
%%%            | ⟦⟨INT⟩⟧
%%%            | ⟦⟨Tmp⟩⟧ ;
%%% 
%%% sort Tmp | symbol ⟦ ⟨T⟩ ⟧ ;
%%% 
%%% // Translation scheme.
%%% 
%%% attribute ↓tmpType{Tmp:Type} ;
%%% 
%%% sort I_Progr ;
%%% 
%%% | scheme ⟦ ICG ⟨Stat⟩ ⟧ ↓tmpType ;
%%% ⟦ ICG id := ⟨Exp#2 ↑HasType(#t2)⟩; ⟧
%%%   → ⟦ { ⟨I_Progr ⟦ICGExp T ⟨Exp#2⟩⟧ ↓tmpType{T:#t2}⟩ } id = T; ⟧ ;
%%% ⟦ ICG { } ⟧ → ⟦ ⟧;
%%% ⟦ ICG { ⟨Stat#s⟩ ⟨Stats#ss⟩ } ⟧ → ⟦ { ICG ⟨Stat#s⟩ } ICG { ⟨Stats#ss⟩ } ⟧ ;
%%% 
%%% | scheme ⟦ ICGExp ⟨Tmp⟩ ⟨Exp⟩ ⟧ ;
%%% 
%%% ⟦ ICGExp T ⟨INT#1⟩ ⟧ → ⟦ T = ⟨INT#1⟩; ⟧ ;
%%% ⟦ ICGExp T ⟨FLOAT#1⟩ ⟧ → ⟦ T = ⟨FLOAT#1⟩; ⟧ ;
%%% ⟦ ICGExp T id ⟧ → ⟦ T = id; ⟧ ;
%%% 
%%% ⟦ ICGExp T ⟨Exp#1⟩ + ⟨Exp#2⟩ ⟧
%%%   → ⟦ {ICGExp T_1 ⟨Exp#1⟩} {ICGExp T_2 ⟨Exp#2⟩} T = T_1 + T_2; ⟧ ;
%%% 
%%% ⟦ ICGExp T ⟨Exp#1⟩ * ⟨Exp#2⟩ ⟧
%%%   → ⟦ {ICGExp T_1 ⟨Exp#1⟩} {ICGExp T_2 ⟨Exp#2⟩} T = T_1 * T_2; ⟧ ;
%%% 
%%% // Helper to flatten code sequence.
%%% | scheme ⟦ {⟨I_Progr⟩} ⟨I_Progr⟩ ⟧;
%%% ⟦ {} ⟨I_Progr#3⟩ ⟧ → #3 ;
%%% ⟦ {⟨I_Instr#1⟩ ⟨I_Progr#2⟩} ⟨I_Progr#3⟩ ⟧ → ⟦ ⟨I_Instr#1⟩ {⟨I_Progr#2⟩} ⟨I_Progr#3⟩ ⟧;
%%% \end{hacs}
%%%   \caption{Intermediate Code Generation.}
%%%   \label{fig:icgen}
%%% \end{figure}
%%% 
%%% \begin{example}\label{ex:icgen}
%%%   %%
%%%   A further part of \emph{First.hx} is the translation from abstract syntax to the intermediate
%%%   representation, shown in Fig.~\ref{fig:icgen}. The fragment contains the usual components: a
%%%   syntax specification, rewrite schemes, and rewrite rules for the "ICG" scheme.
%%% 
%%%   The code only uses two new features: "¶" markers in the syntax to indicate newlines, and rules
%%%   that introduce \emph{fresh} variables (of "Tmp" sort): when the replacement of a rule uses a
%%%   symbol, which was not in the pattern, then this corresponds to \emph{generating} a new globally
%%%   unique symbol. So each time the rule
%%% \begin{hacs}
%%%    ⟦ ICG id := ⟨Exp#2 ↑HasType(#t2)⟩; ⟧
%%%      → ⟦ { ⟨I_Progr ⟦ICGExp T ⟨Exp#2⟩⟧ ↓tmpType{T:#t2}⟩ } id = T; ⟧ ;
%%% \end{hacs}
%%%   is used, "T" denotes a new so-called ``fresh'' symbol.  When printed, the various incarnations of
%%%   "T" will be named "T_1", "T_86", \etc
%%%   %%
%%% \end{example}
%%% 
%%% \begin{figure}[p]\small
%%% \begin{hacs}[numbers=right]
%%% /* 7. CODE GENERATOR. */
%%% 
%%% sort A_Progr | ⟦ ⟨A_Instr⟩ ⟨A_Progr⟩ ⟧ | ⟦⟧ ;
%%% 
%%% sort A_Instr | ⟦ LDF ⟨Tmp⟩, ⟨A_Arg⟩ ¶⟧
%%%              | ⟦ STF ⟨Name⟩, ⟨Tmp⟩ ¶⟧
%%%              | ⟦ ADDF ⟨A_Arg⟩, ⟨A_Arg⟩, ⟨A_Arg⟩ ¶⟧
%%%              | ⟦ MULF ⟨A_Arg⟩, ⟨A_Arg⟩, ⟨A_Arg⟩ ¶⟧ ;
%%% 
%%% sort A_Arg | ⟦ #⟨FLOAT⟩ ⟧ | ⟦ #⟨INT⟩ ⟧ | ⟦ ⟨Name⟩ ⟧ | ⟦ ⟨Tmp⟩ ⟧ ;
%%% 
%%% sort A_Progr | scheme ⟦ CG ⟨I_Progr⟩ ⟧ ;
%%% 
%%% ⟦ CG ⟧ → ⟦⟧ ;
%%% 
%%% ⟦ CG T = ⟨I_Arg#1⟩ + ⟨I_Arg#2⟩ ; ⟨I_Progr#⟩ ⟧
%%%   → ⟦ ADDF T, [⟨I_Arg#1⟩], [⟨I_Arg#2⟩] CG ⟨I_Progr#⟩ ⟧ ;
%%% 
%%% ⟦ CG T = ⟨I_Arg#1⟩ * ⟨I_Arg#2⟩ ; ⟨I_Progr#⟩ ⟧
%%%   → ⟦ MULF T, [⟨I_Arg#1⟩], [⟨I_Arg#2⟩] CG ⟨I_Progr#⟩ ⟧ ;
%%%   
%%% ⟦ CG T = ⟨I_Arg#1⟩ ; ⟨I_Progr#⟩ ⟧
%%%   → ⟦ LDF T, [⟨I_Arg#1⟩] CG ⟨I_Progr#⟩ ⟧ ;
%%% 
%%% ⟦ CG name = T ; ⟨I_Progr#⟩ ⟧
%%%   → ⟦ STF name, T CG ⟨I_Progr#⟩ ⟧ ;
%%% 
%%% sort A_Arg | scheme ⟦ [⟨I_Arg⟩] ⟧ ;
%%% ⟦ [T] ⟧ → ⟦ T ⟧ ;
%%% ⟦ [name] ⟧ → ⟦ name ⟧ ;
%%% ⟦ [⟨FLOAT#1⟩] ⟧ → ⟦ #⟨FLOAT#1⟩ ⟧ ;
%%% ⟦ [⟨INT#1⟩] ⟧ → ⟦ #⟨INT#1⟩ ⟧ ;
%%% \end{hacs}
%%%   \caption{Code Generation.}
%%%   \label{fig:cgen}
%%% \end{figure}
%%% 
%%% \begin{example}\label{ex:cgen}
%%%   The seventh part of \emph{First.hx} is the final translation "CG" from the intermediate
%%%   representation to assembly code. This uses no new features, and is shown in Fig.~\ref{fig:cgen},
%%%   however, it is still worth a sanity check, walking through the "CG" scheme and checking that all
%%%   syntactic cases are covered.
%%% \end{example}
%%% 
%%% \begin{remark}[concrete \emph{vs.} raw syntax]
%%%   In the presentation we have chosen to use \emph{concrete syntax} even for semantic
%%%   operations. This has the advantage of allowing direct invocation of even complex structured
%%%   calculations from the command line but it does ``pollute'' the syntax of the defined language.
%%%   (Production versions of \HAX (not yet released) will have the option of generating parsers that
%%%   ignore concrete syntax of schemes when running the compiler.) It is sometimes practical to define
%%%   ``bridge schemes'' that make schemes available both in syntax and raw; we give an example of this
%%%   in the following section.
%%% \end{remark}


\appendix\small

\section{Manual}\label{app:manual}

This appendix is an evolving attempt at giving a systematic description on \HAX.

\begin{manual}[grammar structure]\label{man:structure}
  A \HAX compiler is specified as a single \emph{.hx} module file with the following structure:
  %%
\begin{hacs}[mathescape,xleftmargin=\parindent]
module $\text{\it\color{blue}modulename}$
{
  $\text{\it\color{blue}Declarations}$
}
\end{hacs}
  %%
  where the \emph{modulename} should be a Java style fully qualified class name with the last
  component is capitalized, like \verb|org.crsx.hacs.samples.First|. The individual sections specify
  the compiler, and the possible contents is documented in the manual blocks throughout this
  document.
\end{manual}

\begin{manual}[lexical declarations]\label{man:token}
  %%
  A token is declared with the keyword "token" followed by the token (sort) name, a "|" (vertical
  bar), and a \emph{regular expression}, which has one of the following forms (with increasing order
  of precedence):
  %%
  \begin{enumerate}

  \item Several alternative regular expressions can be combined with further "|" characters.

  \item Concatenation denotes the regular expression recognizing concatenations of what matches the
    subexpressions.

  \item A regular expression (of the forms following this one) can be followed by a \emph{repetition
      marker}: "?" for zero or one, "+" for one or more, and "*" for zero or more.

  \item A simple word without special characters stands for itself.

  \item A string in single or double quotes stands for the contents of the string except that "\"
    introduces an \emph{escape code} that stands for the encoded character in the string (see next item).

  \item A stand-alone "\" followed by an \emph{escape code} stands for that character: escape codes
    include the usual C and Java escapes: "\n", "\r", "\a", "\f", "\t", octal escapes like "\177",
    special character escapes like "\\", "\'", \hacsc|\"|, and Unicode hexadecimal escapes like
    "\u27e9".

  \item A \emph{character class} is given in "[ ]", with these rules:
   \begin{enumerate}
    \item if the first character is "^" then the character class is negated;
    \item if the first (after "^") character is "]" then that character is (not) permitted;
    \item a "\" followed by an \emph{escape code} is encountered then it stands for the encoded
      character;
    \item two characters connected with a "-" (dash) stands for a single character in the indicated
      (inclusive) \emph{range}.
    \end{enumerate}
    Note that a character class cannot be empty, however, "[^]" is permitted and stands for all
    characters.

  \item The "." (period) character stands for the character class "[^\n]".

  \item A nested regular expression can be given in "( )".

  \item An entire other token "T" can be included (by literal substitution, so recursion is not
    allowed) by writing "⟨T⟩" (the angle brackets are unicode characters U+27E8 and U+27E9). Tokens
    declared with "token fragment" can \emph{only} be used this way.

  \item The special declaration "space" defines what constitutes white space for the generated
    grammar. (Note that this does not influence what is considered space in the specification
    itself, even inside syntax productions.) A spacing declaration permits the special alternative
    "nested" declaration for nested comments, illustrated by the following, which defines usual
    C/Java style spacing with comments as used by \HAX itself:
\begin{hacs}[xleftmargin=\parindent]
space [ \t\f\r\n] | nested "/*" "*/" | "//" .* ;
\end{hacs}

  \end{enumerate}
  %%
  Notice that spacing is not significant in regular expressions, except (1) in character classes,
  (2) in literal strings, and (3) if escaped (as in "\ ").
  %%
\end{manual}

\begin{manual}[syntactic sorts]\label{man:syntax}
  %%
  Formally, \HAX uses the following notations for specifying the syntax to use for terms.
  %%
  \begin{enumerate}

  \item \HAX \emph{production names} are capitalized words, so we can for example use "Exp" for the
    production of expressions.  The name of a production also serves as the name of its \emph{sort},
    \ie, the semantic category that is used internally for abstract syntax trees with that root
    production.  If particular instances of a sort need to be referenced later they can be
    \emph{disambiguated} with a "#"$i$ suffix, \eg, "Exp#2", where $i$ is an optional number or
    other simple word.

  \item A sort is declared by one or more "sort" declarations of the name optionally followed by a
    number of \emph{abstract syntax production} alternatives, each starting with a~"|". A sort
    declaration sets the \emph{current sort} for subsequent declarations and in particular any
    stand-alone production alternatives. All sort declarations for a sort are cumulative.

  \item Double square brackets "⟦…⟧" (unicode U+27E6 and U+27E7) are used for \emph{concrete syntax}
    but can contain nested angle brackets "⟨…⟩" (unicode U+27E8 and U+27E9) with \emph{production
      references} like "⟨Exp⟩" for an expression (as well as several other things that we will come
    to later).  We for example write "⟦⟨Exp⟩+⟨Exp⟩⟧" to describe the form where two expressions are
    separated by a "+" sign.

  \item Concrete syntax specification can include "¶" characters to indicate where \emph{newlines}
    should be inserted in the printed output. (The system can also control indentation but that is
    not enabled yet.)

  \item A trailing "@"$p$ for some precedence integer $p$ indicates that either the subexpression or
    the entire alternative (as appropriate) should be considered to have the indicated precedence,
    with higher numbers indicating higher precedence, \ie, tighter association.  (For details on the
    limitations of how the precedence and left recursion mechanisms are implemented, see
    Appendix~\ref{app:limits}.)

  \item "sugar ⟦…⟧→…" alternatives specify equivalent forms for existing syntax: anything matching
    the left alternative will be interpreted the same as the right one (which must have been
    previously defined); references must be disambiguated.

  \item If a production contains only a reference to a token, where furthermore the token is defined
    such that it can end with "_"$n$ (an underscore followed by a count), then the sort can be
    qualified as a "symbol" sort, which can be used for variables and binders.

  \end{enumerate}
  %%
\end{manual}

\begin{manual}[parsed terms]\label{man:parsed}
  The term model includes \emph{parsed terms}.
  %%
  \begin{enumerate}

  \item Double square brackets "⟦…⟧" (unicode U+27E6 and U+27E7) can be used for \emph{concrete
      terms}, provided the \emph{sort} is clear, either
    \begin{enumerate}
    \item by immediately prefixing with the sort (as in "Exp⟦1+2⟧"), or
    \item by using as the argument of a defined constructor (as "IsType(⟦mytype⟧)"), or
    \item by usng as an attribute value, or
    \item by using as a top level rule pattern or replacement term with a defined current sort.
    \end{enumerate}

  \item Concrete terms can contain nested raw terms in "⟨…⟩" (unicode U+27E8 and U+27E9). Such
    nested raw terms \emph{must} have an explicit sort prefix.

  \item The special term "error⟦…⟧" will print the error message embedded in "⟦…⟧", where one is
    permitted to embed "symbol"-declared variables in "⟨…⟩".

  \end{enumerate}

\end{manual}

\begin{manual}[raw terms, schemes, and rules]\label{man:raw}
  %%
  ``Raw'' declarations consist of the following elements:
  %%
  \begin{enumerate}

  \item A \emph{constructor} is a capitalized word (similar to a sort name but in a separate name
    space).

  \item A \emph{variable} is a lower case word (subject to scoping, described below).

  \item A sort can be given a \emph{semantic production} as a "|" (bar) followed by a \emph{form},
    which consists of a constructor name, optionally followed by a list of the subexpression sorts
    in parenthesis.

%%% "()"ed ","-separated list of
%%%    \emph{scope forms}, which each consist of a \emph{sort} optionally preceded by a \emph{binder
%%%      form}, which is a list of sorts followed by a "." (dot). Thus in the most general case, a
%%%    semantic production has the form
%%%    %%
%%%    \begin{equation*}
%%%      \texttt{|}~C~\texttt{(}
%%%      %~[S_{11},\cdots,S_{1n_1}]~S_1~\texttt{,}
%%%      …~\texttt{,}
%%%      ~S_{m1}\cdots S_{mn_m}~\texttt{.}~S_m
%%%      \texttt{)}
%%%    \end{equation*}
%%%    %%
%%%    with $C$ a constructor name and all $S_i$ and $S_{ij}$ sort names. The $S_i$ declares the
%%%    \emph{argument sort} for the $i$th argument of the construction term, and the $S_{ij}$ is the
%%%    \emph{binder sort} of the $j$th binder for the $i$th argument; $m$ is the \emph{arity} of the
%%%    construction and $n_i$ the \emph{rank} of the $i$th argument.

  \item A semantic production can be qualified as a "scheme", which marks the declared construction
    as a candidate for rewrite rules (defined below).

  \item A \emph{raw term} is either a \emph{construction}, a \emph{variable use}, or a
    \emph{meta-application}, as follows
    %%
    \begin{enumerate}

    \item A \emph{construction} term is a constructor name followed by an optional "()"ed
      ","-separated list of subterms.

%%% \emph{scope arguments}, which each consist of a term optionally preceded
%%%      by a \emph{binder list}, which is a list of variables followed by a "." (dot).  So in the most
%%%      general case, a term looks like this:
%%%      %% 
%%%      \begin{equation*}
%%%        C~\texttt{(}
%%%        ~x_{11}\cdots x_{1n_1}~\texttt{.}~t_1~\texttt{,}
%%%        ~…\texttt{,}
%%%        ~x_{m1}\cdots x_{mn_m}~\texttt{.}~t_m
%%%        \texttt{)}
%%%      \end{equation*}
%%%      %%
%%%      The ``$C$-construction'' is said to have the \emph{subterms} $t_1,…,t_m$, and the arity $m$
%%%      and ranks $n_1…n_m$ must correspond to a semantic production.  If present, the binder prefix
%%%      of each introduces the specified variables \emph{only} for the appropriate subterm modulo
%%%      usual renaming, \ie, writing \texttt{A(x y.x, x y.y)} and \texttt{A(a b.a, a b.b)} and even
%%%      \texttt{A(s t.s, t s.s)} all denote the same term following the conventions of
%%%      \emph{α-equivalence}.  In a scope argument $x\texttt{.}t$ we say that occurrences of $x$ in
%%%      $t$ are \emph{bound} by the binder.

    \item A \emph{variable use} term is a variable, subject to the usual lexical scoping rules.

    \item A \emph{meta-application} term is a \emph{meta-variable}, consisting of a "#" (hash)
      followed by a number or word and optionally by a meta-argument list of ","-separated terms
      enclosed in "[]". Examples include "#t1" (with no arguments), "#[a,b,c]", and "#1[OK,#]".

    \end{enumerate}

  \item A term can have a \emph{sort prefix}. So the term "Type Unif(Type #t1, Type Float)" is the
    same as "Unif(#t1,Float)" provided "Unif" was declared with the raw production
    "|Unif(Type,Type)".

  \item A \emph{rewrite rule} is a pair of terms separatede by "→" (arrow, U+2192), with a few
    additional constraints: in the rule $p→t$, $p$ must be a \emph{pattern}, which means it must be
    a construction term that has been declared as a "scheme" (syntactic or raw) and with the
    restriction that all contained arguments to meta-applications must be bound variables, and all
    meta-applications in $t$ must have meta-variables that also occur in $p$ with the same number of
    meta-arguments.

    Rule declarations must either occur with the appropriate current sort or have a pattern with a
    sort prefix.

  \item One rule per scheme can be prefixed with the qualifier "default". If so then the pattern can
    have no structure: all subterms of the pattern scheme construction must be plain
    meta-applications. Such a default rule is applied \emph{after} it has been ensured that all
    other rules fail for the scheme.

  \item Finally, a rule can be prefixed with the word "rule" for clarity.

  \end{enumerate}
  %%
  Rules are used for \emph{rewriting}, a definition of which is beyond the scope of this document;
  please refer to the literature on higher order rewriting for details~\cite{Klop+:tcs1993}.
  %%
\end{manual}

\begin{manual}[attributes and synthesis rules]\label{man:attributes}\leavevmode
  %%
  \begin{enumerate}

  \item Attributes are declared by "attribute" declarations followed by an \emph{attribute form} of
    one of the following shapes:
    %%
    \begin{enumerate}
    \item "↑Name(ValueSort)" defines that the synthesized attribute "Name" has "ValueSort" values;
    \item "↑Name{KeySort}" defines that the synthesized attribute "Name" is a set of "KeySort" values;
    \item "↑Name{KeySort:ValueSort}" defines that the synthesized attribute "Name" is a map from
      "KeySort" to "Valuesort" values;
    \item "↓Name(ValueSort)", "↓Name{KeySort}", and "↓Name{SymbolSort:ValueSort}" similarly for
      inherited attributes;
    \end{enumerate}

  \item One can add a simple \emph{synthesized attributes} after a raw data term as
    "↑"\emph{name}"("\emph{value}")", where the \emph{name} is an attribute name and the
    \emph{value} can be any term.

  \item Simple \emph{inherited attributes} are added similarly after a raw scheme term as
    "↓"\emph{name}"("\emph{value}")".

  \item An \emph{inherited symbol table attribute extension} is added to a raw scheme term as
    "↓"\emph{name}"{"\emph{symbol}":"\emph{value}"}", where the \emph{symbol} is either a variable
    or a constant (of the appropriate sort).

  \item A \emph{synthesized attribute reference} has the simple form "↑"\emph{name}";" and declares
    that the current sort synthesizes \emph{name} attributes.

  \item A scheme declaration can include \emph{inherited attribute references} of the form
    "↓"\emph{name}, which declares that the scheme inherits the \emph{name} attributes.

  \item A \emph{synthesis rule} is a special rule of the form $t↑name(t')$, where the term $t$ may
    contain subterms with attribute constraints. The rule specifies how terms of the current sort
    and shape $t$ synthesize \emph{name} attributes.

  \item In \emph{rules} one can use the special forms "↑#m", which captures \emph{all} synthesized
    attribute values; "↑t{:#ms}" ("↓t{:#ms}"), which captures the full set of keys or key-value mappings of the
    "t" synthesized (inherited) attribute.

  \end{enumerate}
  %%
  Inherited attributes are managed with regular rules (for schemes) with inherited attribute
  constraints and extensions.
  %%
\end{manual}

\begin{manual}[building and running]\label{man:run}\leavevmode
  To translate a \HAX script to an executable, run the \emph{hacs} command, which generates a number
  of files under a \emph{build} subdirectory, as well as the main script with a \emph{.run}
  extension.  The script accepts a number of options:
  %% 
  \begin{enumerate}

  \item \verb"--sort="\emph{Sort} sets the expected sort (and thus parser productions) for the input to
    \emph{Sort}. The input is read, normalized, and printed.

  \item \verb"--scheme="\emph{Constructor} sets the computation for the compiler to \emph{Constructor},
    which must be a unary raw scheme; the argument sort of \emph{Constructor} defines the parser
    productions to use.  The input is read, wrapped in the action, normalized, and printed.

  \item \verb"--term="\emph{text} use the \emph{text} as the input.

  \item \verb"--input="\emph{file} (or just the \emph{file}) reads the input from \emph{file}.

  \item \verb"--output="\emph{file} sends the input to \emph{file} (the default is the standard output).

  \item \verb"--errors" reports details of errors found by subprocesses.

  \item \verb"--verbose="\emph{n} sets the verbosity of the underlying \CRSX rewrite engine to $n$. The
    default is 0 (quiet) but 1--3 are useful (above 3 you get a lot of low level diagnostic output).

  \item \verb"--parse-verbose" activates (very!) verbose output from JavaCC of the parsing.

  \end{enumerate}
  %%
  You must provide one of \verb"--sort" or \verb"--scheme", and one of \verb"--term" and \verb"--input".

  Notice that the \emph{.run} script has absolute references to the files in the \emph{build}
  directory, so the latter should be moved with care.
\end{manual}




%%% \section{Bonus Examples}\label{appbonus}
%%% 
%%% Some additional \emph{untested} examples. \emph{Note: still need to be worked through.}
%%% 
%%% \begin{example}[\emph{hacs/samples/Bool.hx}]\leavevmode
%%% \inputhacs{../samples/Bool.hx}
%%% \end{example}
%%% 
%%% \begin{example}[\emph{hacs/samples/Deriv.hx}]\leavevmode
%%% \inputhacs{../samples/Deriv.hx}
%%% \end{example}


\section{Common Errors}\label{app:errors}

In this appendix we list some of the more common of what can be called the ``error messages'' of
\HAX. \emph{Note} that most of these only come out when \HAX is run with the \verb'-e' option.

\begin{error}[\HAX syntax]\leavevmode
\begin{code}
Exception in thread "main" java.lang.RuntimeException: net.sf.crsx.CRSException:
 Encountered " "." ". "" at line 35, column 6.
Was expecting one of:
    <MT_Repeat> ...
    "%Repeat" ...
    <MT_Attributes> ...
\end{code}
This error message from the \verb'hacs' command indicates a simple syntax errors in the \emph{.hx}
file.
\end{error}

\begin{error}[user syntax]\leavevmode
\begin{code}
Exception in thread "main" java.lang.RuntimeException:
  net.sf.crsx.CRSException: net.sf.crsx.parser.ParseException:
mycompiler.crs: Parse error in embedded myDecSome term at line 867, column 42:
 ⟦ $TA_Let2b ⟨Dec (#d)⟩{ ⟨DecSome (#ds)⟩} ⟧ at line 867, column 42
 Encountered " "\u27e9" "\u27e8Dec (#d)\u27e9 "" at line 867, column 53
…
\end{code}
  This indicates a concrete syntax error in some parsed syntax---inside "⟦…⟧"---in the \emph{.hx}
  file. The offending fragment is given in double angles in the message. Check that it is correctly
  entered in the \HAX specification in a way that corresponds to a syntax production. Note that the
  line/column numbers refer to the generated \emph{build/…Rules.crs} file, which us not immediately
  helpful (this is a known bug). In error messages a sort is typically referenced as a lower case
  prefix followed by the sort name---here "myDecSome" indicates that the problem is with parsing the
  "DecSome" sort of the "My" parser.
\end{error}

\begin{error}[JavaCC noise]\leavevmode
\begin{code}
Java Compiler Compiler Version ??.??_?? (Parser Generator)
(type "javacc" with no arguments for help)
Reading from file FirstHx.jj . . .
Warning: Choice conflict involving two expansions at
         line 3030, column 34 and line 3033, column 8 respectively.
         A common prefix is: "{" <T_HX_VAR>
         Consider using a lookahead of 3 or more for earlier expansion.
Warning: Line 4680, Column 18: Non-ASCII characters used in regular expression.
Please make sure you use the correct Reader when you create the parser,
 one that can handle your character set.
File "TokenMgrError.java" does not exist.  Will create one.
File "ParseException.java" does not exist.  Will create one.
File "Token.java" does not exist.  Will create one.
File "SimpleCharStream.java" does not exist.  Will create one.
Parser generated with 0 errors and 1 warnings.
Note: net/sf/crsx/samples/gentle/FirstParser.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
\end{code}
  These are ``normal'' messages from JavaCC. Yes, the choice conflict is annoying but is in fact safe.
\end{error}

\begin{error}[missing library]\leavevmode
\begin{code}
gcc -std=c99 -g    -c -o crsx_scan.o crsx_scan.c
crsx.c:11:30: fatal error: unicode/umachine.h: No such file or directory
\end{code}
  The \HAX tools only use one library in C: ICU. You should get the \emph{libicu-dev} package (or
  similar) for your system.
\end{error}

\begin{error}[meta-variable mistake]\leavevmode
\begin{code}
Error in rule Tiger-Ty99_9148-1: contractum uses undefined meta-variable (#es)
Errors prevent normalization.
make: *** [pr3.crs-installed] Error 1
\end{code}
  A rule uses the metavariable "#es" in the replacement without defining it in the corresponding
  pattern.
\end{error}

\begin{error}[]\leavevmode
\begin{code}
/home/krisrose/Desktop/teaching/.../hacs/cookmain PG pr3.hxt > pr3.pg
cookmain: crsx.c:528: bufferEnd: Assertion
   `(((childTerm)->descriptor == ((void *)0)) ? 0 :
        (childTerm)->descriptor->arity) == bufferTop(buffer)->index' failed.
/bin/sh: line 1: 14278 Aborted
  (core dumped) /home/krisrose/Desktop/teaching/.../hacs/cookmain PG pr3.hxt > pr3.pg
\end{code}
  This indicates an arity error: a raw term in the \emph{.hx} file does not have the right number of
  arguments.
\end{error}

\begin{error}\leavevmode
\begin{code}
// $Sortify
// $[Load, ".../build/edu/nyu/csci/cc/fall14/Pr2Solution.hx", "pr2solutionMeta_HxModule"]
Exception in thread "main" edu.nyu.csci.cc.fall14.TokenMgrError:
   Lexical error at line 184, column 31.  Encountered: "t" (116), after : "Call"
\end{code}
This indicates that you have an undefined symbol of sort error in the \emph{.hx} file: the symbol
starting with "Callt" is either undefined or used in a location where it does not match the required
sort.
\end{error}

\begin{error}\leavevmode
\begin{code}
// $Sortify
// $[Load, ".../build/edu/nyu/csci/cc/fall14/Pr2Solution.hx", "pr2solutionMeta_HxModule"]
Exception in thread "main" java.lang.RuntimeException: net.sf.crsx.CRSException:
   Encountered " ")" ") "" at line 255, column 112.
Was expecting one of:
    "," ...
\end{code}
This indicates that you have an incorrect number of arguments in the \emph{.hx} file: here
insufficient arguments (encountering a ")" instead of ","); a similar but opposite error is given
when excess arguments are present.
\end{error}

\begin{error}[]\leavevmode
\begin{code}
/home/krisrose/Desktop/teaching/.../hacs/cookmain PG pr3.hxt > pr3.pg
cookmain: crsx.c:528: bufferEnd: Assertion
   `(((childTerm)->descriptor == ((void *)0)) ? 0 :
        (childTerm)->descriptor->arity) == bufferTop(buffer)->index' failed.
/bin/sh: line 1: 14278 Aborted
  (core dumped) /home/krisrose/Desktop/teaching/.../hacs/cookmain PG pr3.hxt > pr3.pg
\end{code}
  This indicates an arity error: a raw term in the \emph{.hx} file does not have the right number of
  arguments.
\end{error}

\begin{error}[]\leavevmode
\begin{code}
« $Print-Check[
...
»
\end{code}
This error from your \emph{.run} script indicates that you requested a \verb'--scheme' "Check",
which is not in fact declared as a "scheme" in the \emph{.hx} file.
\end{error}


\section{Limitations}\label{app:limits}

\begin{itemize}

\item At most one "nested" declaration per "token".

\item Precedence can only be used on self references, \ie, "⟨E@2⟩" can only occur inside
  productions for the sort "E".

\item It is not possible to use binders and left recursion in the same production with the same
  precedence.

\item Only \emph{immediate} left recursion is currently supported, \ie, the left recursion should be
  within a single production.

\item Productions can share a prefix but only within productions for the same sort, and the prefix
  has to be literally identical unit by unit (except for left recursive precedence markers), \ie,
  \begin{code}
sort S | ⟦ ⟨A⟩ then ⟨B⟩ then C ⟧
       | ⟦ ⟨A⟩ then ⟨B⟩ or else D ⟧ ;
\end{code}
is fine but
\begin{code}
sort S | ⟦ ⟨A⟩ then ⟨B⟩ then C ⟧
       | ⟦ ⟨A⟩ ⟨ThenB⟩ or else D ⟧ ;
sort ThenB | ⟦ then ⟨B⟩ ⟧;
\end{code}
is not.

\item It is not possible to left-factor a binder (so multiple binding constructs cannot have the
  same binder prefix).

\item Variables embedded in "error⟦…⟧" instructions must start with a lower case letter.

\item When using the "symbol" qualifier on a reference to a token then the token \emph{must} allow
  ending in "_"$n$ for $n$ any natural number.

\item When using the same name for a symbol inside of "⟦…⟧" and the corresponding raw variable
  outside of the ⟦⟧, then the common symbol and variable name must be a plain word starting with a
  lower case letter.

\item Special terms like "error⟦…⟧" cannot be used as raw subterms.

\item The "default" rule qualifier is rather fragile and does not yet always work.

\end{itemize}


\bibliography{crs}


\end{document}


%% $Log: hacs-gently.tex,v $
%% Revision 1.29  2014/02/11 15:49:11  krisrose
%% Hash.crs fixed to allow linear use of hash.
%%
%% Revision 1.28  2014/01/26 21:14:34  krisrose
%% Compiled NumericEqual primitive fixed for rounding errors.
%%
%% Revision 1.27  2014/01/21 18:40:46  krisrose
%% Regenerated rulecompiler.
%%
%% Revision 1.26  2014/01/16 14:07:17  krisrose
%% Update compiled $[Decimal] to also handle double.
%%
%% Revision 1.25  2013/12/05 04:10:03  krisrose
%% Manual fix.
%%
%% Revision 1.24  2013/12/03 21:41:55  krisrose
%% Update of hacs.zip.
%%
%% Revision 1.23  2013/12/02 12:21:21  krisrose
%% Option fixes.
%%
%% Revision 1.22  2013/11/25 06:35:09  krisrose
%% HACS cleanup.
%%
%% Revision 1.21  2013/11/21 21:10:55  krisrose
%% Duplicate table row removed.
%%
%% Revision 1.20  2013/11/21 06:19:39  krisrose
%% HACS documentation rough version done.
%%
%% Revision 1.19  2013/11/21 04:01:32  krisrose
%% Newline support in HACS.
%%
%% Revision 1.18  2013/11/20 05:08:17  krisrose
%% HACS functional.
%%
%% Revision 1.17  2013/11/19 21:00:12  krisrose
%% first.hx refactored for hacs-gently runs again.
%%
%% Revision 1.16  2013/11/18 02:28:07  krisrose
%% HACS fully functional.
%%
%% Revision 1.15  2013/11/17 03:20:20  krisrose
%% reify option respects simple-terms.
%% Main .dr not output when modules generated.
%%
%% Revision 1.14  2013/10/30 04:28:28  krisrose
%% HACS synthesized attributes almost ready!
%%
%% Revision 1.13  2013/10/21 18:02:12  krisrose
%% HACS attribute grammar fixed.
%%
%% Revision 1.12  2013/10/17 16:51:43  krisrose
%% Locify avoids $[PassLocationProperties] when possible.
%%
%% Revision 1.11  2013/10/12 21:35:40  krisrose
%% Location and HACS work.
%% Checkpoint before major attribute distribution fix.
%%
%% Revision 1.10  2013/10/06 15:38:28  krisrose
%% First attempt at VariableUse with propserties.
%% Preparing for HACS for unmetaness.
%%
%% Revision 1.9  2013/09/30 11:06:42  krisrose
%% All HACS examples work again.
%%
%% Revision 1.8  2013/09/29 05:49:58  krisrose
%% Attributes next...
%%
%% Revision 1.7  2013/09/27 10:05:12  krisrose
%% Document RegExps.
%%
%% Revision 1.6  2013/09/25 17:14:15  krisrose
%% Change default action to Drop.
%%
%% Revision 1.5  2013/09/20 08:32:04  krisrose
%% Formatting.
%%
%% Revision 1.4  2013/09/20 08:17:57  krisrose
%% Drop diagnostic output.
%%
%% Revision 1.3  2013/09/20 08:11:58  krisrose
%% jar refresh
%%
%% Revision 1.2  2013/09/20 08:03:50  krisrose
%% Ready for the NYU students...
%%
%% Revision 1.1  2013/09/18 14:42:24  krisrose
%% Moved 'dragon' to 'gentle'.
%%
%% New.

%%---------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% End:
